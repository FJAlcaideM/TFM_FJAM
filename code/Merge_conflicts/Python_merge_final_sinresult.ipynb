{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vbg8sMjvjQqc",
        "Otpgq5FKzcGR",
        "bGbdWJ8HzcGT",
        "Y7_PWe2wzcGa",
        "1ew0-6gu7CKT",
        "Ua4TJSXqVXtX",
        "eggP4MzzzcGe",
        "bQpEydR7I_fa",
        "GIJ8JtNcD7fS",
        "Wrcvc6bfDwl3",
        "PasLbuaqDwl4",
        "3dbNtuNSV_-i",
        "Eh3IAFAYdtOE",
        "kNG7Exrne4xx",
        "6G2cVaPa26OD",
        "6p9GAhdwgA-b",
        "gngij3M6gA-e",
        "OpxTxWg6gA-g",
        "tZfhDSHtGC7k",
        "aHI3Mi6z6ruP",
        "u8nRnNzJ6ruV",
        "Auy_UbJq6ruX",
        "lwUCG7iCIM18",
        "lioYyZ0c8ylZ",
        "yro8rb9M8ylb",
        "GRX6DXpJ8ylf",
        "SoY4UZxoP0mu",
        "rSoFnM-wXNGT",
        "xUCyls_t2mav",
        "snOtit5n2max",
        "DOPtrcs72may",
        "jMDhxPIQQ4i7",
        "W7HyDYXr2maz",
        "mD7wbbvE2ma0",
        "ipD7lF1X2ma2",
        "XrXnAwyfQ4jB",
        "O89xD-832ma4",
        "N9DsANFp2ma5",
        "v2tDfVB-2ma6",
        "c_RRVDLAQ4jM",
        "9fWKGdhI2ma7",
        "BSFOyntJ2ma8",
        "d3NS1SLn2ma9",
        "acwUKtZmQ4jS",
        "dVHZv_ytZOmc",
        "pY3JvU_-3F4v",
        "TALjJfoS3F4x",
        "toiBfG1_3F4y",
        "Fs8ZEMPKRXSp",
        "Grvngsym3F4z",
        "usG34X8M3F40",
        "-SpWGfIr3F41",
        "GlkzOJNTRXSv",
        "ivuA-Wo93F42",
        "oS__P5193F43",
        "JI7ttJ283F44",
        "6HTICi5tRXSz",
        "fdGZKlHA3F45",
        "d5SJsase3F46",
        "21OsF5Jd3F47",
        "gEJBX8qcRXS3",
        "j5evzSQEZ_MQ",
        "olp3EnRT3grl",
        "Zk_Y22Q-3grm",
        "lA6gbnVr3grn",
        "Jr3br_jeR7Xv",
        "1BIzmSkT3gro",
        "EZyQjozH3grp",
        "SR9U5g0W3grq",
        "2W3_rS78R7Xx",
        "ZFcKK_eK3grr",
        "ufTEqPpn3grs",
        "wd2W2d_G3grt",
        "Fe4BuK-eR7Xz",
        "RTkhm3uW3gru",
        "JTFjpJjL3grw",
        "9xvVnbWo3grx",
        "p90JYNfmR7X1",
        "KXD_xIQEjo3r",
        "-1WP3kzn35PQ",
        "x4fSRDww35PR",
        "M2LQkCrV35PS",
        "G5W9wa7aSeoo",
        "LuOZiRak35PT",
        "YPvIaUir35PU",
        "CYiuTOr_35PV",
        "shzi97QLSeou",
        "NBoxP6rb35PW",
        "Tb8Vw02p35PX",
        "btUmXTJk35PY",
        "WKzHrI0xSeoy",
        "sET31h6k35PY",
        "asjU1K8I35PZ",
        "1HXsMEu735Pa",
        "Ao7PqeCt2VG7",
        "gFfzEJ3vzcGf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbg8sMjvjQqc"
      },
      "source": [
        "# **IMPORTS:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shM2_VQBAT6W"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNDOTCxVIj88"
      },
      "outputs": [],
      "source": [
        "!pip install dalex -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bhDtPfDdM1X"
      },
      "outputs": [],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAT7E5Hdn4nC"
      },
      "outputs": [],
      "source": [
        "#imports necesarios\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_rel\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.inspection import permutation_importance\n",
        "import statsmodels.api as sm\n",
        "import dalex as dx\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score, RocCurveDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otpgq5FKzcGR"
      },
      "source": [
        "# **Dataset preprocesado:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51JgUjUJzcGS"
      },
      "outputs": [],
      "source": [
        "#carga del dataset\n",
        "data=pd.read_csv(\"/content/drive/MyDrive/TFM/Merge/python_data.csv\")\n",
        "label=pd.read_csv(\"/content/drive/MyDrive/TFM/Merge/python_label.csv\")\n",
        "#file_path_data = r'D:\\Descargas\\merge conflict\\python_data.csv'\n",
        "#file_path_label = r'D:\\Descargas\\merge conflict\\python_label.csv'\n",
        "#data = pd.read_csv(file_path_data)\n",
        "#label= pd.read_csv(file_path_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RISZzmuBG_-d"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFy215vFzcGS"
      },
      "outputs": [],
      "source": [
        "data.head() #comprobar el dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thocXBCtGoOv"
      },
      "outputs": [],
      "source": [
        "label.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKvQrTcVzcGS"
      },
      "outputs": [],
      "source": [
        "#comprobar si existen valores null o ?\n",
        "print(\"¿Existen valores nulos en los datos?:\", data.isnull().values.any())\n",
        "print(\"¿Existen valores  '?'  en los datos?:\", (data == '?').values.any())\n",
        "print(\"¿Existen valores nulos en las etiquetas?:\", label.isnull().values.any())\n",
        "print(\"¿Existen valores  '?'  en las etiquetas?:\", (label == '?').values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbgBeRjNzcGS"
      },
      "outputs": [],
      "source": [
        "print(data.shape)\n",
        "print(label.shape)\n",
        "\n",
        "#obtener lista de atributos sin la variable dependiente\n",
        "feature_names=list(data)\n",
        "print(feature_names)\n",
        "print(list(label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8cOKlP6JJF7"
      },
      "outputs": [],
      "source": [
        "# Calcular la frecuencia de cada clase\n",
        "num_clases = label['is_conflict'].value_counts()\n",
        "print(num_clases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnd16M9oIWeK"
      },
      "outputs": [],
      "source": [
        "# Combinamos los datos con las etiquetas en un solo df\n",
        "df = pd.concat([data, label], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieKyy8HsJDwH"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAs3IAO9zcGS"
      },
      "outputs": [],
      "source": [
        "df.info() #comprobar el tipo de variables y su cantidad. Parece que no hay ninguna variable objeto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Baw3xGuzcGS"
      },
      "outputs": [],
      "source": [
        "df.describe() #obtener algunas estadísitcas de cada atributo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jREdkp_lK5nu"
      },
      "outputs": [],
      "source": [
        "# Parece que file_renamed y file_copied tienen el mismo valor siempre. Vamos a comprobarlo\n",
        "val_renamed = df['file_renamed'].value_counts()\n",
        "val_copied = df['file_copied'].value_counts()\n",
        "print(\"Para file_renamed:\\n\", val_renamed)\n",
        "print(\"Para file_copied:\\n\", val_copied)\n",
        "columnas_constantes = df.columns[df.describe().loc['std'] == 0].tolist()\n",
        "columnas_constantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAoiHoYaLmXM"
      },
      "outputs": [],
      "source": [
        "# Al ser caracteristicas constantes decido eliminarlas\n",
        "df=df.drop('file_renamed', axis=1)\n",
        "df=df.drop('file_copied', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXh5XjhHS1jA"
      },
      "outputs": [],
      "source": [
        "# Actualizamos los nombres de las caracteristicas\n",
        "feature_names=list(df)\n",
        "feature_names.remove('is_conflict')\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkAnQ8NjzcGS"
      },
      "outputs": [],
      "source": [
        "correlation_matrix=df.corr()\n",
        "print(correlation_matrix) #coeficientes de correlación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX_yw8KRoZvl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 7}, linewidths=0.5)\n",
        "plt.title(\"Matriz de correlación\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81JVoP91AXHH"
      },
      "outputs": [],
      "source": [
        "#Pares de atributos con correlación superior a 0.80\n",
        "high_correlation_pairs = []\n",
        "atributos = []\n",
        "\n",
        "#Recorre la matriz de correlación y verifica los valores\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i + 1, len(correlation_matrix.columns)):\n",
        "        if abs(correlation_matrix.iloc[i, j]) > 0.80:\n",
        "            attribute_pair = (correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
        "            high_correlation_pairs.append(attribute_pair)\n",
        "\n",
        "# Imprime los pares de atributos con correlación superior a 0.80 y crear una lista de atributos sin repetir\n",
        "for pair in high_correlation_pairs:\n",
        "    print(\"Correlación alta entre: \", pair[0], \"y\", pair[1])\n",
        "    atributos.extend(pair)\n",
        "\n",
        "# Eliminar duplicados y mantener el orden\n",
        "atributos = list(dict.fromkeys(atributos))\n",
        "\n",
        "# Imprimir la lista de atributos\n",
        "print(\"Lista de atributos con correlación alta: \", atributos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqsc0_1IWpfr"
      },
      "source": [
        "**VALIDACIÓN CRUZADA PARA COMPROBAR EL EFECTO DE LOS PARÁMETROS:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVVbeS1Cb8tU"
      },
      "outputs": [],
      "source": [
        "# Defino los algoritmos base para evaluar\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "brf = BalancedRandomForestClassifier(random_state=42)\n",
        "rus = RUSBoostClassifier(random_state=42)\n",
        "modelos=[rf, brf, gb, ada, rus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBLK9PSbb1ey"
      },
      "outputs": [],
      "source": [
        "for i in atributos:\n",
        "  print(\"\\n##########################################################################################################\")\n",
        "  print(\"\\nPARA EL ATRIBUTO: \", i)\n",
        "\n",
        "  # Preparando los datos\n",
        "  X=df[feature_names]\n",
        "  Y=df['is_conflict']\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, test_size=0.3, random_state=42, stratify=Y)\n",
        "  x_train_sin=x_train.drop(i, axis=1)\n",
        "\n",
        "  for j in modelos:\n",
        "    # Realizar validación cruzada con y sin el atributo con alta correlación:\n",
        "    # Con el atributo\n",
        "    cv_scores_con = cross_val_score(j, x_train, y_train, cv=10, scoring='accuracy')\n",
        "\n",
        "    # Sin el atributo\n",
        "    cv_scores_sin = cross_val_score(j, x_train_sin, y_train, cv=10, scoring='accuracy')\n",
        "\n",
        "    # Calcular el estadístico t y el p-valor\n",
        "    t_statistic, p_value = ttest_rel(cv_scores_con, cv_scores_sin)\n",
        "\n",
        "    # Mostrar los resultados\n",
        "    print(\"-------------------------------------------------------------------------------------------------------------\")\n",
        "    print(\"El modelo: \", j)\n",
        "    print(\"Valor de validación cruzada (con atributo):\", cv_scores_con)\n",
        "    print(\"Valor de validación cruzada (sin atributo):\", cv_scores_sin)\n",
        "    print(\"Valor medio con atributo es: \", np.mean(cv_scores_con), \"\\nEl valor medio sin atributo es: \", np.mean(cv_scores_sin))\n",
        "    if np.mean(cv_scores_con) > np.mean(cv_scores_sin):\n",
        "      print(\"El atributo mejora el desempeño del modelo, con una diferencia de: \", np.mean(cv_scores_con)-np.mean(cv_scores_sin))\n",
        "    else:\n",
        "      print(\"El atributo no mejora el desempeño del modelo, con una diferencia de: \", np.mean(cv_scores_con)-np.mean(cv_scores_sin))\n",
        "\n",
        "    print(\"Estadístico t:\", t_statistic)\n",
        "    print(\"p-valor:\", p_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fihjMtKNsQ3K"
      },
      "outputs": [],
      "source": [
        "# Elimina los atributos con demasiada correlación y menor relevancia que su par\n",
        "feature_names.remove('messages_mean')\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.data_table import DataTable\n",
        "DataTable.max_columns = 30\n",
        "\n",
        "df_display=df.drop(\"messages_mean\", axis=1)\n",
        "df_display.describe()"
      ],
      "metadata": {
        "id": "pgol_h_yX7Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8BNQaOBzcGS"
      },
      "outputs": [],
      "source": [
        "# Tomar los valores de la variable dependiente (y) y las independientes (x)\n",
        "X=df[feature_names]\n",
        "Y=df['is_conflict']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2rD__ywzcGT"
      },
      "outputs": [],
      "source": [
        "#dividir en conjunto de entrenamiento y test 70%-30%\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, test_size=0.3, random_state=42, stratify=Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCHsa9ApQNDI"
      },
      "outputs": [],
      "source": [
        "# Comprobar la division de clases\n",
        "num_train=pd.Series(y_train).value_counts()\n",
        "num_test=pd.Series(y_test).value_counts()\n",
        "porc_train=pd.Series(y_train).value_counts(normalize=True)\n",
        "porc_test=pd.Series(y_test).value_counts(normalize=True)\n",
        "comparacion = pd.DataFrame({'% Train': porc_train, 'Num Train': num_train, '% Test': porc_test,'Num Test': num_test})\n",
        "print(comparacion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGbdWJ8HzcGT"
      },
      "source": [
        "# **Algoritmos:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7_PWe2wzcGa"
      },
      "source": [
        "### **RandomForest:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5uljeikzcGa"
      },
      "outputs": [],
      "source": [
        "modelo=RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "params={'n_estimators':[10,25,50,75,100,200],'min_samples_split':[2,3,5,10,20],'min_samples_leaf':[1,3,5,10,20],'max_depth':[1,3,5,10,20,30]}\n",
        "grid=GridSearchCV(modelo,params,cv=10,scoring='f1',verbose=1)\n",
        "grid.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLtwqnUVzcGa"
      },
      "outputs": [],
      "source": [
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PMUPW8CzcGa"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(class_weight='balanced', max_depth=30, min_samples_leaf=5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc6GICCizcGa"
      },
      "outputs": [],
      "source": [
        "modelo_rf=rf.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSmk5ZNjzcGa"
      },
      "outputs": [],
      "source": [
        "y_pred_rf = modelo_rf.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt3WseVRDbVj"
      },
      "source": [
        "**EVALUACIÓN MODELO:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwOzLYx9zcGa"
      },
      "outputs": [],
      "source": [
        "#comprobación resultados\n",
        "df_pred = pd.DataFrame({'Actual': y_test.squeeze(), 'Predicted': y_pred_rf.squeeze()})\n",
        "print(df_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nuZk1D2-gY7"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusion\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "cm_display = ConfusionMatrixDisplay(cm_rf).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W8LP-PdzcGa"
      },
      "outputs": [],
      "source": [
        "# Calcular métricas para evaluar el rendimiento del algoritmo\n",
        "accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "recall = recall_score(y_test, y_pred_rf)\n",
        "precision = precision_score(y_test, y_pred_rf)\n",
        "f1 = f1_score(y_test, y_pred_rf)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1-score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPgK4-OYzcGb"
      },
      "outputs": [],
      "source": [
        "modelo_rf.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoRA-csYzcGb"
      },
      "outputs": [],
      "source": [
        "modelo_rf.score(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pGOoT8ZchsE"
      },
      "outputs": [],
      "source": [
        "# AUROC\n",
        "y_score = modelo_rf.predict_proba(x_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=modelo_rf.classes_[1])\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byKRewcEfCzB"
      },
      "outputs": [],
      "source": [
        "auc=roc_auc_score(y_test, y_score)\n",
        "auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E57SaBUVxSRb"
      },
      "source": [
        "**CLASES INVERTIDAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk8YviJRyHWc"
      },
      "outputs": [],
      "source": [
        "y_test_inv = y_test.values\n",
        "y_test_inv = 1 - y_test_inv\n",
        "y_test_inv = pd.Series(y_test_inv)\n",
        "y_pred_rf_inv = 1 - y_pred_rf\n",
        "df_pred_inv = pd.DataFrame({'Actual': y_test_inv.squeeze(), 'Predicted': y_pred_rf_inv.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z03ZK7hxJZPz"
      },
      "outputs": [],
      "source": [
        "df_pred.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tuywE_MyIE9"
      },
      "outputs": [],
      "source": [
        "df_pred_inv.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM3kivPmxOtR"
      },
      "outputs": [],
      "source": [
        "# Calcular métricas al invertir las clases\n",
        "accuracy_inv = accuracy_score(y_test_inv, y_pred_rf_inv)\n",
        "recall_inv = recall_score(y_test_inv, y_pred_rf_inv)\n",
        "precision_inv = precision_score(y_test_inv, y_pred_rf_inv)\n",
        "f1_inv = f1_score(y_test_inv, y_pred_rf_inv)\n",
        "print(\"Accuracy:\", accuracy_inv)\n",
        "print(\"Recall:\", recall_inv)\n",
        "print(\"Precision:\", precision_inv)\n",
        "print(\"F1-score:\", f1_inv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVYypVo5xobI"
      },
      "outputs": [],
      "source": [
        "score_inv_result={\"Modelo\":[\"RandomForest\"],\"Accuracy\":[accuracy_inv], \"Precision\":[precision_inv], \"Recall\":[recall_inv], \"F1-score\":[f1_inv]}\n",
        "score_inv_result=pd.DataFrame(score_inv_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5DaM1jUdM-b"
      },
      "source": [
        "**VALIDACIÓN CRUZADA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSqNd-9VdM-b"
      },
      "outputs": [],
      "source": [
        "# El número de folds\n",
        "n_folds = 10\n",
        "\n",
        "# Inicializar listas para almacenar las puntuaciones de las métricas. Nos centramos en las métricas comunes en la literatura\n",
        "acc_sc = []\n",
        "prec_sc = []\n",
        "rcll_sc = []\n",
        "f1_sc = []\n",
        "\n",
        "# Crear los objetos KFold\n",
        "skf = StratifiedKFold(n_splits=n_folds)\n",
        "\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    # Dividir los datos en entrenamiento y prueba\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    cv_rf= RandomForestClassifier(class_weight='balanced', max_depth=30, min_samples_leaf=5, random_state=42)\n",
        "    cv_rf.fit(X_train, Y_train)\n",
        "\n",
        "    # Realizar las predicciones en el conjunto de prueba\n",
        "    Y_pred = cv_rf.predict(X_test)\n",
        "\n",
        "    # Calcular las métricas\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    recall = recall_score(Y_test, Y_pred)\n",
        "    precision = precision_score(Y_test, Y_pred)\n",
        "    f1 = f1_score(Y_test, Y_pred)\n",
        "\n",
        "    # Agregar las puntuaciones a las listas\n",
        "    acc_sc.append(accuracy)\n",
        "    prec_sc.append(precision)\n",
        "    rcll_sc.append(recall)\n",
        "    f1_sc.append(f1)\n",
        "\n",
        "# Calcular la media de las puntuaciones\n",
        "mean_acc = np.mean(acc_sc)\n",
        "mean_prec = np.mean(prec_sc)\n",
        "mean_rcll = np.mean(rcll_sc)\n",
        "mean_f1 = np.mean(f1_sc)\n",
        "\n",
        "print(f'CV Accuracy: {mean_acc:.4f}')\n",
        "print(f'CV Precision: {mean_prec:.4f}')\n",
        "print(f'CV Recall: {mean_rcll:.4f}')\n",
        "print(f'CV F1-Score: {mean_f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nPVd4RSdM-b"
      },
      "outputs": [],
      "source": [
        "cv_results = cross_validate(rf, X, Y, cv=10, scoring=('accuracy','precision', 'recall','f1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmKJ52n5dM-b"
      },
      "outputs": [],
      "source": [
        "sorted(cv_results.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V840MzevdM-b"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\\n\", cv_results['test_accuracy'], \"\\n Con una media de: \", np.mean(cv_results['test_accuracy']))\n",
        "print(\"Precision:\\n\" , cv_results['test_precision'], \"\\n Con una media de: \", np.mean(cv_results['test_precision']))\n",
        "print(\"Recall:\\n\", cv_results['test_recall'], \"\\n Con una media de: \", np.mean(cv_results['test_recall']))\n",
        "print(\"F1-score:\\n\", cv_results['test_f1'], \"\\n Con una media de: \", np.mean(cv_results['test_f1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXOZDY6xzcGb"
      },
      "outputs": [],
      "source": [
        "score_result={\"Modelo\":[\"RandomForest\"],\"Accuracy\":[np.mean(cv_results['test_accuracy'])], \"Precision\":[np.mean(cv_results['test_precision'])], \"Recall\":[np.mean(cv_results['test_recall'])], \"F1-score\":[np.mean(cv_results['test_f1'])]}\n",
        "score_result=pd.DataFrame(score_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ew0-6gu7CKT"
      },
      "source": [
        "### **BalancedRandomForest:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvidRGEc7CKT"
      },
      "outputs": [],
      "source": [
        "modelo=BalancedRandomForestClassifier(random_state=42)\n",
        "params={'n_estimators':[10,25,50,75,100,200],'min_samples_split':[2,3,5,10,20],'min_samples_leaf':[1,3,5,10,20],'max_depth':[1,3,5,10,20,30],'class_weight':[None,'balanced']}\n",
        "grid=GridSearchCV(modelo,params,cv=10,scoring='f1',verbose=1)\n",
        "grid.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t9G04ddDhVC"
      },
      "outputs": [],
      "source": [
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CYX9Q1b7CKT"
      },
      "outputs": [],
      "source": [
        "brf = BalancedRandomForestClassifier(class_weight='balanced', n_estimators=10,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MUwkabA7CKT"
      },
      "outputs": [],
      "source": [
        "modelo_brf=brf.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcHFp6mx7CKT"
      },
      "outputs": [],
      "source": [
        "y_pred_brf = modelo_brf.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32-XY7meDZQN"
      },
      "source": [
        "**EVALUACIÓN MODELO:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvPVomzb7CKU"
      },
      "outputs": [],
      "source": [
        "#comprobación resultados\n",
        "df_pred = pd.DataFrame({'Actual': y_test.squeeze(), 'Predicted': y_pred_brf.squeeze()})\n",
        "print(df_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzNDoXD81hM4"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusion\n",
        "cm_brf = confusion_matrix(y_test, y_pred_brf)\n",
        "cm_display = ConfusionMatrixDisplay(cm_brf).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMS-JPOX1oBn"
      },
      "outputs": [],
      "source": [
        "#calcular métricas para evaluar el rendimiento del algoritmo\n",
        "accuracy = accuracy_score(y_test, y_pred_brf)\n",
        "recall = recall_score(y_test, y_pred_brf)\n",
        "precision = precision_score(y_test, y_pred_brf)\n",
        "f1 = f1_score(y_test, y_pred_brf)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1-score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqotxrYYfzd5"
      },
      "outputs": [],
      "source": [
        "modelo_brf.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EXjmS5-fzd5"
      },
      "outputs": [],
      "source": [
        "modelo_brf.score(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDjcI214fzd4"
      },
      "outputs": [],
      "source": [
        "# AUROC\n",
        "y_score = modelo_brf.predict_proba(x_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=modelo_brf.classes_[1])\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tbxd8g1afzd5"
      },
      "outputs": [],
      "source": [
        "auc=roc_auc_score(y_test, y_score)\n",
        "auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMpli1fLgZla"
      },
      "source": [
        "**CLASES INVERTIDAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt-79IungZlb"
      },
      "outputs": [],
      "source": [
        "y_test_inv = y_test.values\n",
        "y_test_inv = 1 - y_test_inv\n",
        "y_test_inv = pd.Series(y_test_inv)\n",
        "y_pred_brf_inv = 1 - y_pred_brf\n",
        "df_pred_inv = pd.DataFrame({'Actual': y_test_inv.squeeze(), 'Predicted': y_pred_brf_inv.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCKZe5frgZlb"
      },
      "outputs": [],
      "source": [
        "df_pred.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3xwqBCJgZlb"
      },
      "outputs": [],
      "source": [
        "df_pred_inv.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3xABluUgZlb"
      },
      "outputs": [],
      "source": [
        "# Calcular métricas al invertir las clases\n",
        "accuracy_inv = accuracy_score(y_test_inv, y_pred_brf_inv)\n",
        "recall_inv = recall_score(y_test_inv, y_pred_brf_inv)\n",
        "precision_inv = precision_score(y_test_inv, y_pred_brf_inv)\n",
        "f1_inv = f1_score(y_test_inv, y_pred_brf_inv)\n",
        "print(\"Accuracy:\", accuracy_inv)\n",
        "print(\"Recall:\", recall_inv)\n",
        "print(\"Precision:\", precision_inv)\n",
        "print(\"F1-score:\", f1_inv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJQvKuajhG0V"
      },
      "outputs": [],
      "source": [
        "score_inv_result=score_inv_result.append({\"Modelo\":\"BalancedRF\",\"Accuracy\":accuracy_inv, \"Precision\":precision_inv, \"Recall\":recall_inv, \"F1-score\":f1_inv}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwpmRsb_fzd5"
      },
      "source": [
        "**VALIDACIÓN CRUZADA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YBZIZ4pfzd5"
      },
      "outputs": [],
      "source": [
        "# El número de folds\n",
        "n_folds = 10\n",
        "\n",
        "# Inicializar listas para almacenar las puntuaciones de las métricas. Nos centramos en las métricas comunes en la literatura\n",
        "acc_sc = []\n",
        "prec_sc = []\n",
        "rcll_sc = []\n",
        "f1_sc = []\n",
        "\n",
        "# Crear los objetos KFold\n",
        "skf = StratifiedKFold(n_splits=n_folds)\n",
        "\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    # Dividir los datos en entrenamiento y prueba\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    cv_brf= BalancedRandomForestClassifier(class_weight='balanced', n_estimators=10,random_state=42)\n",
        "    cv_brf.fit(X_train, Y_train)\n",
        "\n",
        "    # Realizar las predicciones en el conjunto de prueba\n",
        "    Y_pred = cv_brf.predict(X_test)\n",
        "\n",
        "    # Calcular las métricas\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    recall = recall_score(Y_test, Y_pred)\n",
        "    precision = precision_score(Y_test, Y_pred)\n",
        "    f1 = f1_score(Y_test, Y_pred)\n",
        "\n",
        "    # Agregar las puntuaciones a las listas\n",
        "    acc_sc.append(accuracy)\n",
        "    prec_sc.append(precision)\n",
        "    rcll_sc.append(recall)\n",
        "    f1_sc.append(f1)\n",
        "\n",
        "# Calcular la media de las puntuaciones\n",
        "mean_acc = np.mean(acc_sc)\n",
        "mean_prec = np.mean(prec_sc)\n",
        "mean_rcll = np.mean(rcll_sc)\n",
        "mean_f1 = np.mean(f1_sc)\n",
        "\n",
        "print(f'CV Accuracy: {mean_acc:.4f}')\n",
        "print(f'CV Precision: {mean_prec:.4f}')\n",
        "print(f'CV Recall: {mean_rcll:.4f}')\n",
        "print(f'CV F1-Score: {mean_f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4SWfnm0fzd5"
      },
      "outputs": [],
      "source": [
        "cv_results = cross_validate(brf, X, Y, cv=10, scoring=('accuracy','precision', 'recall','f1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqs7Ue32fzd5"
      },
      "outputs": [],
      "source": [
        "sorted(cv_results.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXFd2oGrfzd5"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\\n\", cv_results['test_accuracy'], \"\\n Con una media de: \", np.mean(cv_results['test_accuracy']))\n",
        "print(\"Precision:\\n\" , cv_results['test_precision'], \"\\n Con una media de: \", np.mean(cv_results['test_precision']))\n",
        "print(\"Recall:\\n\", cv_results['test_recall'], \"\\n Con una media de: \", np.mean(cv_results['test_recall']))\n",
        "print(\"F1-score:\\n\", cv_results['test_f1'], \"\\n Con una media de: \", np.mean(cv_results['test_f1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u5zQH7F7CKV"
      },
      "outputs": [],
      "source": [
        "score_result=score_result.append({\"Modelo\":\"BalancedRF\",\"Accuracy\":np.mean(cv_results['test_accuracy']), \"Precision\":np.mean(cv_results['test_precision']), \"Recall\":np.mean(cv_results['test_recall']), \"F1-score\":np.mean(cv_results['test_f1'])}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua4TJSXqVXtX"
      },
      "source": [
        "### **GradientBoosting:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTHkMiccVXtY"
      },
      "outputs": [],
      "source": [
        "modelo=GradientBoostingClassifier(random_state=42)\n",
        "params={'n_estimators':[10,25,50,75,100,200],'min_samples_split':[2,3,5,10,20],'min_samples_leaf':[1,3,5,10,20],'max_depth':[1,3,5,10,20,30]}\n",
        "grid=GridSearchCV(modelo,params,cv=10,scoring='f1',verbose=1)\n",
        "grid.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3qjHXmGVXtY"
      },
      "outputs": [],
      "source": [
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMLMh04rVXtZ"
      },
      "outputs": [],
      "source": [
        "gb = GradientBoostingClassifier(max_depth=10, min_samples_leaf=10, n_estimators=200, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWiHziezVXtZ"
      },
      "outputs": [],
      "source": [
        "modelo_gb=gb.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNZbhn83VXtZ"
      },
      "outputs": [],
      "source": [
        "y_pred_gb = modelo_gb.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bGqLc3ECYvp"
      },
      "source": [
        "**EVALUACIÓN MODELO:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWSi846vVXtZ"
      },
      "outputs": [],
      "source": [
        "#comprobación resultados\n",
        "df_pred = pd.DataFrame({'Actual': y_test.squeeze(), 'Predicted': y_pred_gb.squeeze()})\n",
        "print(df_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZmhd3pjVXtZ"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusion\n",
        "cm_gb = confusion_matrix(y_test, y_pred_gb)\n",
        "cm_display = ConfusionMatrixDisplay(cm_gb).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiLTbuKMVXta"
      },
      "outputs": [],
      "source": [
        "#calcular métricas para evaluar el rendimiento del algoritmo\n",
        "accuracy = accuracy_score(y_test, y_pred_gb)\n",
        "recall = recall_score(y_test, y_pred_gb)\n",
        "precision = precision_score(y_test, y_pred_gb)\n",
        "f1 = f1_score(y_test, y_pred_gb)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1-score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XshYw2yEVXta"
      },
      "outputs": [],
      "source": [
        "modelo_gb.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULAkoITaVXta"
      },
      "outputs": [],
      "source": [
        "modelo_gb.score(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPlrDKaQVXtZ"
      },
      "outputs": [],
      "source": [
        "# AUROC\n",
        "y_score = modelo_gb.predict_proba(x_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=modelo_gb.classes_[1])\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRGX2WrnVXta"
      },
      "outputs": [],
      "source": [
        "auc=roc_auc_score(y_test, y_score)\n",
        "auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3G0sd86pKcE"
      },
      "source": [
        "**CLASES INVERTIDAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX9_Q4yIpKcE"
      },
      "outputs": [],
      "source": [
        "y_test_inv = y_test.values\n",
        "y_test_inv = 1 - y_test_inv\n",
        "y_test_inv = pd.Series(y_test_inv)\n",
        "y_pred_gb_inv = 1 - y_pred_gb\n",
        "df_pred_inv = pd.DataFrame({'Actual': y_test_inv.squeeze(), 'Predicted': y_pred_gb_inv.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7INWArDpKcF"
      },
      "outputs": [],
      "source": [
        "df_pred.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOAAzHGIpKcF"
      },
      "outputs": [],
      "source": [
        "df_pred_inv.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stVvVkj3pKcF"
      },
      "outputs": [],
      "source": [
        "# Calcular métricas al invertir las clases\n",
        "accuracy_inv = accuracy_score(y_test_inv, y_pred_gb_inv)\n",
        "recall_inv = recall_score(y_test_inv, y_pred_gb_inv)\n",
        "precision_inv = precision_score(y_test_inv, y_pred_gb_inv)\n",
        "f1_inv = f1_score(y_test_inv, y_pred_gb_inv)\n",
        "print(\"Accuracy:\", accuracy_inv)\n",
        "print(\"Recall:\", recall_inv)\n",
        "print(\"Precision:\", precision_inv)\n",
        "print(\"F1-score:\", f1_inv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Dk1nz16pKcF"
      },
      "outputs": [],
      "source": [
        "score_inv_result=score_inv_result.append({\"Modelo\":\"GradientBoost\",\"Accuracy\":accuracy_inv, \"Precision\":precision_inv, \"Recall\":recall_inv, \"F1-score\":f1_inv}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQnluRqyVXta"
      },
      "source": [
        "**VALIDACIÓN CRUZADA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWfsenMuVXta"
      },
      "outputs": [],
      "source": [
        "# El número de folds\n",
        "n_folds = 10\n",
        "\n",
        "# Inicializar listas para almacenar las puntuaciones de las métricas. Nos centramos en las métricas comunes en la literatura\n",
        "acc_sc = []\n",
        "prec_sc = []\n",
        "rcll_sc = []\n",
        "f1_sc = []\n",
        "\n",
        "# Crear los objetos KFold\n",
        "skf = StratifiedKFold(n_splits=n_folds)\n",
        "\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    # Dividir los datos en entrenamiento y prueba\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    cv_gb= GradientBoostingClassifier(max_depth=10, min_samples_leaf=10, n_estimators=200, random_state=42)\n",
        "    cv_gb.fit(X_train, Y_train)\n",
        "\n",
        "    # Realizar las predicciones en el conjunto de prueba\n",
        "    Y_pred = cv_gb.predict(X_test)\n",
        "\n",
        "    # Calcular las métricas\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    recall = recall_score(Y_test, Y_pred)\n",
        "    precision = precision_score(Y_test, Y_pred)\n",
        "    f1 = f1_score(Y_test, Y_pred)\n",
        "\n",
        "    # Agregar las puntuaciones a las listas\n",
        "    acc_sc.append(accuracy)\n",
        "    prec_sc.append(precision)\n",
        "    rcll_sc.append(recall)\n",
        "    f1_sc.append(f1)\n",
        "\n",
        "# Calcular la media de las puntuaciones\n",
        "mean_acc = np.mean(acc_sc)\n",
        "mean_prec = np.mean(prec_sc)\n",
        "mean_rcll = np.mean(rcll_sc)\n",
        "mean_f1 = np.mean(f1_sc)\n",
        "\n",
        "print(f'CV Accuracy: {mean_acc:.4f}')\n",
        "print(f'CV Precision: {mean_prec:.4f}')\n",
        "print(f'CV Recall: {mean_rcll:.4f}')\n",
        "print(f'CV F1-Score: {mean_f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIPNckQ2VXtb"
      },
      "outputs": [],
      "source": [
        "cv_results = cross_validate(gb, X, Y, cv=10, scoring=('accuracy','precision', 'recall','f1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zuqnn2psVXtb"
      },
      "outputs": [],
      "source": [
        "sorted(cv_results.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZNDDmQvVXtb"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\\n\", cv_results['test_accuracy'], \"\\n Con una media de: \", np.mean(cv_results['test_accuracy']))\n",
        "print(\"Precision:\\n\" , cv_results['test_precision'], \"\\n Con una media de: \", np.mean(cv_results['test_precision']))\n",
        "print(\"Recall:\\n\", cv_results['test_recall'], \"\\n Con una media de: \", np.mean(cv_results['test_recall']))\n",
        "print(\"F1-score:\\n\", cv_results['test_f1'], \"\\n Con una media de: \", np.mean(cv_results['test_f1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80Kz1XOqVXtb"
      },
      "outputs": [],
      "source": [
        "score_result=score_result.append({\"Modelo\":\"GradientBoosting\",\"Accuracy\":np.mean(cv_results['test_accuracy']), \"Precision\":np.mean(cv_results['test_precision']), \"Recall\":np.mean(cv_results['test_recall']), \"F1-score\":np.mean(cv_results['test_f1'])}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eggP4MzzzcGe"
      },
      "source": [
        "### **AdaBoosting:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg2_D1Ky5LSZ"
      },
      "outputs": [],
      "source": [
        "modelo=AdaBoostClassifier(random_state=42)\n",
        "params={'n_estimators':[5,10,25,50,75,100,200],'learning_rate':[0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,3.0,5.0], 'algorithm':['SAMME','SAMME.R']}\n",
        "grid=GridSearchCV(modelo,params,cv=10,scoring='f1',verbose=1)\n",
        "grid.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6qEmjQl5LSZ"
      },
      "outputs": [],
      "source": [
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6DL5047zcGe"
      },
      "outputs": [],
      "source": [
        "ada=AdaBoostClassifier(learning_rate=1.2, n_estimators=200, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA1qQfuRzcGe"
      },
      "outputs": [],
      "source": [
        "modelo_ada=ada.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc_g8b1izcGe"
      },
      "outputs": [],
      "source": [
        "y_pred_ada = modelo_ada.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMPvVPFS-Io2"
      },
      "source": [
        "**EVALUACIÓN MODELO:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n12elsCzcGe"
      },
      "outputs": [],
      "source": [
        "#comprobación resultados\n",
        "df_pred = pd.DataFrame({'Actual': y_test.squeeze(), 'Predicted': y_pred_ada.squeeze()})\n",
        "print(df_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Is6cVWihw-Q"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusion\n",
        "cm_ada = confusion_matrix(y_test, y_pred_ada)\n",
        "cm_display = ConfusionMatrixDisplay(cm_ada).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K234TM-uhw-Q"
      },
      "outputs": [],
      "source": [
        "#calcular métricas para evaluar el rendimiento del algoritmo\n",
        "accuracy = accuracy_score(y_test, y_pred_ada)\n",
        "recall = recall_score(y_test, y_pred_ada)\n",
        "precision = precision_score(y_test, y_pred_ada)\n",
        "f1 = f1_score(y_test, y_pred_ada)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1-score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua-c6-uYhw-Q"
      },
      "outputs": [],
      "source": [
        "modelo_ada.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99mBgx_ihw-R"
      },
      "outputs": [],
      "source": [
        "modelo_ada.score(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKvXuO45DIxD"
      },
      "outputs": [],
      "source": [
        "# AUROC\n",
        "y_score = modelo_ada.predict_proba(x_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=modelo_ada.classes_[1])\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WadN0Q8kDIxD"
      },
      "outputs": [],
      "source": [
        "auc=roc_auc_score(y_test, y_score)\n",
        "auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI8-yGwFsuUB"
      },
      "source": [
        "**CLASES INVERTIDAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKOYzZI3suUH"
      },
      "outputs": [],
      "source": [
        "y_test_inv = y_test.values\n",
        "y_test_inv = 1 - y_test_inv\n",
        "y_test_inv = pd.Series(y_test_inv)\n",
        "y_pred_ada_inv = 1 - y_pred_ada\n",
        "df_pred_inv = pd.DataFrame({'Actual': y_test_inv.squeeze(), 'Predicted': y_pred_ada_inv.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njgvQBNlsuUH"
      },
      "outputs": [],
      "source": [
        "df_pred.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1_PUsyXsuUH"
      },
      "outputs": [],
      "source": [
        "df_pred_inv.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnu7NYy9suUH"
      },
      "outputs": [],
      "source": [
        "# Calcular métricas al invertir las clases\n",
        "accuracy_inv = accuracy_score(y_test_inv, y_pred_ada_inv)\n",
        "recall_inv = recall_score(y_test_inv, y_pred_ada_inv)\n",
        "precision_inv = precision_score(y_test_inv, y_pred_ada_inv)\n",
        "f1_inv = f1_score(y_test_inv, y_pred_ada_inv)\n",
        "print(\"Accuracy:\", accuracy_inv)\n",
        "print(\"Recall:\", recall_inv)\n",
        "print(\"Precision:\", precision_inv)\n",
        "print(\"F1-score:\", f1_inv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOEaDYFtsuUH"
      },
      "outputs": [],
      "source": [
        "score_inv_result=score_inv_result.append({\"Modelo\":\"AdaBoost\",\"Accuracy\":accuracy_inv, \"Precision\":precision_inv, \"Recall\":recall_inv, \"F1-score\":f1_inv}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDRnhk7Shw-R"
      },
      "source": [
        "**VALIDACIÓN CRUZADA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbkEEXpdhw-R"
      },
      "outputs": [],
      "source": [
        "# El número de folds\n",
        "n_folds = 10\n",
        "\n",
        "# Inicializar listas para almacenar las puntuaciones de las métricas. Nos centramos en las métricas comunes en la literatura\n",
        "acc_sc = []\n",
        "prec_sc = []\n",
        "rcll_sc = []\n",
        "f1_sc = []\n",
        "\n",
        "# Crear los objetos KFold\n",
        "skf = StratifiedKFold(n_splits=n_folds)\n",
        "\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    # Dividir los datos en entrenamiento y prueba\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    cv_ada= AdaBoostClassifier(learning_rate=1.2, n_estimators=200, random_state=42)\n",
        "    cv_ada.fit(X_train, Y_train)\n",
        "\n",
        "    # Realizar las predicciones en el conjunto de prueba\n",
        "    Y_pred = cv_ada.predict(X_test)\n",
        "\n",
        "    # Calcular las métricas\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    recall = recall_score(Y_test, Y_pred)\n",
        "    precision = precision_score(Y_test, Y_pred)\n",
        "    f1 = f1_score(Y_test, Y_pred)\n",
        "\n",
        "    # Agregar las puntuaciones a las listas\n",
        "    acc_sc.append(accuracy)\n",
        "    prec_sc.append(precision)\n",
        "    rcll_sc.append(recall)\n",
        "    f1_sc.append(f1)\n",
        "\n",
        "# Calcular la media de las puntuaciones\n",
        "mean_acc = np.mean(acc_sc)\n",
        "mean_prec = np.mean(prec_sc)\n",
        "mean_rcll = np.mean(rcll_sc)\n",
        "mean_f1 = np.mean(f1_sc)\n",
        "\n",
        "print(f'CV Accuracy: {mean_acc:.4f}')\n",
        "print(f'CV Precision: {mean_prec:.4f}')\n",
        "print(f'CV Recall: {mean_rcll:.4f}')\n",
        "print(f'CV F1-Score: {mean_f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HszxkO5ghw-R"
      },
      "outputs": [],
      "source": [
        "cv_results = cross_validate(ada, X, Y, cv=10, scoring=('accuracy','precision', 'recall','f1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrW_21x_hw-R"
      },
      "outputs": [],
      "source": [
        "sorted(cv_results.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ6frJkDhw-R"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\\n\", cv_results['test_accuracy'], \"\\n Con una media de: \", np.mean(cv_results['test_accuracy']))\n",
        "print(\"Precision:\\n\" , cv_results['test_precision'], \"\\n Con una media de: \", np.mean(cv_results['test_precision']))\n",
        "print(\"Recall:\\n\", cv_results['test_recall'], \"\\n Con una media de: \", np.mean(cv_results['test_recall']))\n",
        "print(\"F1-score:\\n\", cv_results['test_f1'], \"\\n Con una media de: \", np.mean(cv_results['test_f1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJrk-wL7hw-R"
      },
      "outputs": [],
      "source": [
        "score_result=score_result.append({\"Modelo\":\"AdaBoost\",\"Accuracy\":np.mean(cv_results['test_accuracy']), \"Precision\":np.mean(cv_results['test_precision']), \"Recall\":np.mean(cv_results['test_recall']), \"F1-score\":np.mean(cv_results['test_f1'])}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQpEydR7I_fa"
      },
      "source": [
        "### **RUSBoost:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBZ__YjiI_ff"
      },
      "outputs": [],
      "source": [
        "modelo=RUSBoostClassifier(random_state=42)\n",
        "params={'n_estimators':[5,10,25,50,75,100,200], 'learning_rate':[0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,3.0,5.0], 'algorithm':['SAMME','SAMME.R'],'replacement':[False, True]}\n",
        "grid=GridSearchCV(modelo,params,cv=10,scoring='f1',verbose=1)\n",
        "grid.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4TigvceI_ff"
      },
      "outputs": [],
      "source": [
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG8UnzAYI_fg"
      },
      "outputs": [],
      "source": [
        "rus =RUSBoostClassifier(learning_rate=1.6, n_estimators=10, random_state=42, replacement=False, algorithm='SAMME.R')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXUCQxx8I_fk"
      },
      "outputs": [],
      "source": [
        "modelo_rus=rus.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pilpi9ZEI_fk"
      },
      "outputs": [],
      "source": [
        "y_pred_rus = modelo_rus.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_sv7mRDI_fk"
      },
      "source": [
        "**EVALUACIÓN MODELO:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W3Toea5I_fk"
      },
      "outputs": [],
      "source": [
        "#comprobación resultados\n",
        "df_pred = pd.DataFrame({'Actual': y_test.squeeze(), 'Predicted': y_pred_rus.squeeze()})\n",
        "print(df_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwh0lDGSI_fk"
      },
      "outputs": [],
      "source": [
        "# Matriz de confusion\n",
        "cm_rus = confusion_matrix(y_test, y_pred_rus)\n",
        "cm_display = ConfusionMatrixDisplay(cm_rus).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrjaZskBI_fl"
      },
      "outputs": [],
      "source": [
        "#calcular métricas para evaluar el rendimiento del algoritmo\n",
        "accuracy = accuracy_score(y_test, y_pred_rus)\n",
        "recall = recall_score(y_test, y_pred_rus)\n",
        "precision = precision_score(y_test, y_pred_rus)\n",
        "f1 = f1_score(y_test, y_pred_rus)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1-score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35mieIexI_fl"
      },
      "outputs": [],
      "source": [
        "modelo_rus.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uVx_7oCI_fl"
      },
      "outputs": [],
      "source": [
        "modelo_rus.score(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhVyb7ypI_fk"
      },
      "outputs": [],
      "source": [
        "# AUROC\n",
        "y_score = modelo_rus.predict_proba(x_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=modelo_rus.classes_[1])\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNLAUumYI_fl"
      },
      "outputs": [],
      "source": [
        "auc=roc_auc_score(y_test, y_score)\n",
        "auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXcgYbYVxKvR"
      },
      "source": [
        "**CLASES INVERTIDAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7rIrY6OxKvS"
      },
      "outputs": [],
      "source": [
        "y_test_inv = y_test.values\n",
        "y_test_inv = 1 - y_test_inv\n",
        "y_test_inv = pd.Series(y_test_inv)\n",
        "y_pred_rus_inv = 1 - y_pred_rus\n",
        "df_pred_inv = pd.DataFrame({'Actual': y_test_inv.squeeze(), 'Predicted': y_pred_rus_inv.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv8-z56ixKvS"
      },
      "outputs": [],
      "source": [
        "df_pred.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuLGelZhxKvS"
      },
      "outputs": [],
      "source": [
        "df_pred_inv.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5DPrrrtxKvS"
      },
      "outputs": [],
      "source": [
        "# Calcular métricas al invertir las clases\n",
        "accuracy_inv = accuracy_score(y_test_inv, y_pred_rus_inv)\n",
        "recall_inv = recall_score(y_test_inv, y_pred_rus_inv)\n",
        "precision_inv = precision_score(y_test_inv, y_pred_rus_inv)\n",
        "f1_inv = f1_score(y_test_inv, y_pred_rus_inv)\n",
        "print(\"Accuracy:\", accuracy_inv)\n",
        "print(\"Recall:\", recall_inv)\n",
        "print(\"Precision:\", precision_inv)\n",
        "print(\"F1-score:\", f1_inv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_mluNWVxKvS"
      },
      "outputs": [],
      "source": [
        "score_inv_result=score_inv_result.append({\"Modelo\":\"RUSBoost\",\"Accuracy\":accuracy_inv, \"Precision\":precision_inv, \"Recall\":recall_inv, \"F1-score\":f1_inv}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3wKzOKaI_fl"
      },
      "source": [
        "**VALIDACIÓN CRUZADA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpGksiY9I_fl"
      },
      "outputs": [],
      "source": [
        "# El número de folds\n",
        "n_folds = 10\n",
        "\n",
        "# Inicializar listas para almacenar las puntuaciones de las métricas. Nos centramos en las métricas comunes en la literatura\n",
        "acc_sc = []\n",
        "prec_sc = []\n",
        "rcll_sc = []\n",
        "f1_sc = []\n",
        "\n",
        "# Crear los objetos KFold\n",
        "skf = StratifiedKFold(n_splits=n_folds)\n",
        "\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    # Dividir los datos en entrenamiento y prueba\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    cv_rus= RUSBoostClassifier(learning_rate=1.6, n_estimators=10, random_state=42)\n",
        "    cv_rus.fit(X_train, Y_train)\n",
        "\n",
        "    # Realizar las predicciones en el conjunto de prueba\n",
        "    Y_pred = cv_rus.predict(X_test)\n",
        "\n",
        "    # Calcular las métricas\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    recall = recall_score(Y_test, Y_pred)\n",
        "    precision = precision_score(Y_test, Y_pred)\n",
        "    f1 = f1_score(Y_test, Y_pred)\n",
        "\n",
        "    # Agregar las puntuaciones a las listas\n",
        "    acc_sc.append(accuracy)\n",
        "    prec_sc.append(precision)\n",
        "    rcll_sc.append(recall)\n",
        "    f1_sc.append(f1)\n",
        "\n",
        "# Calcular la media de las puntuaciones\n",
        "mean_acc = np.mean(acc_sc)\n",
        "mean_prec = np.mean(prec_sc)\n",
        "mean_rcll = np.mean(rcll_sc)\n",
        "mean_f1 = np.mean(f1_sc)\n",
        "\n",
        "print(f'CV Accuracy: {mean_acc:.4f}')\n",
        "print(f'CV Precision: {mean_prec:.4f}')\n",
        "print(f'CV Recall: {mean_rcll:.4f}')\n",
        "print(f'CV F1-Score: {mean_f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkMK2HoBI_fm"
      },
      "outputs": [],
      "source": [
        "cv_results = cross_validate(rus, X, Y, cv=10, scoring=('accuracy','precision', 'recall','f1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqWIf1l_I_fm"
      },
      "outputs": [],
      "source": [
        "sorted(cv_results.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3txFinrEI_fm"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\\n\", cv_results['test_accuracy'], \"\\n Con una media de: \", np.mean(cv_results['test_accuracy']))\n",
        "print(\"Precision:\\n\" , cv_results['test_precision'], \"\\n Con una media de: \", np.mean(cv_results['test_precision']))\n",
        "print(\"Recall:\\n\", cv_results['test_recall'], \"\\n Con una media de: \", np.mean(cv_results['test_recall']))\n",
        "print(\"F1-score:\\n\", cv_results['test_f1'], \"\\n Con una media de: \", np.mean(cv_results['test_f1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIEmdjPiI_fm"
      },
      "outputs": [],
      "source": [
        "score_result=score_result.append({\"Modelo\":\"RUSBoost\",\"Accuracy\":np.mean(cv_results['test_accuracy']), \"Precision\":np.mean(cv_results['test_precision']), \"Recall\":np.mean(cv_results['test_recall']), \"F1-score\":np.mean(cv_results['test_f1'])}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIJ8JtNcD7fS"
      },
      "source": [
        "# **Instancias comunes:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nQvUYbCiDjN"
      },
      "outputs": [],
      "source": [
        "# Crear un DataFrame con las predicciones de cada modelo y la etiqueta real\n",
        "pred_modelos_df = pd.DataFrame({\n",
        "    'RandomForest': y_pred_rf,\n",
        "    'BalancedRF': y_pred_brf,\n",
        "    'GradientBoost': y_pred_gb,\n",
        "    'AdaBoost': y_pred_ada,\n",
        "    'RUSBoost': y_pred_rus,\n",
        "    'Etiqueta': y_test\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM8VspFSybft"
      },
      "outputs": [],
      "source": [
        "pred_modelos_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrPYA4yK3qew"
      },
      "outputs": [],
      "source": [
        "# Filtrar las instancias que tienen valor 1 en todas las columnas de los modelos\n",
        "filtro_1 = pred_modelos_df[['RandomForest', 'BalancedRF', 'GradientBoost', 'AdaBoost', 'RUSBoost']].all(axis=1)\n",
        "\n",
        "# Filtrar las instancias que tienen valor 0 en todas las columnas de los modelos\n",
        "filtro_0 = (~pred_modelos_df[['RandomForest', 'BalancedRF', 'GradientBoost', 'AdaBoost', 'RUSBoost']].any(axis=1)) & (~filtro_1)\n",
        "\n",
        "# Aplicar los filtros al DataFrame de las predicciones\n",
        "df_comunes = pred_modelos_df[filtro_1 | filtro_0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "impoOrCU5ESa"
      },
      "outputs": [],
      "source": [
        "df_comunes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I9zhe2auOjV"
      },
      "outputs": [],
      "source": [
        "# Filtrar las instancias que son Verdadero Positivo\n",
        "vp_df = pred_modelos_df[(pred_modelos_df['RandomForest'] == 1) & (pred_modelos_df['BalancedRF'] == 1) & (pred_modelos_df['GradientBoost'] == 1) & (pred_modelos_df['AdaBoost'] == 1) & (pred_modelos_df['RUSBoost'] == 1) & (pred_modelos_df['Etiqueta'] == 1)]\n",
        "\n",
        "# Filtrar las instancias que son Verdadero Negativo\n",
        "vn_df = pred_modelos_df[(pred_modelos_df['RandomForest'] == 0) & (pred_modelos_df['BalancedRF'] == 0) & (pred_modelos_df['GradientBoost'] == 0) & (pred_modelos_df['AdaBoost'] == 0) & (pred_modelos_df['RUSBoost'] == 0) & (pred_modelos_df['Etiqueta'] == 0)]\n",
        "\n",
        "# Filtrar las instancias que son Falso Positivo\n",
        "fp_df = pred_modelos_df[(pred_modelos_df['RandomForest'] == 1) & (pred_modelos_df['BalancedRF'] == 1) & (pred_modelos_df['GradientBoost'] == 1) & (pred_modelos_df['AdaBoost'] == 1) & (pred_modelos_df['RUSBoost'] == 1) & (pred_modelos_df['Etiqueta'] == 0)]\n",
        "\n",
        "# Filtrar las instancias que son Falso Negativo\n",
        "fn_df = pred_modelos_df[(pred_modelos_df['RandomForest'] == 0) & (pred_modelos_df['BalancedRF'] == 0) & (pred_modelos_df['GradientBoost'] == 0) & (pred_modelos_df['AdaBoost'] == 0) & (pred_modelos_df['RUSBoost'] == 0) & (pred_modelos_df['Etiqueta'] == 1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37TdZNqCucgA"
      },
      "outputs": [],
      "source": [
        "vp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6WfdLXaue9S"
      },
      "outputs": [],
      "source": [
        "vn_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgynRNmouhKD"
      },
      "outputs": [],
      "source": [
        "fp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_1zaoz7ujUS"
      },
      "outputs": [],
      "source": [
        "fn_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eCCUxfQb5k_"
      },
      "outputs": [],
      "source": [
        "indices_vp = vp_df.index.tolist()\n",
        "indices_vn = vn_df.index.tolist()\n",
        "indices_fp = fp_df.index.tolist()\n",
        "indices_fn = fn_df.index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5VGHHSWdql-"
      },
      "outputs": [],
      "source": [
        "vp_instancias = x_test.loc[indices_vp]\n",
        "vn_instancias = x_test.loc[indices_vn]\n",
        "fp_instancias = x_test.loc[indices_fp]\n",
        "fn_instancias = x_test.loc[indices_fn]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mW6k3ryUKvw"
      },
      "source": [
        "**VALOR DE PREDICCION INSTANCIAS COMUNES:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xiIZLBxf4ZS"
      },
      "outputs": [],
      "source": [
        "# Valor de la predicciones para RandomForest\n",
        "valor_pred_rf_vp = modelo_rf.predict_proba(vp_instancias)\n",
        "valor_pred_rf_vn = modelo_rf.predict_proba(vn_instancias)\n",
        "valor_pred_rf_fp = modelo_rf.predict_proba(fp_instancias)\n",
        "valor_pred_rf_fn = modelo_rf.predict_proba(fn_instancias)\n",
        "\n",
        "proba_rf_vp = valor_pred_rf_vp[:, 1] # selecciona la probabilidad estimada de la clase positiva de los verdaderos positivos\n",
        "proba_rf_vn = valor_pred_rf_vn[:, 0] # selecciona la probabilidad estimada de la clase negativa de los verdaderos negativos\n",
        "proba_rf_fp = valor_pred_rf_fp[:, 1] # selecciona la probabilidad estimada de la clase positiva de los falsos positivos\n",
        "proba_rf_fn = valor_pred_rf_fn[:, 0] # selecciona la probabilidad estimada de la clase negativa de los falsos negativos\n",
        "\n",
        "proba_rf_vp = pd.Series(proba_rf_vp, index=vp_df.index) # transformamos en series de pandas\n",
        "proba_rf_vn = pd.Series(proba_rf_vn, index=vn_df.index)\n",
        "proba_rf_fp = pd.Series(proba_rf_fp, index=fp_df.index)\n",
        "proba_rf_fn = pd.Series(proba_rf_fn, index=fn_df.index)\n",
        "\n",
        "vp_df['RF V.Pred'] = proba_rf_vp # añadir los valores a los dataframe\n",
        "vn_df['RF V.Pred'] = proba_rf_vn\n",
        "fp_df['RF V.Pred'] = proba_rf_fp\n",
        "fn_df['RF V.Pred'] = proba_rf_fn\n",
        "\n",
        "# Valor de la predicciones para BalancedRandomForest\n",
        "valor_pred_brf_vp = modelo_brf.predict_proba(vp_instancias)\n",
        "valor_pred_brf_vn = modelo_brf.predict_proba(vn_instancias)\n",
        "valor_pred_brf_fp = modelo_brf.predict_proba(fp_instancias)\n",
        "valor_pred_brf_fn = modelo_brf.predict_proba(fn_instancias)\n",
        "\n",
        "proba_brf_vp = valor_pred_brf_vp[:, 1]\n",
        "proba_brf_vn = valor_pred_brf_vn[:, 0]\n",
        "proba_brf_fp = valor_pred_brf_fp[:, 1]\n",
        "proba_brf_fn = valor_pred_brf_fn[:, 0]\n",
        "\n",
        "proba_brf_vp = pd.Series(proba_brf_vp, index=vp_df.index)\n",
        "proba_brf_vn = pd.Series(proba_brf_vn, index=vn_df.index)\n",
        "proba_brf_fp = pd.Series(proba_brf_fp, index=fp_df.index)\n",
        "proba_brf_fn = pd.Series(proba_brf_fn, index=fn_df.index)\n",
        "\n",
        "vp_df['BRF V.Pred'] = proba_brf_vp\n",
        "vn_df['BRF V.Pred'] = proba_brf_vn\n",
        "fp_df['BRF V.Pred'] = proba_brf_fp\n",
        "fn_df['BRF V.Pred'] = proba_brf_fn\n",
        "\n",
        "# Valor de la predicciones para GradientBoosting\n",
        "valor_pred_gb_vp = modelo_gb.predict_proba(vp_instancias)\n",
        "valor_pred_gb_vn = modelo_gb.predict_proba(vn_instancias)\n",
        "valor_pred_gb_fp = modelo_gb.predict_proba(fp_instancias)\n",
        "valor_pred_gb_fn = modelo_gb.predict_proba(fn_instancias)\n",
        "\n",
        "proba_gb_vp = valor_pred_gb_vp[:, 1]\n",
        "proba_gb_vn = valor_pred_gb_vn[:, 0]\n",
        "proba_gb_fp = valor_pred_gb_fp[:, 1]\n",
        "proba_gb_fn = valor_pred_gb_fn[:, 0]\n",
        "\n",
        "proba_gb_vp = pd.Series(proba_gb_vp, index=vp_df.index)\n",
        "proba_gb_vn = pd.Series(proba_gb_vn, index=vn_df.index)\n",
        "proba_gb_fp = pd.Series(proba_gb_fp, index=fp_df.index)\n",
        "proba_gb_fn = pd.Series(proba_gb_fn, index=fn_df.index)\n",
        "\n",
        "vp_df['GB V.Pred'] = proba_gb_vp\n",
        "vn_df['GB V.Pred'] = proba_gb_vn\n",
        "fp_df['GB V.Pred'] = proba_gb_fp\n",
        "fn_df['GB V.Pred'] = proba_gb_fn\n",
        "\n",
        "# Valor de la predicciones para AdaBoost\n",
        "valor_pred_ada_vp = modelo_ada.predict_proba(vp_instancias)\n",
        "valor_pred_ada_vn = modelo_ada.predict_proba(vn_instancias)\n",
        "valor_pred_ada_fp = modelo_ada.predict_proba(fp_instancias)\n",
        "valor_pred_ada_fn = modelo_ada.predict_proba(fn_instancias)\n",
        "\n",
        "proba_ada_vp = valor_pred_ada_vp[:, 1]\n",
        "proba_ada_vn = valor_pred_ada_vn[:, 0]\n",
        "proba_ada_fp = valor_pred_ada_fp[:, 1]\n",
        "proba_ada_fn = valor_pred_ada_fn[:, 0]\n",
        "\n",
        "proba_ada_vp = pd.Series(proba_ada_vp, index=vp_df.index)\n",
        "proba_ada_vn = pd.Series(proba_ada_vn, index=vn_df.index)\n",
        "proba_ada_fp = pd.Series(proba_ada_fp, index=fp_df.index)\n",
        "proba_ada_fn = pd.Series(proba_ada_fn, index=fn_df.index)\n",
        "\n",
        "vp_df['AB V.Pred'] = proba_ada_vp\n",
        "vn_df['AB V.Pred'] = proba_ada_vn\n",
        "fp_df['AB V.Pred'] = proba_ada_fp\n",
        "fn_df['AB V.Pred'] = proba_ada_fn\n",
        "\n",
        "# Valor de la predicciones para RUSBoos\n",
        "valor_pred_rus_vp = modelo_rus.predict_proba(vp_instancias)\n",
        "valor_pred_rus_vn = modelo_rus.predict_proba(vn_instancias)\n",
        "valor_pred_rus_fp = modelo_rus.predict_proba(fp_instancias)\n",
        "valor_pred_rus_fn = modelo_rus.predict_proba(fn_instancias)\n",
        "\n",
        "proba_rus_vp = valor_pred_rus_vp[:, 1]\n",
        "proba_rus_vn = valor_pred_rus_vn[:, 0]\n",
        "proba_rus_fp = valor_pred_rus_fp[:, 1]\n",
        "proba_rus_fn = valor_pred_rus_fn[:, 0]\n",
        "\n",
        "proba_rus_vp = pd.Series(proba_rus_vp, index=vp_df.index)\n",
        "proba_rus_vn = pd.Series(proba_rus_vn, index=vn_df.index)\n",
        "proba_rus_fp = pd.Series(proba_rus_fp, index=fp_df.index)\n",
        "proba_rus_fn = pd.Series(proba_rus_fn, index=fn_df.index)\n",
        "\n",
        "vp_df['RB V.Pred'] = proba_rus_vp\n",
        "vn_df['RB V.Pred'] = proba_rus_vn\n",
        "fp_df['RB V.Pred'] = proba_rus_fp\n",
        "fn_df['RB V.Pred'] = proba_rus_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AdAgAIsulXE"
      },
      "outputs": [],
      "source": [
        "# Cálculo de la media para cada instancia del dataframe\n",
        "media_vp = vp_df[['RF V.Pred', 'BRF V.Pred', 'GB V.Pred', 'AB V.Pred', 'RB V.Pred']].mean(axis=1)\n",
        "vp_df['V.Pred media'] = media_vp\n",
        "\n",
        "media_vn = vn_df[['RF V.Pred', 'BRF V.Pred', 'GB V.Pred', 'AB V.Pred', 'RB V.Pred']].mean(axis=1)\n",
        "vn_df['V.Pred media'] = media_vn\n",
        "\n",
        "media_fp = fp_df[['RF V.Pred', 'BRF V.Pred', 'GB V.Pred', 'AB V.Pred', 'RB V.Pred']].mean(axis=1)\n",
        "fp_df['V.Pred media'] = media_fp\n",
        "\n",
        "media_fn = fn_df[['RF V.Pred', 'BRF V.Pred', 'GB V.Pred', 'AB V.Pred', 'RB V.Pred']].mean(axis=1)\n",
        "fn_df['V.Pred media'] = media_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge53b7OdmCmR"
      },
      "outputs": [],
      "source": [
        "vp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0VC12HzvUqm"
      },
      "outputs": [],
      "source": [
        "vn_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuGz0L2MvVrO"
      },
      "outputs": [],
      "source": [
        "fp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xleveYsvWtE"
      },
      "outputs": [],
      "source": [
        "fn_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo8JlmMxwkTQ"
      },
      "outputs": [],
      "source": [
        "# Calcula la instancia con la media máxima\n",
        "instancia_vp_max = vp_df['V.Pred media'].idxmax()\n",
        "instancia_vn_max = vn_df['V.Pred media'].idxmax()\n",
        "instancia_fp_max = fp_df['V.Pred media'].idxmax()\n",
        "instancia_fn_max = fn_df['V.Pred media'].idxmax()\n",
        "\n",
        "# Calcula la instancia con la mediana\n",
        "mediana_vp = vp_df['V.Pred media'].median()\n",
        "mediana_vn = vn_df['V.Pred media'].median()\n",
        "mediana_fp = fp_df['V.Pred media'].median()\n",
        "mediana_fn = fn_df['V.Pred media'].median()\n",
        "\n",
        "instancia_vp_mediana = vp_df.loc[(vp_df['V.Pred media'] - mediana_vp).abs().idxmin()].name\n",
        "instancia_vn_mediana = vn_df.loc[(vn_df['V.Pred media'] - mediana_vn).abs().idxmin()].name\n",
        "instancia_fp_mediana = fp_df.loc[(fp_df['V.Pred media'] - mediana_fp).abs().idxmin()].name\n",
        "instancia_fn_mediana = fn_df.loc[(fn_df['V.Pred media'] - mediana_fn).abs().idxmin()].name\n",
        "\n",
        "# Calcula la instancia con la media mínima\n",
        "instancia_vp_min = vp_df['V.Pred media'].idxmin()\n",
        "instancia_vn_min = vn_df['V.Pred media'].idxmin()\n",
        "instancia_fp_min = fp_df['V.Pred media'].idxmin()\n",
        "instancia_fn_min = fn_df['V.Pred media'].idxmin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61ot8HyjwPHL"
      },
      "outputs": [],
      "source": [
        "# Mostrar las instancias\n",
        "print(\"La instancia verdadero positivo máxima es: \", instancia_vp_max)\n",
        "print(\"La instancia verdadero negativo máxima es: \", instancia_vn_max)\n",
        "print(\"La instancia falso positivo máxima es: \", instancia_fp_max)\n",
        "print(\"La instancia falso negativo máxima es: \", instancia_fn_max)\n",
        "\n",
        "print(\"La instancia verdadero positivo en la mediana es: \", instancia_vp_mediana)\n",
        "print(\"La instancia verdadero negativo en la mediana es: \", instancia_vn_mediana)\n",
        "print(\"La instancia falso positivo en la mediana es: \", instancia_fp_mediana)\n",
        "print(\"La instancia falso negativo en la mediana es: \", instancia_fn_mediana)\n",
        "\n",
        "print(\"La instancia verdadero positivo minima es: \", instancia_vp_min)\n",
        "print(\"La instancia verdadero negativo minima es: \", instancia_vn_min)\n",
        "print(\"La instancia falso positivo minima es: \", instancia_fp_min)\n",
        "print(\"La instancia falso negativo minima es: \", instancia_fn_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL9B4W29Rjrm"
      },
      "outputs": [],
      "source": [
        "# Indices del conjunto de prueba\n",
        "lista_indices = y_test.index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAdzz-nCSVxZ"
      },
      "outputs": [],
      "source": [
        "# Posiciones dentro del ndarray de las predicciones\n",
        "pos_vp_max = lista_indices.index(instancia_vp_max)\n",
        "pos_vp_min = lista_indices.index(instancia_vp_min)\n",
        "pos_vp_mediana = lista_indices.index(instancia_vp_mediana)\n",
        "pos_vn_max = lista_indices.index(instancia_vn_max)\n",
        "pos_vn_min = lista_indices.index(instancia_vn_min)\n",
        "pos_vn_mediana = lista_indices.index(instancia_vn_mediana)\n",
        "pos_fp_max = lista_indices.index(instancia_fp_max)\n",
        "pos_fp_min = lista_indices.index(instancia_fp_min)\n",
        "pos_fp_mediana = lista_indices.index(instancia_fp_mediana)\n",
        "pos_fn_max = lista_indices.index(instancia_fn_max)\n",
        "pos_fn_min = lista_indices.index(instancia_fn_min)\n",
        "pos_fn_mediana = lista_indices.index(instancia_fn_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8hkAwc4DwmC"
      },
      "outputs": [],
      "source": [
        "df_instancia_vp_max = x_test.loc[instancia_vp_max]\n",
        "df_instancia_vp_min = x_test.loc[instancia_vp_min]\n",
        "df_instancia_vp_mediana = x_test.loc[instancia_vp_mediana]\n",
        "df_instancia_vn_max = x_test.loc[instancia_vn_max]\n",
        "df_instancia_vn_min = x_test.loc[instancia_vn_min]\n",
        "df_instancia_vn_mediana = x_test.loc[instancia_vn_mediana]\n",
        "df_instancia_fp_max = x_test.loc[instancia_fp_max]\n",
        "df_instancia_fp_min = x_test.loc[instancia_fp_min]\n",
        "df_instancia_fp_mediana = x_test.loc[instancia_fp_mediana]\n",
        "df_instancia_fn_max = x_test.loc[instancia_fn_max]\n",
        "df_instancia_fn_min = x_test.loc[instancia_fn_min]\n",
        "df_instancia_fn_mediana = x_test.loc[instancia_fn_mediana]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrcvc6bfDwl3"
      },
      "source": [
        "# **Explicabilidad:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF8B-V6VulNY"
      },
      "outputs": [],
      "source": [
        "# Función para evaluar el signo de los valores\n",
        "def evaluar_valor(valor):\n",
        "    if valor >= 0:\n",
        "        return \"Positivo\"\n",
        "    else:\n",
        "        return \"Negativo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Je50o3lulNY"
      },
      "outputs": [],
      "source": [
        "# Crear las columnas del MultiIndex\n",
        "columns_multi = pd.MultiIndex.from_tuples([\n",
        "    ('Breakdown', 'Ranking'), ('Breakdown', 'Signo'),\n",
        "    ('Shapley', 'Ranking'), ('Shapley', 'Signo'),\n",
        "    ('Lime', 'Ranking'), ('Lime', 'Signo')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PasLbuaqDwl4"
      },
      "source": [
        "## **RandomForest:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIVuchpMDwmA"
      },
      "source": [
        "**FEATURE IMPORTANCE**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permu = permutation_importance(modelo_rf, x_test, y_test, n_repeats=20, random_state=42, n_jobs=2, scoring='f1')\n",
        "\n",
        "# Umbral para valores significativos\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Filtrar los caracteristicas\n",
        "significant_indices = permu.importances_mean > importance_threshold\n",
        "permu_importances = pd.Series(permu.importances_mean.round(2), index=feature_names)[significant_indices]\n",
        "permu_std = permu.importances_std[significant_indices]\n",
        "\n",
        "# Crear la representación gráfica\n",
        "fig, ax = plt.subplots()\n",
        "permu_importances.plot.bar(yerr=permu_std, ax=ax)\n",
        "ax.set_title(\"Feature importances using permutation on full model\")\n",
        "ax.set_ylabel(\"Mean accuracy decrease\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bi8_7JmKoDE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = ['precision', 'recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "permu_score = permutation_importance(modelo_rf, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Itera a través de las métricas\n",
        "for i, metric in enumerate(scoring):\n",
        "    permu = permu_score[metric]\n",
        "\n",
        "    # Filtra las características que cumplen la condición del umbral\n",
        "    significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "    sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "    importances_mean = permu.importances_mean[significant_indices]\n",
        "    importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "    # Ordena los datos por importancia de mayor a menor\n",
        "    sorted_indices = np.argsort(importances_mean)[::1]\n",
        "    sorted_feature_names = [sorted_feature_names[j] for j in sorted_indices]\n",
        "    importances_mean = importances_mean[sorted_indices]\n",
        "    importances_std = importances_std[sorted_indices]\n",
        "\n",
        "    # Crea la representación gráfica en el subplot correspondiente\n",
        "    axs[i].barh(range(len(sorted_feature_names)), importances_mean, xerr=importances_std, align='center')\n",
        "    axs[i].set_yticks(range(len(sorted_feature_names)))\n",
        "    axs[i].set_yticklabels(sorted_feature_names)\n",
        "    axs[i].set_xlabel('Valor Importancia')\n",
        "    axs[i].set_title(f'Importancia por Permutación para {metric_names[i]}')\n",
        "\n",
        "# Ajusta los espacios entre subplots y muestra la figura\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9_CB4fm8oyE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4yQ9whZcH8W"
      },
      "outputs": [],
      "source": [
        "scoring = ['precision','recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Crea un diccionario para almacenar los DataFrames\n",
        "results_global_rf = {}\n",
        "\n",
        "permu_score = permutation_importance(modelo_rf, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "for i, metric in enumerate(scoring):\n",
        "  permu = permu_score[metric]\n",
        "\n",
        "  # Filtra las características que cumplen la condición\n",
        "  significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "  sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "  importances_mean = permu.importances_mean[significant_indices]\n",
        "  importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "  # Crear un DataFrame con los resultados\n",
        "  df_exp_global = pd.DataFrame({'Feature': sorted_feature_names,\n",
        "                       'Importance_Mean': importances_mean,\n",
        "                       'Importance_Std': importances_std})\n",
        "\n",
        "  # Ordenar el DataFrame por importance_mean en orden descendente\n",
        "  df_exp_global = df_exp_global.sort_values(by='Importance_Mean', ascending=False)\n",
        "\n",
        "  # Asignar el DataFrame al diccionario con el nombre de la métrica\n",
        "  results_global_rf[f'df_global_{metric_names[i]}'] = df_exp_global"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_rf['df_global_Precision']"
      ],
      "metadata": {
        "id": "dseOV9NIcH8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_rf['df_global_Recall']"
      ],
      "metadata": {
        "id": "5o_rM_gAcH8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_rf['df_global_F1-score']"
      ],
      "metadata": {
        "id": "NVSSXr7IcH8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPdkibX-DwmB"
      },
      "source": [
        "**BREAK-DOWN, SHAP Y LIME:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riKlq1RpDwmB"
      },
      "outputs": [],
      "source": [
        "#primero definimos el explainer\n",
        "exp = dx.Explainer(modelo_rf, x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dbNtuNSV_-i"
      },
      "source": [
        "### **Instancia VP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqjJpPYaDwmC"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"break_down\",random_state=42)\n",
        "shap_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"shap\",random_state=42)\n",
        "lime_vp_max = exp.predict_surrogate(df_instancia_vp_max, random_state=42)\n",
        "\n",
        "breakdown_vp_df_max = breakdown_vp_max.result\n",
        "shap_vp_df_max = shap_vp_max.result\n",
        "lime_vp_df_max=lime_vp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_max.plot()"
      ],
      "metadata": {
        "id": "sxEhNY6A05YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_max.plot()"
      ],
      "metadata": {
        "id": "t_sp2ya803wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGHIDjaZDwmD"
      },
      "outputs": [],
      "source": [
        "lime_vp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ore9kA4fDwmC"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_max = breakdown_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(index=[0, 26])\n",
        "breakdown_vp_df_max['sign'] = breakdown_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_max = shap_vp_df_max.tail(25)\n",
        "shap_vp_df_max['sign'] = shap_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_max = shap_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_max[\"Variable\"] = lime_vp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_max[\"Signo\"] = lime_vp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_max = lime_vp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_max['Ranking'] = breakdown_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_max['Ranking'] = shap_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_max = shap_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_max['Ranking'] = lime_vp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_max = lime_vp_df_max.head(5)\n",
        "lime_vp_df_max = lime_vp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(columns=['contribution'])\n",
        "shap_vp_df_max = shap_vp_df_max.drop(columns=['contribution'])\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.head(5)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.head(5)\n",
        "shap_vp_df_max = shap_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_max = lime_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_max)\n",
        "print(shap_vp_df_max)\n",
        "print(lime_vp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-scdsbFDwmL"
      },
      "outputs": [],
      "source": [
        "#lime_vp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNfTnWz9ulNb"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_max['Variable'])\n",
        "shapley_features = list(shap_vp_df_max['Variable'])\n",
        "lime_features = list(lime_vp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_max[breakdown_vp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_max[shap_vp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_max[lime_vp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"file_added\", \"file_modified\", \"developer_num\", \"line_removed\", \"file_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "GLYFsEKfwNgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh3IAFAYdtOE"
      },
      "source": [
        "### **Instancia VP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRGeoBrGdtOF"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"shap\",random_state=42)\n",
        "lime_vp_mediana = exp.predict_surrogate(df_instancia_vp_mediana, random_state=42)\n",
        "\n",
        "breakdown_vp_df_mediana = breakdown_vp_mediana.result\n",
        "shap_vp_df_mediana = shap_vp_mediana.result\n",
        "lime_vp_df_mediana=lime_vp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "GbcHCDfH1HZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "DIynwOHy1FdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-9Fn-WQdtOF"
      },
      "outputs": [],
      "source": [
        "lime_vp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP6NX5y4dtOF"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vp_df_mediana['sign'] = breakdown_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.tail(25)\n",
        "shap_vp_df_mediana['sign'] = shap_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_mediana[\"Variable\"] = lime_vp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_mediana[\"Signo\"] = lime_vp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_mediana['Ranking'] = breakdown_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_mediana['Ranking'] = shap_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_mediana['Ranking'] = lime_vp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.head(5)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(columns=['contribution'])\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.drop(columns=['contribution'])\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.head(5)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.head(5)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_mediana)\n",
        "print(shap_vp_df_mediana)\n",
        "print(lime_vp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caRy2Kg8dtOG"
      },
      "outputs": [],
      "source": [
        "#lime_vp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBPTtBzCulNc"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vp_df_mediana['Variable'])\n",
        "lime_features = list(lime_vp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_mediana[breakdown_vp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_mediana[shap_vp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_mediana[lime_vp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"file_added\", \"duration\", \"file_modified\", \"file_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "KvvW7227xxPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNG7Exrne4xx"
      },
      "source": [
        "### **Instancia VP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP-24ySge4xx"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"break_down\",random_state=42)\n",
        "shap_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"shap\",random_state=42)\n",
        "lime_vp_min = exp.predict_surrogate(df_instancia_vp_min, random_state=42)\n",
        "\n",
        "breakdown_vp_df_min = breakdown_vp_min.result\n",
        "shap_vp_df_min = shap_vp_min.result\n",
        "lime_vp_df_min = lime_vp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_min.plot()"
      ],
      "metadata": {
        "id": "-m2SnDDD1OD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_min.plot()"
      ],
      "metadata": {
        "id": "2lqprMi51MjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njin1IdTe4xy"
      },
      "outputs": [],
      "source": [
        "lime_vp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_oQBETculNc"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_min = breakdown_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(index=[0, 26])\n",
        "breakdown_vp_df_min['sign'] = breakdown_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_min = shap_vp_df_min.tail(25)\n",
        "shap_vp_df_min['sign'] = shap_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_min = shap_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_min[\"Variable\"] = lime_vp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_min[\"Signo\"] = lime_vp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_min = lime_vp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_min['Ranking'] = breakdown_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_min['Ranking'] = shap_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_min = shap_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_min['Ranking'] = lime_vp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_min = lime_vp_df_min.head(5)\n",
        "lime_vp_df_min = lime_vp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(columns=['contribution'])\n",
        "shap_vp_df_min = shap_vp_df_min.drop(columns=['contribution'])\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.head(5)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.head(5)\n",
        "shap_vp_df_min = shap_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_min = lime_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_min)\n",
        "print(shap_vp_df_min)\n",
        "print(lime_vp_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L5TDj-de4x3"
      },
      "outputs": [],
      "source": [
        "#lime_vp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "675Xv9NhulNd"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_min['Variable'])\n",
        "shapley_features = list(shap_vp_df_min['Variable'])\n",
        "lime_features = list(lime_vp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_min[breakdown_vp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_min[shap_vp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_min[lime_vp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"messages_max\", \"messages_median\", \"line_removed\", \"file_removed\", \"bug_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "ucyZQ0ujx_R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VP General:**"
      ],
      "metadata": {
        "id": "6G2cVaPa26OD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "tiGLvlIu9hTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_rf_vp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_rf_vp"
      ],
      "metadata": {
        "id": "pvtwyW4o9hTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_rf_vp[(\"General\", \"Ranking\")] = df_resumen_rf_vp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_rf_vp[(\"General\", \"Conteo Total\")] = df_resumen_rf_vp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_rf_vp"
      ],
      "metadata": {
        "id": "Fuc182OE9hTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_rf_vp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_rf_vp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_rf_vp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_rf_vp[(\"General\", \"Peso Conteo\")] = df_resumen_rf_vp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_rf_vp[(\"General\", \"Puntaje\")] = df_resumen_rf_vp[(\"General\", \"Peso Rango\")] + df_resumen_rf_vp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_rf_vp[(\"General\", \"Ranking\")] = df_resumen_rf_vp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_rf_vp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rf_vp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rf_vp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_rf_vp"
      ],
      "metadata": {
        "id": "zQ_a-SnA9hTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_rf_vp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_rf_vp = df_resumen_rf_vp[new_columns]"
      ],
      "metadata": {
        "id": "FIVAl_Ho9hTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_rf_vp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_rf_vp[(tech, \"Ranking Medio\")] = df_resumen_rf_vp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_rf_vp"
      ],
      "metadata": {
        "id": "f2G63ssk9hTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p9GAhdwgA-b"
      },
      "source": [
        "### **Instancia VN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHuC0uEGgA-c"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"break_down\",random_state=42)\n",
        "shap_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"shap\",random_state=42)\n",
        "lime_vn_max = exp.predict_surrogate(df_instancia_vn_max, random_state=42)\n",
        "\n",
        "breakdown_vn_df_max = breakdown_vn_max.result\n",
        "shap_vn_df_max = shap_vn_max.result\n",
        "lime_vn_df_max = lime_vn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_max.plot()"
      ],
      "metadata": {
        "id": "NYYCufvv1VKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_max.plot()"
      ],
      "metadata": {
        "id": "sEF-x7A_1Tkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHrOXT2fgA-d"
      },
      "outputs": [],
      "source": [
        "lime_vn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y889tuBulNd"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_max = breakdown_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(index=[0, 26])\n",
        "breakdown_vn_df_max['sign'] = breakdown_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_max = shap_vn_df_max.tail(25)\n",
        "shap_vn_df_max['sign'] = shap_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_max = shap_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_max[\"Variable\"] = lime_vn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_max[\"Signo\"] = lime_vn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_max = lime_vn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_max['Ranking'] = breakdown_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_max['Ranking'] = shap_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_max = shap_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_max['Ranking'] = lime_vn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_max = lime_vn_df_max.head(5)\n",
        "lime_vn_df_max = lime_vn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(columns=['contribution'])\n",
        "shap_vn_df_max = shap_vn_df_max.drop(columns=['contribution'])\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.head(5)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.head(5)\n",
        "shap_vn_df_max = shap_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_max = lime_vn_df_max.reset_index(drop=True)\n",
        "lime_vn_df_max.at[1, 'Variable'] = 'commit_num'\n",
        "lime_vn_df_max.at[3, 'Variable'] = 'file_added'\n",
        "\n",
        "print(breakdown_vn_df_max)\n",
        "print(shap_vn_df_max)\n",
        "print(lime_vn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YeIEtZzgA-e"
      },
      "outputs": [],
      "source": [
        "#lime_vn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCrXuyzJulNe"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_max['Variable'])\n",
        "shapley_features = list(shap_vn_df_max['Variable'])\n",
        "lime_features = list(lime_vn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_max[breakdown_vn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_max[shap_vn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_max[lime_vn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"commit_num\", \"parallel_changed_file_num\", \"duration\", \"file_added\", \"line_added\", \"developer_num\", \"file_removed\", \"bug_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "pcFIt1FJyW4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gngij3M6gA-e"
      },
      "source": [
        "### **Instancia VN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAB-Tm-LgA-e"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"shap\",random_state=42)\n",
        "lime_vn_mediana = exp.predict_surrogate(df_instancia_vn_mediana, random_state=42)\n",
        "\n",
        "breakdown_vn_df_mediana = breakdown_vn_mediana.result\n",
        "shap_vn_df_mediana = shap_vn_mediana.result\n",
        "lime_vn_df_mediana = lime_vn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "tMBpWAsh1ZvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "j15DvB0K1Zkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNOgdjNogA-f"
      },
      "outputs": [],
      "source": [
        "lime_vn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaoR1pQqulNe"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vn_df_mediana['sign'] = breakdown_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.tail(25)\n",
        "shap_vn_df_mediana['sign'] = shap_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_mediana[\"Variable\"] = lime_vn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_mediana[\"Signo\"] = lime_vn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_mediana['Ranking'] = breakdown_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_mediana['Ranking'] = shap_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_mediana['Ranking'] = lime_vn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.head(5)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(columns=['contribution'])\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.drop(columns=['contribution'])\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.head(5)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.head(5)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.reset_index(drop=True)\n",
        "lime_vn_df_mediana.at[2, 'Variable'] = 'developer_num'\n",
        "lime_vn_df_mediana.at[3, 'Variable'] = 'file_added'\n",
        "\n",
        "print(breakdown_vn_df_mediana)\n",
        "print(shap_vn_df_mediana)\n",
        "print(lime_vn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKk0sVA6gA-g",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#lime_vn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNs6ID8PulNf"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vn_df_mediana['Variable'])\n",
        "lime_features = list(lime_vn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_mediana[breakdown_vn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_mediana[shap_vn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_mediana[lime_vn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"file_removed\", \"messages_median\", \"file_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "0UPjCwr5yZAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpxTxWg6gA-g"
      },
      "source": [
        "### **Instancia VN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93EQOsIbgA-h"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"break_down\",random_state=42)\n",
        "shap_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"shap\",random_state=42)\n",
        "lime_vn_min = exp.predict_surrogate(df_instancia_vn_min, random_state=42)\n",
        "\n",
        "breakdown_vn_df_min = breakdown_vn_min.result\n",
        "shap_vn_df_min = shap_vn_min.result\n",
        "lime_vn_df_min = lime_vn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_min.plot()"
      ],
      "metadata": {
        "id": "VU_01ZTX1g-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_min.plot()"
      ],
      "metadata": {
        "id": "MjSIhMVI1iRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLRj4zNZgA-h"
      },
      "outputs": [],
      "source": [
        "lime_vn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSeYqsklulNf"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_min = breakdown_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(index=[0, 26])\n",
        "breakdown_vn_df_min['sign'] = breakdown_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_min = shap_vn_df_min.tail(25)\n",
        "shap_vn_df_min['sign'] = shap_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_min = shap_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_min[\"Variable\"] = lime_vn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_min[\"Signo\"] = lime_vn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_min = lime_vn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_min['Ranking'] = breakdown_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_min['Ranking'] = shap_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_min = shap_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_min['Ranking'] = lime_vn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_min = lime_vn_df_min.head(5)\n",
        "lime_vn_df_min = lime_vn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(columns=['contribution'])\n",
        "shap_vn_df_min = shap_vn_df_min.drop(columns=['contribution'])\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.head(5)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.head(5)\n",
        "shap_vn_df_min = shap_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_min = lime_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vn_df_min)\n",
        "print(shap_vn_df_min)\n",
        "print(lime_vn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDb58N80gA-i"
      },
      "outputs": [],
      "source": [
        "#lime_vn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oT3wohDulNf"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_min['Variable'])\n",
        "shapley_features = list(shap_vn_df_min['Variable'])\n",
        "lime_features = list(lime_vn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_min[breakdown_vn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_min[shap_vn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_min[lime_vn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"messages_min\", \"line_added\", \"file_modified\", \"messages_max\", \"file_removed\", \"file_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "9sB4uNPsyeI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VN General:**"
      ],
      "metadata": {
        "id": "tZfhDSHtGC7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "cj5z9WOHGC7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_rf_vn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_rf_vn"
      ],
      "metadata": {
        "id": "a4Et1xtLGC7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_rf_vn[(\"General\", \"Ranking\")] = df_resumen_rf_vn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_rf_vn[(\"General\", \"Conteo Total\")] = df_resumen_rf_vn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_rf_vn"
      ],
      "metadata": {
        "id": "HxUVJ_OUGC7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_rf_vn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_rf_vn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_rf_vn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_rf_vn[(\"General\", \"Peso Conteo\")] = df_resumen_rf_vn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_rf_vn[(\"General\", \"Puntaje\")] = df_resumen_rf_vn[(\"General\", \"Peso Rango\")] + df_resumen_rf_vn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_rf_vn[(\"General\", \"Ranking\")] = df_resumen_rf_vn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_rf_vn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rf_vn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rf_vn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_rf_vn"
      ],
      "metadata": {
        "id": "vkabMp1pGC7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_rf_vn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_rf_vn = df_resumen_rf_vn[new_columns]"
      ],
      "metadata": {
        "id": "dlS5oqlcGC7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_rf_vn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_rf_vn[(tech, \"Ranking Medio\")] = df_resumen_rf_vn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_rf_vn"
      ],
      "metadata": {
        "id": "sHi37TB4GC7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHI3Mi6z6ruP"
      },
      "source": [
        "### **Instancia FP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Bu8Yvd46ruQ"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"break_down\",random_state=42)\n",
        "shap_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"shap\",random_state=42)\n",
        "lime_fp_max = exp.predict_surrogate(df_instancia_fp_max, random_state=42)\n",
        "\n",
        "breakdown_fp_df_max = breakdown_fp_max.result\n",
        "shap_fp_df_max = shap_fp_max.result\n",
        "lime_fp_df_max=lime_fp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_max.plot()"
      ],
      "metadata": {
        "id": "o187ly3T1ljq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_max.plot()"
      ],
      "metadata": {
        "id": "VRlRRVUZ1myh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvkTZTZ36ruQ"
      },
      "outputs": [],
      "source": [
        "lime_fp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHDx6X8vulNg"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_max = breakdown_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(index=[0, 26])\n",
        "breakdown_fp_df_max['sign'] = breakdown_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_max = shap_fp_df_max.tail(25)\n",
        "shap_fp_df_max['sign'] = shap_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_max = shap_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_max[\"Variable\"] = lime_fp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_max[\"Signo\"] = lime_fp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_max = lime_fp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_max['Ranking'] = breakdown_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_max['Ranking'] = shap_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_max = shap_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_max['Ranking'] = lime_fp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_max = lime_fp_df_max.head(5)\n",
        "lime_fp_df_max = lime_fp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(columns=['contribution'])\n",
        "shap_fp_df_max = shap_fp_df_max.drop(columns=['contribution'])\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.head(5)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.head(5)\n",
        "shap_fp_df_max = shap_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_max = lime_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_max)\n",
        "print(shap_fp_df_max)\n",
        "print(lime_fp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz0ipJ8c6ruV"
      },
      "outputs": [],
      "source": [
        "#lime_fp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QICow4CeulNg"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_max['Variable'])\n",
        "shapley_features = list(shap_fp_df_max['Variable'])\n",
        "lime_features = list(lime_fp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_max[breakdown_fp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_max[shap_fp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_max[lime_fp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"file_added\", \"developer_num\", \"file_modified\", \"line_removed\", \"file_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "1OI-rw23yoKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8nRnNzJ6ruV"
      },
      "source": [
        "### **Instancia FP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Adbw77l6ruV"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"shap\",random_state=42)\n",
        "lime_fp_mediana = exp.predict_surrogate(df_instancia_fp_mediana, random_state=42)\n",
        "\n",
        "breakdown_fp_df_mediana = breakdown_fp_mediana.result\n",
        "shap_fp_df_mediana = shap_fp_mediana.result\n",
        "lime_fp_df_mediana=lime_fp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "QyfqKS561qMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "1jcQAOo41qCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQM2MBAs6ruW"
      },
      "outputs": [],
      "source": [
        "lime_fp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3zksKe1ulNh"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fp_df_mediana['sign'] = breakdown_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.tail(25)\n",
        "shap_fp_df_mediana['sign'] = shap_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_mediana[\"Variable\"] = lime_fp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_mediana[\"Signo\"] = lime_fp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_mediana['Ranking'] = breakdown_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_mediana['Ranking'] = shap_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_mediana['Ranking'] = lime_fp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.head(5)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(columns=['contribution'])\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.drop(columns=['contribution'])\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.head(5)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.head(5)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_mediana)\n",
        "print(shap_fp_df_mediana)\n",
        "print(lime_fp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-xKaA8L6ruX"
      },
      "outputs": [],
      "source": [
        "#lime_fp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gLKRpTpulNh"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fp_df_mediana['Variable'])\n",
        "lime_features = list(lime_fp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_mediana[breakdown_fp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_mediana[shap_fp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_mediana[lime_fp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"file_removed\", \"line_removed\",  \"file_added\", \"bug_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "_FSwWZTdysIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auy_UbJq6ruX"
      },
      "source": [
        "### **Instancia FP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy1UWvnH6ruX"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"break_down\",random_state=42)\n",
        "shap_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"shap\",random_state=42)\n",
        "lime_fp_min = exp.predict_surrogate(df_instancia_fp_min, random_state=42)\n",
        "\n",
        "breakdown_fp_df_min = breakdown_fp_min.result\n",
        "shap_fp_df_min = shap_fp_min.result\n",
        "lime_fp_df_min = lime_fp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_min.plot()"
      ],
      "metadata": {
        "id": "tKJNsFiM1xy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_min.plot()"
      ],
      "metadata": {
        "id": "DYjCS_cI10Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J4QjZ6F6ruY"
      },
      "outputs": [],
      "source": [
        "lime_fp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S40ADuBtulNi"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_min = breakdown_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(index=[0, 26])\n",
        "breakdown_fp_df_min['sign'] = breakdown_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_min = shap_fp_df_min.tail(25)\n",
        "shap_fp_df_min['sign'] = shap_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_min = shap_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_min[\"Variable\"] = lime_fp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_min[\"Signo\"] = lime_fp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_min = lime_fp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_min['Ranking'] = breakdown_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_min['Ranking'] = shap_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_min = shap_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_min['Ranking'] = lime_fp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_min = lime_fp_df_min.head(5)\n",
        "lime_fp_df_min = lime_fp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(columns=['contribution'])\n",
        "shap_fp_df_min = shap_fp_df_min.drop(columns=['contribution'])\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.head(5)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.head(5)\n",
        "shap_fp_df_min = shap_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_min = lime_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_min)\n",
        "print(shap_fp_df_min)\n",
        "print(lime_fp_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44gAS31Q6ruZ"
      },
      "outputs": [],
      "source": [
        "#lime_fp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INO_xyr6ulNi"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_min['Variable'])\n",
        "shapley_features = list(shap_fp_df_min['Variable'])\n",
        "lime_features = list(lime_fp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_min[breakdown_fp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_min[shap_fp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_min[lime_fp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"file_modified\",  \"file_removed\", \"file_added\", \"line_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "-CwV98kOyxhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FP General:**"
      ],
      "metadata": {
        "id": "lwUCG7iCIM18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "Q8kOvTqbIM19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_rf_fp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_rf_fp"
      ],
      "metadata": {
        "id": "5kwXYp-nIM19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_rf_fp[(\"General\", \"Ranking\")] = df_resumen_rf_fp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_rf_fp[(\"General\", \"Conteo Total\")] = df_resumen_rf_fp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_rf_fp"
      ],
      "metadata": {
        "id": "olz7y0KQIM19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_rf_fp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_rf_fp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_rf_fp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_rf_fp[(\"General\", \"Peso Conteo\")] = df_resumen_rf_fp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_rf_fp[(\"General\", \"Puntaje\")] = df_resumen_rf_fp[(\"General\", \"Peso Rango\")] + df_resumen_rf_fp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_rf_fp[(\"General\", \"Ranking\")] = df_resumen_rf_fp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_rf_fp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rf_fp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rf_fp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_rf_fp"
      ],
      "metadata": {
        "id": "5H3JS2jzIM19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_rf_fp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_rf_fp = df_resumen_rf_fp[new_columns]"
      ],
      "metadata": {
        "id": "1rmw7HGQIM1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_rf_fp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_rf_fp[(tech, \"Ranking Medio\")] = df_resumen_rf_fp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_rf_fp"
      ],
      "metadata": {
        "id": "sMFlGteTIM1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lioYyZ0c8ylZ"
      },
      "source": [
        "### **Instancia FN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYs0JPIa8ylZ"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"break_down\",random_state=42)\n",
        "shap_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"shap\",random_state=42)\n",
        "lime_fn_max = exp.predict_surrogate(df_instancia_fn_max, random_state=42)\n",
        "\n",
        "breakdown_fn_df_max = breakdown_fn_max.result\n",
        "shap_fn_df_max = shap_fn_max.result\n",
        "lime_fn_df_max=lime_fn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_max.plot()"
      ],
      "metadata": {
        "id": "xjENtU7y15NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_max.plot()"
      ],
      "metadata": {
        "id": "ru9CVt9515GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCn72NXN8ylZ"
      },
      "outputs": [],
      "source": [
        "lime_fn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BC0Bl99ulNj"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_max = breakdown_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(index=[0, 26])\n",
        "breakdown_fn_df_max['sign'] = breakdown_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_max = shap_fn_df_max.tail(25)\n",
        "shap_fn_df_max['sign'] = shap_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_max = shap_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_max[\"Variable\"] = lime_fn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_max[\"Signo\"] = lime_fn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_max = lime_fn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_max['Ranking'] = breakdown_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_max['Ranking'] = shap_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_max = shap_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_max['Ranking'] = lime_fn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_max = lime_fn_df_max.head(5)\n",
        "lime_fn_df_max = lime_fn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(columns=['contribution'])\n",
        "shap_fn_df_max = shap_fn_df_max.drop(columns=['contribution'])\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.head(5)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.head(5)\n",
        "shap_fn_df_max = shap_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_max = lime_fn_df_max.reset_index(drop=True)\n",
        "lime_fn_df_max.at[2, 'Variable'] = 'developer_num'\n",
        "lime_fn_df_max.at[3, 'Variable'] = 'file_added'\n",
        "\n",
        "print(breakdown_fn_df_max)\n",
        "print(shap_fn_df_max)\n",
        "print(lime_fn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kH7m7G08ylb"
      },
      "outputs": [],
      "source": [
        "#lime_fn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju8UC2QdulNj"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_max['Variable'])\n",
        "shapley_features = list(shap_fn_df_max['Variable'])\n",
        "lime_features = list(lime_fn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_max[breakdown_fn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_max[shap_fn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_max[lime_fn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"file_modified\", \"duration\", \"file_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "PtuCfiwPy3f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yro8rb9M8ylb"
      },
      "source": [
        "### **Instancia FN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOTRcTDj8ylb"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"shap\",random_state=42)\n",
        "lime_fn_mediana = exp.predict_surrogate(df_instancia_fn_mediana, random_state=42)\n",
        "\n",
        "breakdown_fn_df_mediana = breakdown_fn_mediana.result\n",
        "shap_fn_df_mediana = shap_fn_mediana.result\n",
        "lime_fn_df_mediana=lime_fn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "8Xrlv7xI19Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "vpGr94ir19Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPq8yMlo8ylb"
      },
      "outputs": [],
      "source": [
        "lime_fn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83ItZ7AyulNk"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fn_df_mediana['sign'] = breakdown_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.tail(25)\n",
        "shap_fn_df_mediana['sign'] = shap_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_mediana[\"Variable\"] = lime_fn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_mediana[\"Signo\"] = lime_fn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_mediana['Ranking'] = breakdown_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_mediana['Ranking'] = shap_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_mediana['Ranking'] = lime_fn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.head(5)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(columns=['contribution'])\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.drop(columns=['contribution'])\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.head(5)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.head(5)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fn_df_mediana)\n",
        "print(shap_fn_df_mediana)\n",
        "print(lime_fn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5FyYjB68ylf"
      },
      "outputs": [],
      "source": [
        "#lime_fn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ_JI_IBulNl"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fn_df_mediana['Variable'])\n",
        "lime_features = list(lime_fn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_mediana[breakdown_fn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_mediana[shap_fn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_mediana[lime_fn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"duration\", \"line_added\", \"line_removed\", \"file_modified\",  \"file_removed\", \"file_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "eAIemvSny673"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRX6DXpJ8ylf"
      },
      "source": [
        "### **Instancia FN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubV9LdoB8ylf"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"break_down\",random_state=42)\n",
        "shap_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"shap\",random_state=42)\n",
        "lime_fn_min = exp.predict_surrogate(df_instancia_fn_min, random_state=42)\n",
        "\n",
        "breakdown_fn_df_min = breakdown_fn_min.result\n",
        "shap_fn_df_min = shap_fn_min.result\n",
        "lime_fn_df_min = lime_fn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_min.plot()"
      ],
      "metadata": {
        "id": "HMbWnQw22COY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_min.plot()"
      ],
      "metadata": {
        "id": "hdcSpQet2DXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67-N4IdN8ylg"
      },
      "outputs": [],
      "source": [
        "lime_fn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwvWrOqlulNl"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_min = breakdown_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(index=[0, 26])\n",
        "breakdown_fn_df_min['sign'] = breakdown_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_min = shap_fn_df_min.tail(25)\n",
        "shap_fn_df_min['sign'] = shap_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_min = shap_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_min[\"Variable\"] = lime_fn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_min[\"Signo\"] = lime_fn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_min = lime_fn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_min['Ranking'] = breakdown_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_min['Ranking'] = shap_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_min = shap_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_min['Ranking'] = lime_fn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_min = lime_fn_df_min.head(5)\n",
        "lime_fn_df_min = lime_fn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(columns=['contribution'])\n",
        "shap_fn_df_min = shap_fn_df_min.drop(columns=['contribution'])\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.head(5)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.head(5)\n",
        "shap_fn_df_min = shap_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_min = lime_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fn_df_min)\n",
        "print(shap_fn_df_min)\n",
        "print(lime_fn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TahiFikQ8ylh"
      },
      "outputs": [],
      "source": [
        "#lime_fn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Is1DD7RulNm"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_min['Variable'])\n",
        "shapley_features = list(shap_fn_df_min['Variable'])\n",
        "lime_features = list(lime_fn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_min[breakdown_fn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_min[shap_fn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_min[lime_fn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"file_modified\",  \"file_added\", \"duration\", \"file_removed\", \"bug_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "JeH8TzsWzAQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FN General:**"
      ],
      "metadata": {
        "id": "SoY4UZxoP0mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "zjDeKKCdP0mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_rf_fn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_rf_fn"
      ],
      "metadata": {
        "id": "LkBx2vzTP0mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_rf_fn[(\"General\", \"Ranking\")] = df_resumen_rf_fn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_rf_fn[(\"General\", \"Conteo Total\")] = df_resumen_rf_fn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_rf_fn"
      ],
      "metadata": {
        "id": "KJV0O4wbP0mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_rf_fn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_rf_fn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_rf_fn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_rf_fn[(\"General\", \"Peso Conteo\")] = df_resumen_rf_fn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_rf_fn[(\"General\", \"Puntaje\")] = df_resumen_rf_fn[(\"General\", \"Peso Rango\")] + df_resumen_rf_fn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_rf_fn[(\"General\", \"Ranking\")] = df_resumen_rf_fn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_rf_fn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rf_fn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rf_fn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_rf_fn"
      ],
      "metadata": {
        "id": "pk1lNMcyP0mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_rf_fn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_rf_fn = df_resumen_rf_fn[new_columns]"
      ],
      "metadata": {
        "id": "OzC-UcmsP0mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_rf_fn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_rf_fn[(tech, \"Ranking Medio\")] = df_resumen_rf_fn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_rf_fn"
      ],
      "metadata": {
        "id": "om9MAs1PP0mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSoFnM-wXNGT"
      },
      "source": [
        "## **BalancedRandomForest:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhUXNSbNXNGd"
      },
      "source": [
        "**FEATURE IMPORTANCE**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permu = permutation_importance(modelo_brf, x_test, y_test, n_repeats=20, random_state=42, n_jobs=2, scoring='f1')\n",
        "\n",
        "# Umbral para valores significativos\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Filtrar los caracteristicas\n",
        "significant_indices = permu.importances_mean > importance_threshold\n",
        "permu_importances = pd.Series(permu.importances_mean.round(3), index=feature_names)[significant_indices]\n",
        "permu_std = permu.importances_std[significant_indices]\n",
        "\n",
        "# Crear la representación gráfica\n",
        "fig, ax = plt.subplots()\n",
        "permu_importances.plot.bar(yerr=permu_std, ax=ax)\n",
        "ax.set_title(\"Feature importances using permutation on full model\")\n",
        "ax.set_ylabel(\"Mean accuracy decrease\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NSlzTAj61veU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = ['precision', 'recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "permu_score = permutation_importance(modelo_brf, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Itera a través de las métricas\n",
        "for i, metric in enumerate(scoring):\n",
        "    permu = permu_score[metric]\n",
        "\n",
        "    # Filtra las características que cumplen la condición del umbral\n",
        "    significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "    sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "    importances_mean = permu.importances_mean[significant_indices]\n",
        "    importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "    # Ordena los datos por importancia de mayor a menor\n",
        "    sorted_indices = np.argsort(importances_mean)[::1]\n",
        "    sorted_feature_names = [sorted_feature_names[j] for j in sorted_indices]\n",
        "    importances_mean = importances_mean[sorted_indices]\n",
        "    importances_std = importances_std[sorted_indices]\n",
        "\n",
        "    # Crea la representación gráfica en el subplot correspondiente\n",
        "    axs[i].barh(range(len(sorted_feature_names)), importances_mean, xerr=importances_std, align='center')\n",
        "    axs[i].set_yticks(range(len(sorted_feature_names)))\n",
        "    axs[i].set_yticklabels(sorted_feature_names)\n",
        "    axs[i].set_xlabel('Valor Importancia')\n",
        "    axs[i].set_title(f'Importancia por Permutación para {metric_names[i]}')\n",
        "\n",
        "# Ajusta los espacios entre subplots y muestra la figura\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xDyC8f9Z1veV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DvPVGrq1veW"
      },
      "outputs": [],
      "source": [
        "scoring = ['precision','recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Crea un diccionario para almacenar los DataFrames\n",
        "results_global_brf = {}\n",
        "\n",
        "permu_score = permutation_importance(modelo_brf, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "for i, metric in enumerate(scoring):\n",
        "  permu = permu_score[metric]\n",
        "\n",
        "  # Filtra las características que cumplen la condición\n",
        "  significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "  sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "  importances_mean = permu.importances_mean[significant_indices]\n",
        "  importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "  # Crear un DataFrame con los resultados\n",
        "  df_exp_global = pd.DataFrame({'Feature': sorted_feature_names,\n",
        "                       'Importance_Mean': importances_mean,\n",
        "                       'Importance_Std': importances_std})\n",
        "\n",
        "  # Ordenar el DataFrame por importance_mean en orden descendente\n",
        "  df_exp_global = df_exp_global.sort_values(by='Importance_Mean', ascending=False)\n",
        "\n",
        "  # Asignar el DataFrame al diccionario con el nombre de la métrica\n",
        "  results_global_brf[f'df_global_{metric_names[i]}'] = df_exp_global"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_brf['df_global_Precision']"
      ],
      "metadata": {
        "id": "AYtPqOrn1veW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_brf['df_global_Recall']"
      ],
      "metadata": {
        "id": "qCn30IVx1veW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_brf['df_global_F1-score']"
      ],
      "metadata": {
        "id": "IlORyPC91veX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCzI-avpXNGe"
      },
      "source": [
        "**BREAK-DOWN, SHAP Y LIME:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl3Bp3edYFdC"
      },
      "outputs": [],
      "source": [
        "#primero definimos el explainer\n",
        "exp = dx.Explainer(modelo_brf, x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUCyls_t2mav"
      },
      "source": [
        "### **Instancia VP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXM4peOX2maw"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"break_down\",random_state=42)\n",
        "shap_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"shap\",random_state=42)\n",
        "lime_vp_max = exp.predict_surrogate(df_instancia_vp_max, random_state=42)\n",
        "\n",
        "breakdown_vp_df_max = breakdown_vp_max.result\n",
        "shap_vp_df_max = shap_vp_max.result\n",
        "lime_vp_df_max=lime_vp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_max.plot()"
      ],
      "metadata": {
        "id": "q2IpEJWM2maw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_max.plot()"
      ],
      "metadata": {
        "id": "ZqGEhfrI2maw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr-q82202maw"
      },
      "outputs": [],
      "source": [
        "lime_vp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ECb3HaL2maw"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_max = breakdown_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(index=[0, 26])\n",
        "breakdown_vp_df_max['sign'] = breakdown_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_max = shap_vp_df_max.tail(25)\n",
        "shap_vp_df_max['sign'] = shap_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_max = shap_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_max[\"Variable\"] = lime_vp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_max[\"Signo\"] = lime_vp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_max = lime_vp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_max['Ranking'] = breakdown_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_max['Ranking'] = shap_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_max = shap_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_max['Ranking'] = lime_vp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_max = lime_vp_df_max.head(5)\n",
        "lime_vp_df_max = lime_vp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(columns=['contribution'])\n",
        "shap_vp_df_max = shap_vp_df_max.drop(columns=['contribution'])\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.head(5)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.head(5)\n",
        "shap_vp_df_max = shap_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_max = lime_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_max)\n",
        "print(shap_vp_df_max)\n",
        "print(lime_vp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY9jemDI2max"
      },
      "outputs": [],
      "source": [
        "#lime_vp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB_f8bqM2max"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_max['Variable'])\n",
        "shapley_features = list(shap_vp_df_max['Variable'])\n",
        "lime_features = list(lime_vp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_max[breakdown_vp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_max[shap_vp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_max[lime_vp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"line_removed\", \"line_added\", \"file_modified\", \"duration\", \"file_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "dlwUyrSdFhBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snOtit5n2max"
      },
      "source": [
        "### **Instancia VP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3BYowqo2max"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"shap\",random_state=42)\n",
        "lime_vp_mediana = exp.predict_surrogate(df_instancia_vp_mediana, random_state=42)\n",
        "\n",
        "breakdown_vp_df_mediana = breakdown_vp_mediana.result\n",
        "shap_vp_df_mediana = shap_vp_mediana.result\n",
        "lime_vp_df_mediana=lime_vp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "-k-Wl6De2max"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "5gFCNPce2max"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O53lZFXb2max"
      },
      "outputs": [],
      "source": [
        "lime_vp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oafa9jxE2may"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vp_df_mediana['sign'] = breakdown_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.tail(25)\n",
        "shap_vp_df_mediana['sign'] = shap_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_mediana[\"Variable\"] = lime_vp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_mediana[\"Signo\"] = lime_vp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_mediana['Ranking'] = breakdown_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_mediana['Ranking'] = shap_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_mediana['Ranking'] = lime_vp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.head(5)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(columns=['contribution'])\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.drop(columns=['contribution'])\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.head(5)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.head(5)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_mediana)\n",
        "print(shap_vp_df_mediana)\n",
        "print(lime_vp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-7XK-G82may"
      },
      "outputs": [],
      "source": [
        "#lime_vp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibm5fyNU2may"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vp_df_mediana['Variable'])\n",
        "lime_features = list(lime_vp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_mediana[breakdown_vp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_mediana[shap_vp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_mediana[lime_vp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"file_added\", \"messages_min\", \"delete_frequency\", \"file_removed\", \"file_modified\", \"duration\", \"developer_num\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "D9MH5IKyFnMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOPtrcs72may"
      },
      "source": [
        "### **Instancia VP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gf7rIpdL2may"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"break_down\",random_state=42)\n",
        "shap_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"shap\",random_state=42)\n",
        "lime_vp_min = exp.predict_surrogate(df_instancia_vp_min, random_state=42)\n",
        "\n",
        "breakdown_vp_df_min = breakdown_vp_min.result\n",
        "shap_vp_df_min = shap_vp_min.result\n",
        "lime_vp_df_min = lime_vp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_min.plot()"
      ],
      "metadata": {
        "id": "ax5v-Hbb2may"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_min.plot()"
      ],
      "metadata": {
        "id": "ZwDr2hsg2may"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9vSfb0j2maz"
      },
      "outputs": [],
      "source": [
        "lime_vp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l5FPP0D2maz"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_min = breakdown_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(index=[0, 26])\n",
        "breakdown_vp_df_min['sign'] = breakdown_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_min = shap_vp_df_min.tail(25)\n",
        "shap_vp_df_min['sign'] = shap_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_min = shap_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_min[\"Variable\"] = lime_vp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_min[\"Signo\"] = lime_vp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_min = lime_vp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_min['Ranking'] = breakdown_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_min['Ranking'] = shap_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_min = shap_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_min['Ranking'] = lime_vp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_min = lime_vp_df_min.head(5)\n",
        "lime_vp_df_min = lime_vp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(columns=['contribution'])\n",
        "shap_vp_df_min = shap_vp_df_min.drop(columns=['contribution'])\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.head(5)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.head(5)\n",
        "shap_vp_df_min = shap_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_min = lime_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_min)\n",
        "print(shap_vp_df_min)\n",
        "print(lime_vp_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVT2f_zE2maz"
      },
      "outputs": [],
      "source": [
        "#lime_vp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW1VM-O92maz"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_min['Variable'])\n",
        "shapley_features = list(shap_vp_df_min['Variable'])\n",
        "lime_features = list(lime_vp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_min[breakdown_vp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_min[shap_vp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_min[lime_vp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"file_modified\", \"commit_num\", \"file_added\", \"add_frequency\", \"developer_num\", \"file_removed\", \"fix_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "TFbBxKzJFugY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VP General:**"
      ],
      "metadata": {
        "id": "jMDhxPIQQ4i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "j5EgbDbIQ4i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_brf_vp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_brf_vp"
      ],
      "metadata": {
        "id": "8COB1fpzQ4i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_brf_vp[(\"General\", \"Ranking\")] = df_resumen_brf_vp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_brf_vp[(\"General\", \"Conteo Total\")] = df_resumen_brf_vp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_brf_vp"
      ],
      "metadata": {
        "id": "XFeJ5y8HQ4i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_brf_vp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_brf_vp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_brf_vp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_brf_vp[(\"General\", \"Peso Conteo\")] = df_resumen_brf_vp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_brf_vp[(\"General\", \"Puntaje\")] = df_resumen_brf_vp[(\"General\", \"Peso Rango\")] + df_resumen_brf_vp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_brf_vp[(\"General\", \"Ranking\")] = df_resumen_brf_vp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_brf_vp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_brf_vp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_brf_vp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_brf_vp"
      ],
      "metadata": {
        "id": "wzq-nyUYQ4i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_brf_vp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_brf_vp = df_resumen_brf_vp[new_columns]"
      ],
      "metadata": {
        "id": "1eb4QAbrQ4jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_brf_vp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_brf_vp[(tech, \"Ranking Medio\")] = df_resumen_brf_vp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_brf_vp"
      ],
      "metadata": {
        "id": "i6L3eUduQ4jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7HyDYXr2maz"
      },
      "source": [
        "### **Instancia VN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYe130Oq2maz"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"break_down\",random_state=42)\n",
        "shap_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"shap\",random_state=42)\n",
        "lime_vn_max = exp.predict_surrogate(df_instancia_vn_max, random_state=42)\n",
        "\n",
        "breakdown_vn_df_max = breakdown_vn_max.result\n",
        "shap_vn_df_max = shap_vn_max.result\n",
        "lime_vn_df_max = lime_vn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_max.plot()"
      ],
      "metadata": {
        "id": "E-oEitv52maz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_max.plot()"
      ],
      "metadata": {
        "id": "qbe9T4Iv2maz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywP2t6wX2ma0"
      },
      "outputs": [],
      "source": [
        "lime_vn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnNF7WQT2ma0"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_max = breakdown_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(index=[0, 26])\n",
        "breakdown_vn_df_max['sign'] = breakdown_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_max = shap_vn_df_max.tail(25)\n",
        "shap_vn_df_max['sign'] = shap_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_max = shap_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_max[\"Variable\"] = lime_vn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_max[\"Signo\"] = lime_vn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_max = lime_vn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_max['Ranking'] = breakdown_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_max['Ranking'] = shap_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_max = shap_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_max['Ranking'] = lime_vn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_max = lime_vn_df_max.head(5)\n",
        "lime_vn_df_max = lime_vn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(columns=['contribution'])\n",
        "shap_vn_df_max = shap_vn_df_max.drop(columns=['contribution'])\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.head(5)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.head(5)\n",
        "shap_vn_df_max = shap_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_max = lime_vn_df_max.reset_index(drop=True)\n",
        "lime_vn_df_max.at[2, 'Variable'] = 'commit_num'\n",
        "\n",
        "print(breakdown_vn_df_max)\n",
        "print(shap_vn_df_max)\n",
        "print(lime_vn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-Ecjk342ma0"
      },
      "outputs": [],
      "source": [
        "#lime_vn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJuRKKHt2ma0"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_max['Variable'])\n",
        "shapley_features = list(shap_vn_df_max['Variable'])\n",
        "lime_features = list(lime_vn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_max[breakdown_vn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_max[shap_vn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_max[lime_vn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"commit_num\", \"parallel_changed_file_num\", \"improve_frequency\", \"refactor_frequency\", \"file_removed\", \"developer_num\", \"file_added\", \"duration\", \"bug_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "b8Lvt1nlJX2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD7wbbvE2ma0"
      },
      "source": [
        "### **Instancia VN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se33n7pZ2ma1"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"shap\",random_state=42)\n",
        "lime_vn_mediana = exp.predict_surrogate(df_instancia_vn_mediana, random_state=42)\n",
        "\n",
        "breakdown_vn_df_mediana = breakdown_vn_mediana.result\n",
        "shap_vn_df_mediana = shap_vn_mediana.result\n",
        "lime_vn_df_mediana = lime_vn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "5HWzFve82ma1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "rCeZ51yl2ma1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wQ7VR1A2ma1"
      },
      "outputs": [],
      "source": [
        "lime_vn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5mi_Gsm2ma2"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vn_df_mediana['sign'] = breakdown_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.tail(25)\n",
        "shap_vn_df_mediana['sign'] = shap_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_mediana[\"Variable\"] = lime_vn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_mediana[\"Signo\"] = lime_vn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_mediana['Ranking'] = breakdown_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_mediana['Ranking'] = shap_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_mediana['Ranking'] = lime_vn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.head(5)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(columns=['contribution'])\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.drop(columns=['contribution'])\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.head(5)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.head(5)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.reset_index(drop=True)\n",
        "lime_vn_df_mediana.at[3, 'Variable'] = 'developer_num'\n",
        "\n",
        "print(breakdown_vn_df_mediana)\n",
        "print(shap_vn_df_mediana)\n",
        "print(lime_vn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9p0tQwyT2ma2"
      },
      "outputs": [],
      "source": [
        "#lime_vn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50BfCk3j2ma2"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vn_df_mediana['Variable'])\n",
        "lime_features = list(lime_vn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_mediana[breakdown_vn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_mediana[shap_vn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_mediana[lime_vn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"commit_num\", \"parallel_changed_file_num\", \"developer_num\", \"line_removed\", \"file_modified\", \"line_added\", \"file_added\", \"file_removed\", \"bug_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "arb16r0IJbWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipD7lF1X2ma2"
      },
      "source": [
        "### **Instancia VN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dIXDKQ42ma3"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"break_down\",random_state=42)\n",
        "shap_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"shap\",random_state=42)\n",
        "lime_vn_min = exp.predict_surrogate(df_instancia_vn_min, random_state=42)\n",
        "\n",
        "breakdown_vn_df_min = breakdown_vn_min.result\n",
        "shap_vn_df_min = shap_vn_min.result\n",
        "lime_vn_df_min = lime_vn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_min.plot()"
      ],
      "metadata": {
        "id": "44qAuGzt2ma3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_min.plot()"
      ],
      "metadata": {
        "id": "-PfFw1u52ma3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-d2xDPf2ma3"
      },
      "outputs": [],
      "source": [
        "lime_vn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hji7gwKC2ma3"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_min = breakdown_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(index=[0, 26])\n",
        "breakdown_vn_df_min['sign'] = breakdown_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_min = shap_vn_df_min.tail(25)\n",
        "shap_vn_df_min['sign'] = shap_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_min = shap_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_min[\"Variable\"] = lime_vn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_min[\"Signo\"] = lime_vn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_min = lime_vn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_min['Ranking'] = breakdown_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_min['Ranking'] = shap_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_min = shap_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_min['Ranking'] = lime_vn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_min = lime_vn_df_min.head(5)\n",
        "lime_vn_df_min = lime_vn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(columns=['contribution'])\n",
        "shap_vn_df_min = shap_vn_df_min.drop(columns=['contribution'])\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.head(5)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.head(5)\n",
        "shap_vn_df_min = shap_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_min = lime_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vn_df_min)\n",
        "print(shap_vn_df_min)\n",
        "print(lime_vn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0J6Xxey2ma3"
      },
      "outputs": [],
      "source": [
        "#lime_vn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHgqXEFi2ma4"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_min['Variable'])\n",
        "shapley_features = list(shap_vn_df_min['Variable'])\n",
        "lime_features = list(lime_vn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_min[breakdown_vn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_min[shap_vn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_min[lime_vn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"messages_max\", \"commit_num\", \"developer_num\", \"line_removed\", \"messages_median\", \"file_removed\", \"bug_frequency\", \"fix_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "swRBHGjNJhA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VN General:**"
      ],
      "metadata": {
        "id": "XrXnAwyfQ4jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "JArYxUnTQ4jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_brf_vn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_brf_vn"
      ],
      "metadata": {
        "id": "m2kll-phQ4jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_brf_vn[(\"General\", \"Ranking\")] = df_resumen_brf_vn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_brf_vn[(\"General\", \"Conteo Total\")] = df_resumen_brf_vn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_brf_vn"
      ],
      "metadata": {
        "id": "iZQsNtc9Q4jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_brf_vn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_brf_vn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_brf_vn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_brf_vn[(\"General\", \"Peso Conteo\")] = df_resumen_brf_vn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_brf_vn[(\"General\", \"Puntaje\")] = df_resumen_brf_vn[(\"General\", \"Peso Rango\")] + df_resumen_brf_vn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_brf_vn[(\"General\", \"Ranking\")] = df_resumen_brf_vn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_brf_vn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_brf_vn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_brf_vn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_brf_vn"
      ],
      "metadata": {
        "id": "oStphYEeQ4jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_brf_vn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_brf_vn = df_resumen_brf_vn[new_columns]"
      ],
      "metadata": {
        "id": "BHvOtQ_kQ4jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_brf_vn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_brf_vn[(tech, \"Ranking Medio\")] = df_resumen_brf_vn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_brf_vn"
      ],
      "metadata": {
        "id": "ncd1jiqmQ4jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O89xD-832ma4"
      },
      "source": [
        "### **Instancia FP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wsgv3k3H2ma4"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"break_down\",random_state=42)\n",
        "shap_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"shap\",random_state=42)\n",
        "lime_fp_max = exp.predict_surrogate(df_instancia_fp_max, random_state=42)\n",
        "\n",
        "breakdown_fp_df_max = breakdown_fp_max.result\n",
        "shap_fp_df_max = shap_fp_max.result\n",
        "lime_fp_df_max=lime_fp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_max.plot()"
      ],
      "metadata": {
        "id": "i_xpLaBZ2ma4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_max.plot()"
      ],
      "metadata": {
        "id": "b-kVMK912ma4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RSO738X2ma4"
      },
      "outputs": [],
      "source": [
        "lime_fp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3umuBMgd2ma5"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_max = breakdown_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(index=[0, 26])\n",
        "breakdown_fp_df_max['sign'] = breakdown_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_max = shap_fp_df_max.tail(25)\n",
        "shap_fp_df_max['sign'] = shap_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_max = shap_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_max[\"Variable\"] = lime_fp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_max[\"Signo\"] = lime_fp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_max = lime_fp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_max['Ranking'] = breakdown_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_max['Ranking'] = shap_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_max = shap_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_max['Ranking'] = lime_fp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_max = lime_fp_df_max.head(5)\n",
        "lime_fp_df_max = lime_fp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(columns=['contribution'])\n",
        "shap_fp_df_max = shap_fp_df_max.drop(columns=['contribution'])\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.head(5)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.head(5)\n",
        "shap_fp_df_max = shap_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_max = lime_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_max)\n",
        "print(shap_fp_df_max)\n",
        "print(lime_fp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ya8-eUIJ2ma5"
      },
      "outputs": [],
      "source": [
        "#lime_fp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qs41sZA2ma5"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_max['Variable'])\n",
        "shapley_features = list(shap_fp_df_max['Variable'])\n",
        "lime_features = list(lime_fp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_max[breakdown_fp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_max[shap_fp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_max[lime_fp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"file_removed\", \"developer_num\", \"file_added\", \"duration\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "M8sUeXICNhrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9DsANFp2ma5"
      },
      "source": [
        "### **Instancia FP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1b67iSI2ma5"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"shap\",random_state=42)\n",
        "lime_fp_mediana = exp.predict_surrogate(df_instancia_fp_mediana, random_state=42)\n",
        "\n",
        "breakdown_fp_df_mediana = breakdown_fp_mediana.result\n",
        "shap_fp_df_mediana = shap_fp_mediana.result\n",
        "lime_fp_df_mediana=lime_fp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "MiAS3kZ02ma5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "8AosmH6a2ma5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpffTO7M2ma5"
      },
      "outputs": [],
      "source": [
        "lime_fp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Csavnu5r2ma5"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fp_df_mediana['sign'] = breakdown_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.tail(25)\n",
        "shap_fp_df_mediana['sign'] = shap_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_mediana[\"Variable\"] = lime_fp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_mediana[\"Signo\"] = lime_fp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_mediana['Ranking'] = breakdown_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_mediana['Ranking'] = shap_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_mediana['Ranking'] = lime_fp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.head(5)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(columns=['contribution'])\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.drop(columns=['contribution'])\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.head(5)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.head(5)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_mediana)\n",
        "print(shap_fp_df_mediana)\n",
        "print(lime_fp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7apU8_-2ma6"
      },
      "outputs": [],
      "source": [
        "#lime_fp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLNYJJ3g2ma6"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fp_df_mediana['Variable'])\n",
        "lime_features = list(lime_fp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_mediana[breakdown_fp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_mediana[shap_fp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_mediana[lime_fp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"messages_max\", \"file_removed\", \"line_removed\", \"file_added\", \"file_modified\", \"fix_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "eM-bTMP6Nmlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2tDfVB-2ma6"
      },
      "source": [
        "### **Instancia FP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GG-OmFNZ2ma6"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"break_down\",random_state=42)\n",
        "shap_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"shap\",random_state=42)\n",
        "lime_fp_min = exp.predict_surrogate(df_instancia_fp_min, random_state=42)\n",
        "\n",
        "breakdown_fp_df_min = breakdown_fp_min.result\n",
        "shap_fp_df_min = shap_fp_min.result\n",
        "lime_fp_df_min = lime_fp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_min.plot()"
      ],
      "metadata": {
        "id": "DCHXjLKB2ma6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_min.plot()"
      ],
      "metadata": {
        "id": "SzQ3OH6Z2ma6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgKz4Qrt2ma6"
      },
      "outputs": [],
      "source": [
        "lime_fp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPgH72pJ2ma6"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_min = breakdown_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(index=[0, 26])\n",
        "breakdown_fp_df_min['sign'] = breakdown_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_min = shap_fp_df_min.tail(25)\n",
        "shap_fp_df_min['sign'] = shap_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_min = shap_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_min[\"Variable\"] = lime_fp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_min[\"Signo\"] = lime_fp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_min = lime_fp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_min['Ranking'] = breakdown_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_min['Ranking'] = shap_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_min = shap_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_min['Ranking'] = lime_fp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_min = lime_fp_df_min.head(5)\n",
        "lime_fp_df_min = lime_fp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(columns=['contribution'])\n",
        "shap_fp_df_min = shap_fp_df_min.drop(columns=['contribution'])\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.head(5)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.head(5)\n",
        "shap_fp_df_min = shap_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_min = lime_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_min)\n",
        "print(shap_fp_df_min)\n",
        "print(lime_fp_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXS3a89g2ma7"
      },
      "outputs": [],
      "source": [
        "#lime_fp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMB6IoJA2ma7"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_min['Variable'])\n",
        "shapley_features = list(shap_fp_df_min['Variable'])\n",
        "lime_features = list(lime_fp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_min[breakdown_fp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_min[shap_fp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_min[lime_fp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"commit_density\", \"line_added\", \"line_removed\", \"developer_num\", \"file_added\", \"messages_min\", \"file_removed\", \"file_modified\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "3PsrVGdjNtlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FP General:**"
      ],
      "metadata": {
        "id": "c_RRVDLAQ4jM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "QR6MotoVQ4jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_brf_fp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_brf_fp"
      ],
      "metadata": {
        "id": "4lQiYAIkQ4jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_brf_fp[(\"General\", \"Ranking\")] = df_resumen_brf_fp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_brf_fp[(\"General\", \"Conteo Total\")] = df_resumen_brf_fp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_brf_fp"
      ],
      "metadata": {
        "id": "V_rKRxESQ4jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_brf_fp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_brf_fp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_brf_fp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_brf_fp[(\"General\", \"Peso Conteo\")] = df_resumen_brf_fp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_brf_fp[(\"General\", \"Puntaje\")] = df_resumen_brf_fp[(\"General\", \"Peso Rango\")] + df_resumen_brf_fp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_brf_fp[(\"General\", \"Ranking\")] = df_resumen_brf_fp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_brf_fp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_brf_fp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_brf_fp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_brf_fp"
      ],
      "metadata": {
        "id": "3v97vE-jQ4jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_brf_fp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_brf_fp = df_resumen_brf_fp[new_columns]"
      ],
      "metadata": {
        "id": "KRwmlcsKQ4jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_brf_fp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_brf_fp[(tech, \"Ranking Medio\")] = df_resumen_brf_fp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_brf_fp"
      ],
      "metadata": {
        "id": "52vJYiZmQ4jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fWKGdhI2ma7"
      },
      "source": [
        "### **Instancia FN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY5Okrnd2ma7"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"break_down\",random_state=42)\n",
        "shap_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"shap\",random_state=42)\n",
        "lime_fn_max = exp.predict_surrogate(df_instancia_fn_max, random_state=42)\n",
        "\n",
        "breakdown_fn_df_max = breakdown_fn_max.result\n",
        "shap_fn_df_max = shap_fn_max.result\n",
        "lime_fn_df_max=lime_fn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_max.plot()"
      ],
      "metadata": {
        "id": "RylhJ3un2ma7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_max.plot()"
      ],
      "metadata": {
        "id": "UgYv2Cdd2ma7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KakOHvjN2ma7"
      },
      "outputs": [],
      "source": [
        "lime_fn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv_c7JAc2ma7"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_max = breakdown_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(index=[0, 26])\n",
        "breakdown_fn_df_max['sign'] = breakdown_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_max = shap_fn_df_max.tail(25)\n",
        "shap_fn_df_max['sign'] = shap_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_max = shap_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_max[\"Variable\"] = lime_fn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_max[\"Signo\"] = lime_fn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_max = lime_fn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_max['Ranking'] = breakdown_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_max['Ranking'] = shap_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_max = shap_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_max['Ranking'] = lime_fn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_max = lime_fn_df_max.head(5)\n",
        "lime_fn_df_max = lime_fn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(columns=['contribution'])\n",
        "shap_fn_df_max = shap_fn_df_max.drop(columns=['contribution'])\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.head(5)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.head(5)\n",
        "shap_fn_df_max = shap_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_max = lime_fn_df_max.reset_index(drop=True)\n",
        "lime_fn_df_max.at[3, 'Variable'] = 'developer_num'\n",
        "\n",
        "print(breakdown_fn_df_max)\n",
        "print(shap_fn_df_max)\n",
        "print(lime_fn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91s6AnNR2ma8"
      },
      "outputs": [],
      "source": [
        "#lime_fn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCv7suRE2ma8"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_max['Variable'])\n",
        "shapley_features = list(shap_fn_df_max['Variable'])\n",
        "lime_features = list(lime_fn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_max[breakdown_fn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_max[shap_fn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_max[lime_fn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"commit_num\", \"parallel_changed_file_num\", \"line_removed\", \"developer_num\", \"use_frequency\", \"line_added\", \"file_removed\", \"duration\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "kWbHd4RVQATz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSFOyntJ2ma8"
      },
      "source": [
        "### **Instancia FN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxdmgcbP2ma8"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"shap\",random_state=42)\n",
        "lime_fn_mediana = exp.predict_surrogate(df_instancia_fn_mediana, random_state=42)\n",
        "\n",
        "breakdown_fn_df_mediana = breakdown_fn_mediana.result\n",
        "shap_fn_df_mediana = shap_fn_mediana.result\n",
        "lime_fn_df_mediana=lime_fn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "3uhK282B2ma8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "cfDy4a9I2ma8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWUwlrnN2ma8"
      },
      "outputs": [],
      "source": [
        "lime_fn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-seDD2p2ma9"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fn_df_mediana['sign'] = breakdown_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.tail(25)\n",
        "shap_fn_df_mediana['sign'] = shap_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_mediana[\"Variable\"] = lime_fn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_mediana[\"Signo\"] = lime_fn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_mediana['Ranking'] = breakdown_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_mediana['Ranking'] = shap_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_mediana['Ranking'] = lime_fn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.head(5)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(columns=['contribution'])\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.drop(columns=['contribution'])\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.head(5)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.head(5)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fn_df_mediana)\n",
        "print(shap_fn_df_mediana)\n",
        "print(lime_fn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpNO1UUY2ma9"
      },
      "outputs": [],
      "source": [
        "#lime_fn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaW3rXsk2ma9"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fn_df_mediana['Variable'])\n",
        "lime_features = list(lime_fn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_mediana[breakdown_fn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_mediana[shap_fn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_mediana[lime_fn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"file_modified\", \"developer_num\", \"line_added\", \"commit_num\", \"file_added\", \"file_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "RsJR6IDUQEY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3NS1SLn2ma9"
      },
      "source": [
        "### **Instancia FN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb352ZSm2ma9"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"break_down\",random_state=42)\n",
        "shap_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"shap\",random_state=42)\n",
        "lime_fn_min = exp.predict_surrogate(df_instancia_fn_min, random_state=42)\n",
        "\n",
        "breakdown_fn_df_min = breakdown_fn_min.result\n",
        "shap_fn_df_min = shap_fn_min.result\n",
        "lime_fn_df_min = lime_fn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_min.plot()"
      ],
      "metadata": {
        "id": "sdrZlX0v2ma9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_min.plot()"
      ],
      "metadata": {
        "id": "3vhY9J_r2ma-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry9JP1p22ma-"
      },
      "outputs": [],
      "source": [
        "lime_fn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAuNcSWH2ma-"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_min = breakdown_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(index=[0, 26])\n",
        "breakdown_fn_df_min['sign'] = breakdown_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_min = shap_fn_df_min.tail(25)\n",
        "shap_fn_df_min['sign'] = shap_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_min = shap_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_min[\"Variable\"] = lime_fn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_min[\"Signo\"] = lime_fn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_min = lime_fn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_min['Ranking'] = breakdown_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_min['Ranking'] = shap_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_min = shap_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_min['Ranking'] = lime_fn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_min = lime_fn_df_min.head(5)\n",
        "lime_fn_df_min = lime_fn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(columns=['contribution'])\n",
        "shap_fn_df_min = shap_fn_df_min.drop(columns=['contribution'])\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.head(5)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.head(5)\n",
        "shap_fn_df_min = shap_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_min = lime_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fn_df_min)\n",
        "print(shap_fn_df_min)\n",
        "print(lime_fn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UQIV3R62ma-"
      },
      "outputs": [],
      "source": [
        "#lime_fn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgtJ0bcj2ma-"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_min['Variable'])\n",
        "shapley_features = list(shap_fn_df_min['Variable'])\n",
        "lime_features = list(lime_fn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_min[breakdown_fn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_min[shap_fn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_min[lime_fn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"line_added\", \"duration\", \"commit_density\", \"file_removed\", \"file_modified\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "nuUFNcEIQLUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FN General:**"
      ],
      "metadata": {
        "id": "acwUKtZmQ4jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "YGRepzuFQ4jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_brf_fn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_brf_fn"
      ],
      "metadata": {
        "id": "zNyos_AmQ4jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_brf_fn[(\"General\", \"Ranking\")] = df_resumen_brf_fn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_brf_fn[(\"General\", \"Conteo Total\")] = df_resumen_brf_fn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_brf_fn"
      ],
      "metadata": {
        "id": "id6ae_rbQ4jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_brf_fn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_brf_fn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_brf_fn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_brf_fn[(\"General\", \"Peso Conteo\")] = df_resumen_brf_fn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_brf_fn[(\"General\", \"Puntaje\")] = df_resumen_brf_fn[(\"General\", \"Peso Rango\")] + df_resumen_brf_fn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_brf_fn[(\"General\", \"Ranking\")] = df_resumen_brf_fn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_brf_fn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_brf_fn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_brf_fn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_brf_fn"
      ],
      "metadata": {
        "id": "3Ao6l3b1Q4jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_brf_fn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_brf_fn = df_resumen_brf_fn[new_columns]"
      ],
      "metadata": {
        "id": "tOPGfyk9Q4jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_brf_fn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_brf_fn[(tech, \"Ranking Medio\")] = df_resumen_brf_fn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_brf_fn"
      ],
      "metadata": {
        "id": "gPeiEKOMQ4jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVHZv_ytZOmc"
      },
      "source": [
        "## **GradientBoosting:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siZsrc_aZOmi"
      },
      "source": [
        "**FEATURE IMPORTANCE**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permu = permutation_importance(modelo_gb, x_test, y_test, n_repeats=20, random_state=42, n_jobs=2, scoring='f1')\n",
        "\n",
        "# Umbral para valores significativos\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Filtrar los caracteristicas\n",
        "significant_indices = permu.importances_mean > importance_threshold\n",
        "permu_importances = pd.Series(permu.importances_mean.round(3), index=feature_names)[significant_indices]\n",
        "permu_std = permu.importances_std[significant_indices]\n",
        "\n",
        "# Crear la representación gráfica\n",
        "fig, ax = plt.subplots()\n",
        "permu_importances.plot.bar(yerr=permu_std, ax=ax)\n",
        "ax.set_title(\"Feature importances using permutation on full model\")\n",
        "ax.set_ylabel(\"Mean accuracy decrease\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V6BjUsGw2jee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = ['precision', 'recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "permu_score = permutation_importance(modelo_gb, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Itera a través de las métricas\n",
        "for i, metric in enumerate(scoring):\n",
        "    permu = permu_score[metric]\n",
        "\n",
        "    # Filtra las características que cumplen la condición del umbral\n",
        "    significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "    sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "    importances_mean = permu.importances_mean[significant_indices]\n",
        "    importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "    # Ordena los datos por importancia de mayor a menor\n",
        "    sorted_indices = np.argsort(importances_mean)[::1]\n",
        "    sorted_feature_names = [sorted_feature_names[j] for j in sorted_indices]\n",
        "    importances_mean = importances_mean[sorted_indices]\n",
        "    importances_std = importances_std[sorted_indices]\n",
        "\n",
        "    # Crea la representación gráfica en el subplot correspondiente\n",
        "    axs[i].barh(range(len(sorted_feature_names)), importances_mean, xerr=importances_std, align='center')\n",
        "    axs[i].set_yticks(range(len(sorted_feature_names)))\n",
        "    axs[i].set_yticklabels(sorted_feature_names)\n",
        "    axs[i].set_xlabel('Valor Importancia')\n",
        "    axs[i].set_title(f'Importancia por Permutación para {metric_names[i]}')\n",
        "\n",
        "# Ajusta los espacios entre subplots y muestra la figura\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8JiR6CIC2jef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDlH_ZB92jef"
      },
      "outputs": [],
      "source": [
        "scoring = ['precision','recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Crea un diccionario para almacenar los DataFrames\n",
        "results_global_gb = {}\n",
        "\n",
        "permu_score = permutation_importance(modelo_gb, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "for i, metric in enumerate(scoring):\n",
        "  permu = permu_score[metric]\n",
        "\n",
        "  # Filtra las características que cumplen la condición\n",
        "  significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "  sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "  importances_mean = permu.importances_mean[significant_indices]\n",
        "  importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "  # Crear un DataFrame con los resultados\n",
        "  df_exp_global = pd.DataFrame({'Feature': sorted_feature_names,\n",
        "                       'Importance_Mean': importances_mean,\n",
        "                       'Importance_Std': importances_std})\n",
        "\n",
        "  # Ordenar el DataFrame por importance_mean en orden descendente\n",
        "  df_exp_global = df_exp_global.sort_values(by='Importance_Mean', ascending=False)\n",
        "\n",
        "  # Asignar el DataFrame al diccionario con el nombre de la métrica\n",
        "  results_global_gb[f'df_global_{metric_names[i]}'] = df_exp_global"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_gb['df_global_Precision']"
      ],
      "metadata": {
        "id": "Xco4cHen2jeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_gb['df_global_Recall']"
      ],
      "metadata": {
        "id": "swOaJqVX2jeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_gb['df_global_F1-score']"
      ],
      "metadata": {
        "id": "kmYbs3Gw2jeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9QiTyYDZOmj"
      },
      "source": [
        "**BREAK-DOWN, SHAP Y LIME:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snzVvrChZZ5-"
      },
      "outputs": [],
      "source": [
        "#primero definimos el explainer\n",
        "exp = dx.Explainer(modelo_gb, x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY3JvU_-3F4v"
      },
      "source": [
        "### **Instancia VP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJKjJ9Hs3F4v"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"break_down\",random_state=42)\n",
        "shap_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"shap\",random_state=42)\n",
        "lime_vp_max = exp.predict_surrogate(df_instancia_vp_max, random_state=42)\n",
        "\n",
        "breakdown_vp_df_max = breakdown_vp_max.result\n",
        "shap_vp_df_max = shap_vp_max.result\n",
        "lime_vp_df_max=lime_vp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_max.plot()"
      ],
      "metadata": {
        "id": "vhwyxW1C3F4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_max.plot()"
      ],
      "metadata": {
        "id": "mzOxUcI-3F4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Mr2lBHm3F4w"
      },
      "outputs": [],
      "source": [
        "lime_vp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YusyDvXG3F4w"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_max = breakdown_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(index=[0, 26])\n",
        "breakdown_vp_df_max['sign'] = breakdown_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_max = shap_vp_df_max.tail(25)\n",
        "shap_vp_df_max['sign'] = shap_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_max = shap_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_max[\"Variable\"] = lime_vp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_max[\"Signo\"] = lime_vp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_max = lime_vp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_max['Ranking'] = breakdown_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_max['Ranking'] = shap_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_max = shap_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_max['Ranking'] = lime_vp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_max = lime_vp_df_max.head(5)\n",
        "lime_vp_df_max = lime_vp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(columns=['contribution'])\n",
        "shap_vp_df_max = shap_vp_df_max.drop(columns=['contribution'])\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.head(5)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.head(5)\n",
        "shap_vp_df_max = shap_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_max = lime_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_max)\n",
        "print(shap_vp_df_max)\n",
        "print(lime_vp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imrktgg33F4w"
      },
      "outputs": [],
      "source": [
        "#lime_vp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGKNN-493F4w"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_max['Variable'])\n",
        "shapley_features = list(shap_vp_df_max['Variable'])\n",
        "lime_features = list(lime_vp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_max[breakdown_vp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_max[shap_vp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_max[lime_vp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"line_removed\",\"file_removed\", \"duration\", \"commit_num\", \"file_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "IOUkdS-PR9hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TALjJfoS3F4x"
      },
      "source": [
        "### **Instancia VP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo2B1_n13F4x"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"shap\",random_state=42)\n",
        "lime_vp_mediana = exp.predict_surrogate(df_instancia_vp_mediana, random_state=42)\n",
        "\n",
        "breakdown_vp_df_mediana = breakdown_vp_mediana.result\n",
        "shap_vp_df_mediana = shap_vp_mediana.result\n",
        "lime_vp_df_mediana=lime_vp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "eSoBRNbt3F4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "ztmLW_7g3F4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVvnAiTu3F4x"
      },
      "outputs": [],
      "source": [
        "lime_vp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amMe7hHa3F4x"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vp_df_mediana['sign'] = breakdown_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.tail(25)\n",
        "shap_vp_df_mediana['sign'] = shap_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_mediana[\"Variable\"] = lime_vp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_mediana[\"Signo\"] = lime_vp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_mediana['Ranking'] = breakdown_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_mediana['Ranking'] = shap_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_mediana['Ranking'] = lime_vp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.head(5)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(columns=['contribution'])\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.drop(columns=['contribution'])\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.head(5)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.head(5)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_mediana)\n",
        "print(shap_vp_df_mediana)\n",
        "print(lime_vp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBm2IfYy3F4x"
      },
      "outputs": [],
      "source": [
        "#lime_vp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iryJ4w--3F4x"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vp_df_mediana['Variable'])\n",
        "lime_features = list(lime_vp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_mediana[breakdown_vp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_mediana[shap_vp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_mediana[lime_vp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"developer_num\", \"file_added\", \"line_removed\", \"file_removed\", \"parallel_changed_file_num\", \"remove_frequency\", \"commit_num\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "xpONbaTdSB2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toiBfG1_3F4y"
      },
      "source": [
        "### **Instancia VP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MeL7yvx3F4y"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"break_down\",random_state=42)\n",
        "shap_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"shap\",random_state=42)\n",
        "lime_vp_min = exp.predict_surrogate(df_instancia_vp_min, random_state=42)\n",
        "\n",
        "breakdown_vp_df_min = breakdown_vp_min.result\n",
        "shap_vp_df_min = shap_vp_min.result\n",
        "lime_vp_df_min = lime_vp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_min.plot()"
      ],
      "metadata": {
        "id": "OA_3KQuZ3F4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_min.plot()"
      ],
      "metadata": {
        "id": "Nojc7lzh3F4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWsGR80E3F4y"
      },
      "outputs": [],
      "source": [
        "lime_vp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-BBhBl93F4y"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_min = breakdown_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(index=[0, 26])\n",
        "breakdown_vp_df_min['sign'] = breakdown_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_min = shap_vp_df_min.tail(25)\n",
        "shap_vp_df_min['sign'] = shap_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_min = shap_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_min[\"Variable\"] = lime_vp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_min[\"Signo\"] = lime_vp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_min = lime_vp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_min['Ranking'] = breakdown_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_min['Ranking'] = shap_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_min = shap_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_min['Ranking'] = lime_vp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_min = lime_vp_df_min.head(5)\n",
        "lime_vp_df_min = lime_vp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(columns=['contribution'])\n",
        "shap_vp_df_min = shap_vp_df_min.drop(columns=['contribution'])\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.head(5)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.head(5)\n",
        "shap_vp_df_min = shap_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_min = lime_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_min)\n",
        "print(shap_vp_df_min)\n",
        "print(lime_vp_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N20fUiZs3F4y"
      },
      "outputs": [],
      "source": [
        "#lime_vp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4hT1kB63F4y"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_min['Variable'])\n",
        "shapley_features = list(shap_vp_df_min['Variable'])\n",
        "lime_features = list(lime_vp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_min[breakdown_vp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_min[shap_vp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_min[lime_vp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"commit_density\", \"commit_num\", \"parallel_changed_file_num\", \"line_removed\", \"developer_num\", \"file_modified\",  \"file_removed\", \"improve_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "YKm-xsZ2SIH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VP General:**"
      ],
      "metadata": {
        "id": "Fs8ZEMPKRXSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "0GwQW4EXRXSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_gb_vp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_gb_vp"
      ],
      "metadata": {
        "id": "kRqpDrMNRXSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_gb_vp[(\"General\", \"Ranking\")] = df_resumen_gb_vp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_gb_vp[(\"General\", \"Conteo Total\")] = df_resumen_gb_vp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_gb_vp"
      ],
      "metadata": {
        "id": "BzUK4wC7RXSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_gb_vp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_gb_vp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_gb_vp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_gb_vp[(\"General\", \"Peso Conteo\")] = df_resumen_gb_vp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_gb_vp[(\"General\", \"Puntaje\")] = df_resumen_gb_vp[(\"General\", \"Peso Rango\")] + df_resumen_gb_vp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_gb_vp[(\"General\", \"Ranking\")] = df_resumen_gb_vp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_gb_vp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_gb_vp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_gb_vp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_gb_vp"
      ],
      "metadata": {
        "id": "uLQrthI7RXSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_gb_vp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_gb_vp = df_resumen_gb_vp[new_columns]"
      ],
      "metadata": {
        "id": "8C5927VKRXSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_gb_vp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_gb_vp[(tech, \"Ranking Medio\")] = df_resumen_gb_vp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_gb_vp"
      ],
      "metadata": {
        "id": "n4E_FxEtRXSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grvngsym3F4z"
      },
      "source": [
        "### **Instancia VN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s48qX8xk3F4z"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"break_down\",random_state=42)\n",
        "shap_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"shap\",random_state=42)\n",
        "lime_vn_max = exp.predict_surrogate(df_instancia_vn_max, random_state=42)\n",
        "\n",
        "breakdown_vn_df_max = breakdown_vn_max.result\n",
        "shap_vn_df_max = shap_vn_max.result\n",
        "lime_vn_df_max = lime_vn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_max.plot()"
      ],
      "metadata": {
        "id": "TbGXS0Dx3F4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_max.plot()"
      ],
      "metadata": {
        "id": "JLBdrjk23F4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FdoEeIa3F4z"
      },
      "outputs": [],
      "source": [
        "lime_vn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWKagDYZ3F4z"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_max = breakdown_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(index=[0, 26])\n",
        "breakdown_vn_df_max['sign'] = breakdown_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_max = shap_vn_df_max.tail(25)\n",
        "shap_vn_df_max['sign'] = shap_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_max = shap_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_max[\"Variable\"] = lime_vn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_max[\"Signo\"] = lime_vn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_max = lime_vn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_max['Ranking'] = breakdown_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_max['Ranking'] = shap_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_max = shap_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_max['Ranking'] = lime_vn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_max = lime_vn_df_max.head(5)\n",
        "lime_vn_df_max = lime_vn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(columns=['contribution'])\n",
        "shap_vn_df_max = shap_vn_df_max.drop(columns=['contribution'])\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.head(5)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.head(5)\n",
        "shap_vn_df_max = shap_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_max = lime_vn_df_max.reset_index(drop=True)\n",
        "lime_vn_df_max.at[2, 'Variable'] = 'commit_num'\n",
        "lime_vn_df_max.at[3, 'Variable'] = 'file_added'\n",
        "lime_vn_df_max.at[4, 'Variable'] = 'line_removed'\n",
        "\n",
        "print(breakdown_vn_df_max)\n",
        "print(shap_vn_df_max)\n",
        "print(lime_vn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovq14uJT3F4z"
      },
      "outputs": [],
      "source": [
        "#lime_vn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCFVXzzh3F4z"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_max['Variable'])\n",
        "shapley_features = list(shap_vn_df_max['Variable'])\n",
        "lime_features = list(lime_vn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_max[breakdown_vn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_max[shap_vn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_max[lime_vn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"file_added\", \"commit_num\", \"improve_frequency\", \"line_removed\", \"developer_num\", \"parallel_changed_file_num\", \"duration\", \"file_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "EvKF4y9oZaNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usG34X8M3F40"
      },
      "source": [
        "### **Instancia VN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfEZn6OS3F40"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"shap\",random_state=42)\n",
        "lime_vn_mediana = exp.predict_surrogate(df_instancia_vn_mediana, random_state=42)\n",
        "\n",
        "breakdown_vn_df_mediana = breakdown_vn_mediana.result\n",
        "shap_vn_df_mediana = shap_vn_mediana.result\n",
        "lime_vn_df_mediana = lime_vn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "9wNa-dpR3F40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "L3yCbvmQ3F40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN8Z6fnd3F40"
      },
      "outputs": [],
      "source": [
        "lime_vn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O53c9uho3F40"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vn_df_mediana['sign'] = breakdown_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.tail(25)\n",
        "shap_vn_df_mediana['sign'] = shap_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_mediana[\"Variable\"] = lime_vn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_mediana[\"Signo\"] = lime_vn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_mediana['Ranking'] = breakdown_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_mediana['Ranking'] = shap_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_mediana['Ranking'] = lime_vn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.head(5)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(columns=['contribution'])\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.drop(columns=['contribution'])\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.head(5)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.head(5)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.reset_index(drop=True)\n",
        "lime_vn_df_mediana.at[2, 'Variable'] = 'developer_num'\n",
        "lime_vn_df_mediana.at[3, 'Variable'] = 'file_added'\n",
        "lime_vn_df_mediana.at[4, 'Variable'] = 'line_removed'\n",
        "\n",
        "print(breakdown_vn_df_mediana)\n",
        "print(shap_vn_df_mediana)\n",
        "print(lime_vn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0EARPzqb3F40"
      },
      "outputs": [],
      "source": [
        "#lime_vn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akqn1j9s3F40"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vn_df_mediana['Variable'])\n",
        "lime_features = list(lime_vn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_mediana[breakdown_vn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_mediana[shap_vn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_mediana[lime_vn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"file_modified\", \"messages_max\", \"file_added\", \"commit_num\", \"line_added\", \"file_removed\", \"line_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "fRYTe3DWZegj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SpWGfIr3F41"
      },
      "source": [
        "### **Instancia VN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jlgw4343F41"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"break_down\",random_state=42)\n",
        "shap_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"shap\",random_state=42)\n",
        "lime_vn_min = exp.predict_surrogate(df_instancia_vn_min, random_state=42)\n",
        "\n",
        "breakdown_vn_df_min = breakdown_vn_min.result\n",
        "shap_vn_df_min = shap_vn_min.result\n",
        "lime_vn_df_min = lime_vn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_min.plot()"
      ],
      "metadata": {
        "id": "iXEfy1LC3F41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_min.plot()"
      ],
      "metadata": {
        "id": "EY57yXfI3F41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRwyWSa73F41"
      },
      "outputs": [],
      "source": [
        "lime_vn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPUhsNli3F41"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_min = breakdown_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(index=[0, 26])\n",
        "breakdown_vn_df_min['sign'] = breakdown_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_min = shap_vn_df_min.tail(25)\n",
        "shap_vn_df_min['sign'] = shap_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_min = shap_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_min[\"Variable\"] = lime_vn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_min[\"Signo\"] = lime_vn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_min = lime_vn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_min['Ranking'] = breakdown_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_min['Ranking'] = shap_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_min = shap_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_min['Ranking'] = lime_vn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_min = lime_vn_df_min.head(5)\n",
        "lime_vn_df_min = lime_vn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(columns=['contribution'])\n",
        "shap_vn_df_min = shap_vn_df_min.drop(columns=['contribution'])\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.head(5)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.head(5)\n",
        "shap_vn_df_min = shap_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_min = lime_vn_df_min.reset_index(drop=True)\n",
        "lime_vn_df_min.at[4, 'Variable'] = 'duration'\n",
        "\n",
        "print(breakdown_vn_df_min)\n",
        "print(shap_vn_df_min)\n",
        "print(lime_vn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypK-S_zX3F41"
      },
      "outputs": [],
      "source": [
        "#lime_vn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfENBYzU3F41"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_min['Variable'])\n",
        "shapley_features = list(shap_vn_df_min['Variable'])\n",
        "lime_features = list(lime_vn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_min[breakdown_vn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_min[shap_vn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_min[lime_vn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"commit_num\", \"messages_max\", \"parallel_changed_file_num\", \"line_removed\", \"messages_min\", \"developer_num\", \"file_removed\", \"file_added\", \"duration\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "usUfS0ycZj4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VN General:**"
      ],
      "metadata": {
        "id": "GlkzOJNTRXSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "CwKbM3-rRXSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_gb_vn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_gb_vn"
      ],
      "metadata": {
        "id": "vJVmARxCRXSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_gb_vn[(\"General\", \"Ranking\")] = df_resumen_gb_vn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_gb_vn[(\"General\", \"Conteo Total\")] = df_resumen_gb_vn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_gb_vn"
      ],
      "metadata": {
        "id": "JDnzKauORXSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_gb_vn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_gb_vn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_gb_vn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_gb_vn[(\"General\", \"Peso Conteo\")] = df_resumen_gb_vn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_gb_vn[(\"General\", \"Puntaje\")] = df_resumen_gb_vn[(\"General\", \"Peso Rango\")] + df_resumen_gb_vn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_gb_vn[(\"General\", \"Ranking\")] = df_resumen_gb_vn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_gb_vn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_gb_vn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_gb_vn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_gb_vn"
      ],
      "metadata": {
        "id": "7xxgqdJvRXSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_gb_vn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_gb_vn = df_resumen_gb_vn[new_columns]"
      ],
      "metadata": {
        "id": "Rw08oJQ8RXSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_gb_vn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_gb_vn[(tech, \"Ranking Medio\")] = df_resumen_gb_vn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_gb_vn"
      ],
      "metadata": {
        "id": "BzmfU0_aRXSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivuA-Wo93F42"
      },
      "source": [
        "### **Instancia FP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wV7ws0x43F42"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"break_down\",random_state=42)\n",
        "shap_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"shap\",random_state=42)\n",
        "lime_fp_max = exp.predict_surrogate(df_instancia_fp_max, random_state=42)\n",
        "\n",
        "breakdown_fp_df_max = breakdown_fp_max.result\n",
        "shap_fp_df_max = shap_fp_max.result\n",
        "lime_fp_df_max=lime_fp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_max.plot()"
      ],
      "metadata": {
        "id": "MED0pVC03F42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_max.plot()"
      ],
      "metadata": {
        "id": "KVUGNcNM3F42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcn0kfzl3F42"
      },
      "outputs": [],
      "source": [
        "lime_fp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyQJ6dcW3F42"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_max = breakdown_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(index=[0, 26])\n",
        "breakdown_fp_df_max['sign'] = breakdown_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_max = shap_fp_df_max.tail(25)\n",
        "shap_fp_df_max['sign'] = shap_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_max = shap_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_max[\"Variable\"] = lime_fp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_max[\"Signo\"] = lime_fp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_max = lime_fp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_max['Ranking'] = breakdown_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_max['Ranking'] = shap_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_max = shap_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_max['Ranking'] = lime_fp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_max = lime_fp_df_max.head(5)\n",
        "lime_fp_df_max = lime_fp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(columns=['contribution'])\n",
        "shap_fp_df_max = shap_fp_df_max.drop(columns=['contribution'])\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.head(5)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.head(5)\n",
        "shap_fp_df_max = shap_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_max = lime_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_max)\n",
        "print(shap_fp_df_max)\n",
        "print(lime_fp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN1CckLt3F42"
      },
      "outputs": [],
      "source": [
        "#lime_fp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5jeb2_F3F43"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_max['Variable'])\n",
        "shapley_features = list(shap_fp_df_max['Variable'])\n",
        "lime_features = list(lime_fp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_max[breakdown_fp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_max[shap_fp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_max[lime_fp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"line_removed\", \"commit_num\", \"developer_num\", \"duration\", \"messages_max\", \"file_removed\",  \"messages_min\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "NSwa7peqdyRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS__P5193F43"
      },
      "source": [
        "### **Instancia FP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLoLC0C13F43"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"shap\",random_state=42)\n",
        "lime_fp_mediana = exp.predict_surrogate(df_instancia_fp_mediana, random_state=42)\n",
        "\n",
        "breakdown_fp_df_mediana = breakdown_fp_mediana.result\n",
        "shap_fp_df_mediana = shap_fp_mediana.result\n",
        "lime_fp_df_mediana=lime_fp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "W5pSDTdq3F43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "H605Z5ME3F43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1HkZUiQ3F43"
      },
      "outputs": [],
      "source": [
        "lime_fp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrB9OJ4G3F43"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fp_df_mediana['sign'] = breakdown_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.tail(25)\n",
        "shap_fp_df_mediana['sign'] = shap_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_mediana[\"Variable\"] = lime_fp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_mediana[\"Signo\"] = lime_fp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_mediana['Ranking'] = breakdown_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_mediana['Ranking'] = shap_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_mediana['Ranking'] = lime_fp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.head(5)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(columns=['contribution'])\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.drop(columns=['contribution'])\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.head(5)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.head(5)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_mediana)\n",
        "print(shap_fp_df_mediana)\n",
        "print(lime_fp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JYxvW843F44"
      },
      "outputs": [],
      "source": [
        "#lime_fp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_M-e-9G3F44"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fp_df_mediana['Variable'])\n",
        "lime_features = list(lime_fp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_mediana[breakdown_fp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_mediana[shap_fp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_mediana[lime_fp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"line_removed\", \"messages_min\", \"developer_num\", \"file_added\", \"file_removed\", \"file_modified\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "cH4aSuEud2E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI7ttJ283F44"
      },
      "source": [
        "### **Instancia FP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j87deP6D3F44"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"break_down\",random_state=42)\n",
        "shap_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"shap\",random_state=42)\n",
        "lime_fp_min = exp.predict_surrogate(df_instancia_fp_min, random_state=42)\n",
        "\n",
        "breakdown_fp_df_min = breakdown_fp_min.result\n",
        "shap_fp_df_min = shap_fp_min.result\n",
        "lime_fp_df_min = lime_fp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_min.plot()"
      ],
      "metadata": {
        "id": "nrn5Ly-H3F44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_min.plot()"
      ],
      "metadata": {
        "id": "CtSwiaLF3F44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xovqbo2n3F44"
      },
      "outputs": [],
      "source": [
        "lime_fp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfA3J6kJ3F44"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_min = breakdown_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(index=[0, 26])\n",
        "breakdown_fp_df_min['sign'] = breakdown_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_min = shap_fp_df_min.tail(25)\n",
        "shap_fp_df_min['sign'] = shap_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_min = shap_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_min[\"Variable\"] = lime_fp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_min[\"Signo\"] = lime_fp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_min = lime_fp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_min['Ranking'] = breakdown_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_min['Ranking'] = shap_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_min = shap_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_min['Ranking'] = lime_fp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_min = lime_fp_df_min.head(5)\n",
        "lime_fp_df_min = lime_fp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(columns=['contribution'])\n",
        "shap_fp_df_min = shap_fp_df_min.drop(columns=['contribution'])\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.head(5)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.head(5)\n",
        "shap_fp_df_min = shap_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_min = lime_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_min)\n",
        "print(shap_fp_df_min)\n",
        "print(lime_fp_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6MovW-73F45"
      },
      "outputs": [],
      "source": [
        "#lime_fp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVxhq_jM3F45"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_min['Variable'])\n",
        "shapley_features = list(shap_fp_df_min['Variable'])\n",
        "lime_features = list(lime_fp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_min[breakdown_fp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_min[shap_fp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_min[lime_fp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"developer_num\", \"parallel_changed_file_num\", \"commit_num\", \"file_added\", \"file_removed\", \"duration\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "3u5ESg7qd-Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FP General:**"
      ],
      "metadata": {
        "id": "6HTICi5tRXSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "Hz3LIvL9RXS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_gb_fp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_gb_fp"
      ],
      "metadata": {
        "id": "gcXV-nRdRXS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_gb_fp[(\"General\", \"Ranking\")] = df_resumen_gb_fp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_gb_fp[(\"General\", \"Conteo Total\")] = df_resumen_gb_fp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_gb_fp"
      ],
      "metadata": {
        "id": "FM0MB8WLRXS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_gb_fp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_gb_fp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_gb_fp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_gb_fp[(\"General\", \"Peso Conteo\")] = df_resumen_gb_fp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_gb_fp[(\"General\", \"Puntaje\")] = df_resumen_gb_fp[(\"General\", \"Peso Rango\")] + df_resumen_gb_fp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_gb_fp[(\"General\", \"Ranking\")] = df_resumen_gb_fp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_gb_fp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_gb_fp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_gb_fp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_gb_fp"
      ],
      "metadata": {
        "id": "9nlz0i_ARXS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_gb_fp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_gb_fp = df_resumen_gb_fp[new_columns]"
      ],
      "metadata": {
        "id": "T7iyjRYhRXS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_gb_fp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_gb_fp[(tech, \"Ranking Medio\")] = df_resumen_gb_fp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_gb_fp"
      ],
      "metadata": {
        "id": "6M02Hby0RXS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdGZKlHA3F45"
      },
      "source": [
        "### **Instancia FN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDVZixJK3F45"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"break_down\",random_state=42)\n",
        "shap_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"shap\",random_state=42)\n",
        "lime_fn_max = exp.predict_surrogate(df_instancia_fn_max, random_state=42)\n",
        "\n",
        "breakdown_fn_df_max = breakdown_fn_max.result\n",
        "shap_fn_df_max = shap_fn_max.result\n",
        "lime_fn_df_max=lime_fn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_max.plot()"
      ],
      "metadata": {
        "id": "r4Nqzm8-3F45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_max.plot()"
      ],
      "metadata": {
        "id": "Ljvrs8Vk3F45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S5Qr5Ke3F45"
      },
      "outputs": [],
      "source": [
        "lime_fn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAxhqIZN3F46"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_max = breakdown_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(index=[0, 26])\n",
        "breakdown_fn_df_max['sign'] = breakdown_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_max = shap_fn_df_max.tail(25)\n",
        "shap_fn_df_max['sign'] = shap_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_max = shap_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_max[\"Variable\"] = lime_fn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_max[\"Signo\"] = lime_fn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_max = lime_fn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_max['Ranking'] = breakdown_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_max['Ranking'] = shap_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_max = shap_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_max['Ranking'] = lime_fn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_max = lime_fn_df_max.head(5)\n",
        "lime_fn_df_max = lime_fn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(columns=['contribution'])\n",
        "shap_fn_df_max = shap_fn_df_max.drop(columns=['contribution'])\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.head(5)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.head(5)\n",
        "shap_fn_df_max = shap_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_max = lime_fn_df_max.reset_index(drop=True)\n",
        "lime_fn_df_max.at[2, 'Variable'] = 'developer_num'\n",
        "lime_fn_df_max.at[3, 'Variable'] = 'line_removed'\n",
        "lime_fn_df_max.at[4, 'Variable'] = 'file_added'\n",
        "\n",
        "print(breakdown_fn_df_max)\n",
        "print(shap_fn_df_max)\n",
        "print(lime_fn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4SGW1a03F46"
      },
      "outputs": [],
      "source": [
        "#lime_fn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n8XRgg33F46"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_max['Variable'])\n",
        "shapley_features = list(shap_fn_df_max['Variable'])\n",
        "lime_features = list(lime_fn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_max[breakdown_fn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_max[shap_fn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_max[lime_fn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"commit_num\", \"parallel_changed_file_num\", \"developer_num\", \"file_added\", \"duration\", \"line_added\", \"file_removed\", \"line_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "7B0KYVNNeIJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5SJsase3F46"
      },
      "source": [
        "### **Instancia FN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGueq6GB3F46"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"shap\",random_state=42)\n",
        "lime_fn_mediana = exp.predict_surrogate(df_instancia_fn_mediana, random_state=42)\n",
        "\n",
        "breakdown_fn_df_mediana = breakdown_fn_mediana.result\n",
        "shap_fn_df_mediana = shap_fn_mediana.result\n",
        "lime_fn_df_mediana=lime_fn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "8SNueB6X3F46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "cpU8SDnE3F46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCg12_1k3F46"
      },
      "outputs": [],
      "source": [
        "lime_fn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6RCPAA73F46"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fn_df_mediana['sign'] = breakdown_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.tail(25)\n",
        "shap_fn_df_mediana['sign'] = shap_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_mediana[\"Variable\"] = lime_fn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_mediana[\"Signo\"] = lime_fn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_mediana['Ranking'] = breakdown_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_mediana['Ranking'] = shap_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_mediana['Ranking'] = lime_fn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.head(5)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(columns=['contribution'])\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.drop(columns=['contribution'])\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.head(5)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.head(5)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fn_df_mediana)\n",
        "print(shap_fn_df_mediana)\n",
        "print(lime_fn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BESfAcxY3F47"
      },
      "outputs": [],
      "source": [
        "#lime_fn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4VZCLsM3F47"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fn_df_mediana['Variable'])\n",
        "lime_features = list(lime_fn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_mediana[breakdown_fn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_mediana[shap_fn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_mediana[lime_fn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"line_added\", \"parallel_changed_file_num\", \"file_added\", \"file_modified\", \"file_removed\", \"developer_num\",\"commit_num\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "dnWUt4o9ePYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21OsF5Jd3F47"
      },
      "source": [
        "### **Instancia FN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EL_zhua3F47"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"break_down\",random_state=42)\n",
        "shap_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"shap\",random_state=42)\n",
        "lime_fn_min = exp.predict_surrogate(df_instancia_fn_min, random_state=42)\n",
        "\n",
        "breakdown_fn_df_min = breakdown_fn_min.result\n",
        "shap_fn_df_min = shap_fn_min.result\n",
        "lime_fn_df_min = lime_fn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_min.plot()"
      ],
      "metadata": {
        "id": "10gDYRBy3F47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_min.plot()"
      ],
      "metadata": {
        "id": "0wpMOQA93F47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fU49VgH3F47"
      },
      "outputs": [],
      "source": [
        "lime_fn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXGHLEXP3F47"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_min = breakdown_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(index=[0, 26])\n",
        "breakdown_fn_df_min['sign'] = breakdown_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_min = shap_fn_df_min.tail(25)\n",
        "shap_fn_df_min['sign'] = shap_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_min = shap_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_min[\"Variable\"] = lime_fn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_min[\"Signo\"] = lime_fn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_min = lime_fn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_min['Ranking'] = breakdown_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_min['Ranking'] = shap_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_min = shap_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_min['Ranking'] = lime_fn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_min = lime_fn_df_min.head(5)\n",
        "lime_fn_df_min = lime_fn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(columns=['contribution'])\n",
        "shap_fn_df_min = shap_fn_df_min.drop(columns=['contribution'])\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.head(5)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.head(5)\n",
        "shap_fn_df_min = shap_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_min = lime_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fn_df_min)\n",
        "print(shap_fn_df_min)\n",
        "print(lime_fn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh4ROnNp3F47"
      },
      "outputs": [],
      "source": [
        "#lime_fn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMSkFMj13F48"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_min['Variable'])\n",
        "shapley_features = list(shap_fn_df_min['Variable'])\n",
        "lime_features = list(lime_fn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_min[breakdown_fn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_min[shap_fn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_min[lime_fn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"duration\", \"parallel_changed_file_num\", \"file_added\", \"file_modified\", \"developer_num\", \"line_added\", \"file_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "ROK0hFJReU71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FN General:**"
      ],
      "metadata": {
        "id": "gEJBX8qcRXS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "wgM8s2xHRXS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_gb_fn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_gb_fn"
      ],
      "metadata": {
        "id": "lN3mLgSFRXS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_gb_fn[(\"General\", \"Ranking\")] = df_resumen_gb_fn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_gb_fn[(\"General\", \"Conteo Total\")] = df_resumen_gb_fn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_gb_fn"
      ],
      "metadata": {
        "id": "JgT87ScpRXS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_gb_fn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_gb_fn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_gb_fn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_gb_fn[(\"General\", \"Peso Conteo\")] = df_resumen_gb_fn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_gb_fn[(\"General\", \"Puntaje\")] = df_resumen_gb_fn[(\"General\", \"Peso Rango\")] + df_resumen_gb_fn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_gb_fn[(\"General\", \"Ranking\")] = df_resumen_gb_fn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_gb_fn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_gb_fn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_gb_fn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_gb_fn"
      ],
      "metadata": {
        "id": "jhBEDSH0RXS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_gb_fn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_gb_fn = df_resumen_gb_fn[new_columns]"
      ],
      "metadata": {
        "id": "VypC7RoURXS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_gb_fn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_gb_fn[(tech, \"Ranking Medio\")] = df_resumen_gb_fn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_gb_fn"
      ],
      "metadata": {
        "id": "yZBFQduPRXS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5evzSQEZ_MQ"
      },
      "source": [
        "## **AdaBoosting:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvbqvqstZ_MW"
      },
      "source": [
        "**FEATURE IMPORTANCE**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permu = permutation_importance(modelo_ada, x_test, y_test, n_repeats=20, random_state=42, n_jobs=2, scoring='f1')\n",
        "\n",
        "# Umbral para valores significativos\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Filtrar los caracteristicas\n",
        "significant_indices = permu.importances_mean > importance_threshold\n",
        "permu_importances = pd.Series(permu.importances_mean.round(3), index=feature_names)[significant_indices]\n",
        "permu_std = permu.importances_std[significant_indices]\n",
        "\n",
        "# Crear la representación gráfica\n",
        "fig, ax = plt.subplots()\n",
        "permu_importances.plot.bar(yerr=permu_std, ax=ax)\n",
        "ax.set_title(\"Feature importances using permutation on full model\")\n",
        "ax.set_ylabel(\"Mean accuracy decrease\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gldjxXnx4UhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = ['precision', 'recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "permu_score = permutation_importance(modelo_ada, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Itera a través de las métricas\n",
        "for i, metric in enumerate(scoring):\n",
        "    permu = permu_score[metric]\n",
        "\n",
        "    # Filtra las características que cumplen la condición del umbral\n",
        "    significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "    sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "    importances_mean = permu.importances_mean[significant_indices]\n",
        "    importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "    # Ordena los datos por importancia de mayor a menor\n",
        "    sorted_indices = np.argsort(importances_mean)[::1]\n",
        "    sorted_feature_names = [sorted_feature_names[j] for j in sorted_indices]\n",
        "    importances_mean = importances_mean[sorted_indices]\n",
        "    importances_std = importances_std[sorted_indices]\n",
        "\n",
        "    # Crea la representación gráfica en el subplot correspondiente\n",
        "    axs[i].barh(range(len(sorted_feature_names)), importances_mean, xerr=importances_std, align='center')\n",
        "    axs[i].set_yticks(range(len(sorted_feature_names)))\n",
        "    axs[i].set_yticklabels(sorted_feature_names)\n",
        "    axs[i].set_xlabel('Valor Importancia')\n",
        "    axs[i].set_title(f'Importancia por Permutación para {metric_names[i]}')\n",
        "\n",
        "# Ajusta los espacios entre subplots y muestra la figura\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IDghHVR34UhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtVoYyUI4UhK"
      },
      "outputs": [],
      "source": [
        "scoring = ['precision','recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Crea un diccionario para almacenar los DataFrames\n",
        "results_global_ada = {}\n",
        "\n",
        "permu_score = permutation_importance(modelo_ada, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "for i, metric in enumerate(scoring):\n",
        "  permu = permu_score[metric]\n",
        "\n",
        "  # Filtra las características que cumplen la condición\n",
        "  significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "  sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "  importances_mean = permu.importances_mean[significant_indices]\n",
        "  importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "  # Crear un DataFrame con los resultados\n",
        "  df_exp_global = pd.DataFrame({'Feature': sorted_feature_names,\n",
        "                       'Importance_Mean': importances_mean,\n",
        "                       'Importance_Std': importances_std})\n",
        "\n",
        "  # Ordenar el DataFrame por importance_mean en orden descendente\n",
        "  df_exp_global = df_exp_global.sort_values(by='Importance_Mean', ascending=False)\n",
        "\n",
        "  # Asignar el DataFrame al diccionario con el nombre de la métrica\n",
        "  results_global_ada[f'df_global_{metric_names[i]}'] = df_exp_global"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_ada['df_global_Precision']"
      ],
      "metadata": {
        "id": "zsIKssxr4UhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_ada['df_global_Recall']"
      ],
      "metadata": {
        "id": "_x03_gMM4UhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_ada['df_global_F1-score']"
      ],
      "metadata": {
        "id": "XWVluLzD4UhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUMNWqEXZ_MY"
      },
      "source": [
        "**BREAK-DOWN, SHAP Y LIME:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keyhJMhdZ_MY"
      },
      "outputs": [],
      "source": [
        "#primero definimos el explainer\n",
        "exp = dx.Explainer(modelo_ada, x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olp3EnRT3grl"
      },
      "source": [
        "### **Instancia VP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5SIsPL93grl"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"break_down\",random_state=42)\n",
        "shap_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"shap\",random_state=42)\n",
        "lime_vp_max = exp.predict_surrogate(df_instancia_vp_max, random_state=42)\n",
        "\n",
        "breakdown_vp_df_max = breakdown_vp_max.result\n",
        "shap_vp_df_max = shap_vp_max.result\n",
        "lime_vp_df_max=lime_vp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_max.plot()"
      ],
      "metadata": {
        "id": "Ht2u59Iu3grl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_max.plot()"
      ],
      "metadata": {
        "id": "AE5WjJCd3grm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Phzd0mXp3grm"
      },
      "outputs": [],
      "source": [
        "lime_vp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlBCYJZv3grm"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_max = breakdown_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(index=[0, 26])\n",
        "breakdown_vp_df_max['sign'] = breakdown_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_max = shap_vp_df_max.tail(25)\n",
        "shap_vp_df_max['sign'] = shap_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_max = shap_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_max[\"Variable\"] = lime_vp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_max[\"Signo\"] = lime_vp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_max = lime_vp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_max['Ranking'] = breakdown_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_max['Ranking'] = shap_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_max = shap_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_max['Ranking'] = lime_vp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_max = lime_vp_df_max.head(5)\n",
        "lime_vp_df_max = lime_vp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(columns=['contribution'])\n",
        "shap_vp_df_max = shap_vp_df_max.drop(columns=['contribution'])\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.head(5)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.head(5)\n",
        "shap_vp_df_max = shap_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_max = lime_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_max)\n",
        "print(shap_vp_df_max)\n",
        "print(lime_vp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ze2xCRf83grm"
      },
      "outputs": [],
      "source": [
        "#lime_vp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v4n6e1F3grm"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_max['Variable'])\n",
        "shapley_features = list(shap_vp_df_max['Variable'])\n",
        "lime_features = list(lime_vp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_max[breakdown_vp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_max[shap_vp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_max[lime_vp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"line_removed\", \"file_modified\", \"developer_num\", \"file_removed\", \"file_added\", \"line_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "ZU6yh1h8myQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk_Y22Q-3grm"
      },
      "source": [
        "### **Instancia VP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsZGMjTT3grm"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"shap\",random_state=42)\n",
        "lime_vp_mediana = exp.predict_surrogate(df_instancia_vp_mediana, random_state=42)\n",
        "\n",
        "breakdown_vp_df_mediana = breakdown_vp_mediana.result\n",
        "shap_vp_df_mediana = shap_vp_mediana.result\n",
        "lime_vp_df_mediana=lime_vp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "QWV5TylQ3grn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "jSKhsLA33grn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix1yTqCv3grn"
      },
      "outputs": [],
      "source": [
        "lime_vp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HO_sOKZ3grn"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vp_df_mediana['sign'] = breakdown_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.tail(25)\n",
        "shap_vp_df_mediana['sign'] = shap_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_mediana[\"Variable\"] = lime_vp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_mediana[\"Signo\"] = lime_vp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_mediana['Ranking'] = breakdown_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_mediana['Ranking'] = shap_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_mediana['Ranking'] = lime_vp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.head(5)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(columns=['contribution'])\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.drop(columns=['contribution'])\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.head(5)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.head(5)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_mediana)\n",
        "print(shap_vp_df_mediana)\n",
        "print(lime_vp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwKsKKwC3grn"
      },
      "outputs": [],
      "source": [
        "#lime_vp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cta7LTc3grn"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vp_df_mediana['Variable'])\n",
        "lime_features = list(lime_vp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_mediana[breakdown_vp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_mediana[shap_vp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_mediana[lime_vp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"file_removed\", \"commit_num\", \"file_modified\", \"line_added\", \"file_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "oLYnVvJrm3Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA6gbnVr3grn"
      },
      "source": [
        "### **Instancia VP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DzGL9KZ3grn"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"break_down\",random_state=42)\n",
        "shap_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"shap\",random_state=42)\n",
        "lime_vp_min = exp.predict_surrogate(df_instancia_vp_min, random_state=42)\n",
        "\n",
        "breakdown_vp_df_min = breakdown_vp_min.result\n",
        "shap_vp_df_min = shap_vp_min.result\n",
        "lime_vp_df_min = lime_vp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_min.plot()"
      ],
      "metadata": {
        "id": "7Hk6J7pG3grn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_min.plot()"
      ],
      "metadata": {
        "id": "SSKc8Zzm3grn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfn5q0o-3gro"
      },
      "outputs": [],
      "source": [
        "lime_vp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuEpEElt3gro"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_min = breakdown_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(index=[0, 26])\n",
        "breakdown_vp_df_min['sign'] = breakdown_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_min = shap_vp_df_min.tail(25)\n",
        "shap_vp_df_min['sign'] = shap_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_min = shap_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_min[\"Variable\"] = lime_vp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_min[\"Signo\"] = lime_vp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_min = lime_vp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_min['Ranking'] = breakdown_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_min['Ranking'] = shap_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_min = shap_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_min['Ranking'] = lime_vp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_min = lime_vp_df_min.head(5)\n",
        "lime_vp_df_min = lime_vp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(columns=['contribution'])\n",
        "shap_vp_df_min = shap_vp_df_min.drop(columns=['contribution'])\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.head(5)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.head(5)\n",
        "shap_vp_df_min = shap_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_min = lime_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_min)\n",
        "print(shap_vp_df_min)\n",
        "print(lime_vp_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvQVMwbd3gro"
      },
      "outputs": [],
      "source": [
        "#lime_vp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKQQYAke3gro"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_min['Variable'])\n",
        "shapley_features = list(shap_vp_df_min['Variable'])\n",
        "lime_features = list(lime_vp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_min[breakdown_vp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_min[shap_vp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_min[lime_vp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"line_removed\", \"messages_median\", \"file_removed\", \"file_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "JAmxeriQm-QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VP General:**"
      ],
      "metadata": {
        "id": "Jr3br_jeR7Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "Vg-sZda5R7Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_ada_vp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_ada_vp"
      ],
      "metadata": {
        "id": "2EEBBLF1R7Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_ada_vp[(\"General\", \"Ranking\")] = df_resumen_ada_vp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_ada_vp[(\"General\", \"Conteo Total\")] = df_resumen_ada_vp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_ada_vp"
      ],
      "metadata": {
        "id": "rjmgvLHpR7Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_ada_vp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_ada_vp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_ada_vp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_ada_vp[(\"General\", \"Peso Conteo\")] = df_resumen_ada_vp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_ada_vp[(\"General\", \"Puntaje\")] = df_resumen_ada_vp[(\"General\", \"Peso Rango\")] + df_resumen_ada_vp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_ada_vp[(\"General\", \"Ranking\")] = df_resumen_ada_vp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_ada_vp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_ada_vp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_ada_vp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_ada_vp"
      ],
      "metadata": {
        "id": "J0VS0F8gR7Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_ada_vp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_ada_vp = df_resumen_ada_vp[new_columns]"
      ],
      "metadata": {
        "id": "cUj0dGq1R7Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_ada_vp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_ada_vp[(tech, \"Ranking Medio\")] = df_resumen_ada_vp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_ada_vp"
      ],
      "metadata": {
        "id": "oUN_2kLWR7Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BIzmSkT3gro"
      },
      "source": [
        "### **Instancia VN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzSuDF6V3gro"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"break_down\",random_state=42)\n",
        "shap_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"shap\",random_state=42)\n",
        "lime_vn_max = exp.predict_surrogate(df_instancia_vn_max, random_state=42)\n",
        "\n",
        "breakdown_vn_df_max = breakdown_vn_max.result\n",
        "shap_vn_df_max = shap_vn_max.result\n",
        "lime_vn_df_max = lime_vn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_max.plot()"
      ],
      "metadata": {
        "id": "j3AcnX9l3gro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_max.plot()"
      ],
      "metadata": {
        "id": "9S3whUht3gro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeS1Hr-t3gro"
      },
      "outputs": [],
      "source": [
        "lime_vn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH1BYgnj3grp"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_max = breakdown_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(index=[0, 26])\n",
        "breakdown_vn_df_max['sign'] = breakdown_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_max = shap_vn_df_max.tail(25)\n",
        "shap_vn_df_max['sign'] = shap_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_max = shap_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_max[\"Variable\"] = lime_vn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_max[\"Signo\"] = lime_vn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_max = lime_vn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_max['Ranking'] = breakdown_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_max['Ranking'] = shap_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_max = shap_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_max['Ranking'] = lime_vn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_max = lime_vn_df_max.head(5)\n",
        "lime_vn_df_max = lime_vn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(columns=['contribution'])\n",
        "shap_vn_df_max = shap_vn_df_max.drop(columns=['contribution'])\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.head(5)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.head(5)\n",
        "shap_vn_df_max = shap_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_max = lime_vn_df_max.reset_index(drop=True)\n",
        "lime_vn_df_max.at[2, 'Variable'] = 'commit_num'\n",
        "lime_vn_df_max.at[3, 'Variable'] = 'file_modified'\n",
        "\n",
        "print(breakdown_vn_df_max)\n",
        "print(shap_vn_df_max)\n",
        "print(lime_vn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e45IKul63grp"
      },
      "outputs": [],
      "source": [
        "#lime_vn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU6g5GxE3grp"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_max['Variable'])\n",
        "shapley_features = list(shap_vn_df_max['Variable'])\n",
        "lime_features = list(lime_vn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_max[breakdown_vn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_max[shap_vn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_max[lime_vn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"improve_frequency\",\"commit_num\", \"developer_num\", \"duration\", \"file_removed\", \"file_modified\", \"commit_density\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "nD6UQ6aw01iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZyQjozH3grp"
      },
      "source": [
        "### **Instancia VN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh8Dy-ca3grp"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"shap\",random_state=42)\n",
        "lime_vn_mediana = exp.predict_surrogate(df_instancia_vn_mediana, random_state=42)\n",
        "\n",
        "breakdown_vn_df_mediana = breakdown_vn_mediana.result\n",
        "shap_vn_df_mediana = shap_vn_mediana.result\n",
        "lime_vn_df_mediana = lime_vn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "q9gxVwyf3grp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "sKrnqE5e3grp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZIGmtoP3grp"
      },
      "outputs": [],
      "source": [
        "lime_vn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRB2KyWq3grp"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vn_df_mediana['sign'] = breakdown_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.tail(25)\n",
        "shap_vn_df_mediana['sign'] = shap_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_mediana[\"Variable\"] = lime_vn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_mediana[\"Signo\"] = lime_vn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_mediana['Ranking'] = breakdown_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_mediana['Ranking'] = shap_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_mediana['Ranking'] = lime_vn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.head(5)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(columns=['contribution'])\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.drop(columns=['contribution'])\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.head(5)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.head(5)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.reset_index(drop=True)\n",
        "lime_vn_df_mediana.at[3, 'Variable'] = 'developer_num'\n",
        "lime_vn_df_mediana.at[4, 'Variable'] = 'file_modified'\n",
        "\n",
        "print(breakdown_vn_df_mediana)\n",
        "print(shap_vn_df_mediana)\n",
        "print(lime_vn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "2U-PgPCZ3grq"
      },
      "outputs": [],
      "source": [
        "#lime_vn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euwUPfCd3grq"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vn_df_mediana['Variable'])\n",
        "lime_features = list(lime_vn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_mediana[breakdown_vn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_mediana[shap_vn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_mediana[lime_vn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"line_removed\", \"file_added\", \"file_removed\", \"file_modified\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "-Y7ErdTZ07i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR9U5g0W3grq"
      },
      "source": [
        "### **Instancia VN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2gHYJS-3grq"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"break_down\",random_state=42)\n",
        "shap_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"shap\",random_state=42)\n",
        "lime_vn_min = exp.predict_surrogate(df_instancia_vn_min, random_state=42)\n",
        "\n",
        "breakdown_vn_df_min = breakdown_vn_min.result\n",
        "shap_vn_df_min = shap_vn_min.result\n",
        "lime_vn_df_min = lime_vn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_min.plot()"
      ],
      "metadata": {
        "id": "_aEnV4BG3grq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_min.plot()"
      ],
      "metadata": {
        "id": "-A5bcZPa3grq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmtaj_Qs3grq"
      },
      "outputs": [],
      "source": [
        "lime_vn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i0JBNsD3grq"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_min = breakdown_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(index=[0, 26])\n",
        "breakdown_vn_df_min['sign'] = breakdown_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_min = shap_vn_df_min.tail(25)\n",
        "shap_vn_df_min['sign'] = shap_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_min = shap_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_min[\"Variable\"] = lime_vn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_min[\"Signo\"] = lime_vn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_min = lime_vn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_min['Ranking'] = breakdown_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_min['Ranking'] = shap_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_min = shap_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_min['Ranking'] = lime_vn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_min = lime_vn_df_min.head(5)\n",
        "lime_vn_df_min = lime_vn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(columns=['contribution'])\n",
        "shap_vn_df_min = shap_vn_df_min.drop(columns=['contribution'])\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.head(5)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.head(5)\n",
        "shap_vn_df_min = shap_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_min = lime_vn_df_min.reset_index(drop=True)\n",
        "lime_vn_df_min.at[4, 'Variable'] = 'file_modified'\n",
        "\n",
        "print(breakdown_vn_df_min)\n",
        "print(shap_vn_df_min)\n",
        "print(lime_vn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLpIQ9Pf3grr"
      },
      "outputs": [],
      "source": [
        "#lime_vn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGCbYIeY3grr"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_min['Variable'])\n",
        "shapley_features = list(shap_vn_df_min['Variable'])\n",
        "lime_features = list(lime_vn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_min[breakdown_vn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_min[shap_vn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_min[lime_vn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"messages_median\", \"messages_min\", \"developer_num\", \"commit_num\", \"file_removed\", \"file_added\", \"file_modified\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "2NCUEL-L1CSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VN General:**"
      ],
      "metadata": {
        "id": "2W3_rS78R7Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "whACK-cOR7Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_ada_vn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_ada_vn"
      ],
      "metadata": {
        "id": "_UGBxkUAR7Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_ada_vn[(\"General\", \"Ranking\")] = df_resumen_ada_vn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_ada_vn[(\"General\", \"Conteo Total\")] = df_resumen_ada_vn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_ada_vn"
      ],
      "metadata": {
        "id": "Xzf7SdwdR7Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_ada_vn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_ada_vn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_ada_vn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_ada_vn[(\"General\", \"Peso Conteo\")] = df_resumen_ada_vn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_ada_vn[(\"General\", \"Puntaje\")] = df_resumen_ada_vn[(\"General\", \"Peso Rango\")] + df_resumen_ada_vn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_ada_vn[(\"General\", \"Ranking\")] = df_resumen_ada_vn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_ada_vn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_ada_vn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_ada_vn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_ada_vn"
      ],
      "metadata": {
        "id": "0vzZKi-bR7Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_ada_vn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_ada_vn = df_resumen_ada_vn[new_columns]"
      ],
      "metadata": {
        "id": "N8_prreSR7Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_ada_vn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_ada_vn[(tech, \"Ranking Medio\")] = df_resumen_ada_vn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_ada_vn"
      ],
      "metadata": {
        "id": "27u-K7MgR7Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFcKK_eK3grr"
      },
      "source": [
        "### **Instancia FP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ3sI3Bl3grr"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"break_down\",random_state=42)\n",
        "shap_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"shap\",random_state=42)\n",
        "lime_fp_max = exp.predict_surrogate(df_instancia_fp_max, random_state=42)\n",
        "\n",
        "breakdown_fp_df_max = breakdown_fp_max.result\n",
        "shap_fp_df_max = shap_fp_max.result\n",
        "lime_fp_df_max=lime_fp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_max.plot()"
      ],
      "metadata": {
        "id": "Q18EspNt3grr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_max.plot()"
      ],
      "metadata": {
        "id": "K662bVY03grr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XOOxVir3grr"
      },
      "outputs": [],
      "source": [
        "lime_fp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_bIjIsJ3grr"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_max = breakdown_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(index=[0, 26])\n",
        "breakdown_fp_df_max['sign'] = breakdown_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_max = shap_fp_df_max.tail(25)\n",
        "shap_fp_df_max['sign'] = shap_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_max = shap_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_max[\"Variable\"] = lime_fp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_max[\"Signo\"] = lime_fp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_max = lime_fp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_max['Ranking'] = breakdown_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_max['Ranking'] = shap_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_max = shap_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_max['Ranking'] = lime_fp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_max = lime_fp_df_max.head(5)\n",
        "lime_fp_df_max = lime_fp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(columns=['contribution'])\n",
        "shap_fp_df_max = shap_fp_df_max.drop(columns=['contribution'])\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.head(5)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.head(5)\n",
        "shap_fp_df_max = shap_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_max = lime_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_max)\n",
        "print(shap_fp_df_max)\n",
        "print(lime_fp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEz5C_hH3grr"
      },
      "outputs": [],
      "source": [
        "#lime_fp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj-agbxv3grr"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_max['Variable'])\n",
        "shapley_features = list(shap_fp_df_max['Variable'])\n",
        "lime_features = list(lime_fp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_max[breakdown_fp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_max[shap_fp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_max[lime_fp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"line_removed\", \"line_added\", \"file_modified\", \"file_removed\", \"file_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "kplRzpDKDVXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufTEqPpn3grs"
      },
      "source": [
        "### **Instancia FP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvHB9Fzk3grs"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"shap\",random_state=42)\n",
        "lime_fp_mediana = exp.predict_surrogate(df_instancia_fp_mediana, random_state=42)\n",
        "\n",
        "breakdown_fp_df_mediana = breakdown_fp_mediana.result\n",
        "shap_fp_df_mediana = shap_fp_mediana.result\n",
        "lime_fp_df_mediana=lime_fp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "dYZYE60b3grs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "JtOfpSwR3grs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCZ4lRg73grs"
      },
      "outputs": [],
      "source": [
        "lime_fp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqcHyQxL3grs"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fp_df_mediana['sign'] = breakdown_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.tail(25)\n",
        "shap_fp_df_mediana['sign'] = shap_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_mediana[\"Variable\"] = lime_fp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_mediana[\"Signo\"] = lime_fp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_mediana['Ranking'] = breakdown_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_mediana['Ranking'] = shap_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_mediana['Ranking'] = lime_fp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.head(5)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(columns=['contribution'])\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.drop(columns=['contribution'])\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.head(5)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.head(5)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_mediana)\n",
        "print(shap_fp_df_mediana)\n",
        "print(lime_fp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCCmHORw3grs"
      },
      "outputs": [],
      "source": [
        "#lime_fp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9K8Vpxt3grt"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fp_df_mediana['Variable'])\n",
        "lime_features = list(lime_fp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_mediana[breakdown_fp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_mediana[shap_fp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_mediana[lime_fp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"file_added\", \"developer_num\", \"line_added\",  \"file_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "nN-A-keBDdV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd2W2d_G3grt"
      },
      "source": [
        "### **Instancia FP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMmSJ-6f3grt"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"break_down\",random_state=42)\n",
        "shap_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"shap\",random_state=42)\n",
        "lime_fp_min = exp.predict_surrogate(df_instancia_fp_min, random_state=42)\n",
        "\n",
        "breakdown_fp_df_min = breakdown_fp_min.result\n",
        "shap_fp_df_min = shap_fp_min.result\n",
        "lime_fp_df_min = lime_fp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_min.plot()"
      ],
      "metadata": {
        "id": "kQQmjAdh3grt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_min.plot()"
      ],
      "metadata": {
        "id": "f0HSzOZu3grt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUcYOnDj3grt"
      },
      "outputs": [],
      "source": [
        "lime_fp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJH4E8BZ3gru"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_min = breakdown_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(index=[0, 26])\n",
        "breakdown_fp_df_min['sign'] = breakdown_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_min = shap_fp_df_min.tail(25)\n",
        "shap_fp_df_min['sign'] = shap_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_min = shap_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_min[\"Variable\"] = lime_fp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_min[\"Signo\"] = lime_fp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_min = lime_fp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_min['Ranking'] = breakdown_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_min['Ranking'] = shap_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_min = shap_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_min['Ranking'] = lime_fp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_min = lime_fp_df_min.head(5)\n",
        "lime_fp_df_min = lime_fp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(columns=['contribution'])\n",
        "shap_fp_df_min = shap_fp_df_min.drop(columns=['contribution'])\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.head(5)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.head(5)\n",
        "shap_fp_df_min = shap_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_min = lime_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_min)\n",
        "print(shap_fp_df_min)\n",
        "print(lime_fp_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kciDWXwk3gru"
      },
      "outputs": [],
      "source": [
        "#lime_fp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fkySaLI3gru"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_min['Variable'])\n",
        "shapley_features = list(shap_fp_df_min['Variable'])\n",
        "lime_features = list(lime_fp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_min[breakdown_fp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_min[shap_fp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_min[lime_fp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"file_added\", \"line_added\", \"file_removed\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "1fCh9qKaDidj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FP General:**"
      ],
      "metadata": {
        "id": "Fe4BuK-eR7Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "QLZd3wm-R7Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_ada_fp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_ada_fp"
      ],
      "metadata": {
        "id": "9BkSyoVIR7X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_ada_fp[(\"General\", \"Ranking\")] = df_resumen_ada_fp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_ada_fp[(\"General\", \"Conteo Total\")] = df_resumen_ada_fp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_ada_fp"
      ],
      "metadata": {
        "id": "8kCoR0oPR7X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_ada_fp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_ada_fp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_ada_fp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_ada_fp[(\"General\", \"Peso Conteo\")] = df_resumen_ada_fp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_ada_fp[(\"General\", \"Puntaje\")] = df_resumen_ada_fp[(\"General\", \"Peso Rango\")] + df_resumen_ada_fp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_ada_fp[(\"General\", \"Ranking\")] = df_resumen_ada_fp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_ada_fp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_ada_fp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_ada_fp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_ada_fp"
      ],
      "metadata": {
        "id": "b7jlqgI1R7X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_ada_fp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_ada_fp = df_resumen_ada_fp[new_columns]"
      ],
      "metadata": {
        "id": "I2cLchpgR7X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_ada_fp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_ada_fp[(tech, \"Ranking Medio\")] = df_resumen_ada_fp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_ada_fp"
      ],
      "metadata": {
        "id": "1E-uS1eGR7X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTkhm3uW3gru"
      },
      "source": [
        "### **Instancia FN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA_2xhTJ3gru"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"break_down\",random_state=42)\n",
        "shap_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"shap\",random_state=42)\n",
        "lime_fn_max = exp.predict_surrogate(df_instancia_fn_max, random_state=42)\n",
        "\n",
        "breakdown_fn_df_max = breakdown_fn_max.result\n",
        "shap_fn_df_max = shap_fn_max.result\n",
        "lime_fn_df_max=lime_fn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_max.plot()"
      ],
      "metadata": {
        "id": "2FzaGvkf3grv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_max.plot()"
      ],
      "metadata": {
        "id": "NIpp3Y9V3grv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU4XnOZb3grv"
      },
      "outputs": [],
      "source": [
        "lime_fn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkDzcfT63grv"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_max = breakdown_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(index=[0, 26])\n",
        "breakdown_fn_df_max['sign'] = breakdown_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_max = shap_fn_df_max.tail(25)\n",
        "shap_fn_df_max['sign'] = shap_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_max = shap_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_max[\"Variable\"] = lime_fn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_max[\"Signo\"] = lime_fn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_max = lime_fn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_max['Ranking'] = breakdown_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_max['Ranking'] = shap_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_max = shap_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_max['Ranking'] = lime_fn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_max = lime_fn_df_max.head(5)\n",
        "lime_fn_df_max = lime_fn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(columns=['contribution'])\n",
        "shap_fn_df_max = shap_fn_df_max.drop(columns=['contribution'])\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.head(5)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.head(5)\n",
        "shap_fn_df_max = shap_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_max = lime_fn_df_max.reset_index(drop=True)\n",
        "lime_fn_df_max.at[3, 'Variable'] = 'developer_num'\n",
        "lime_fn_df_max.at[4, 'Variable'] = 'file_modified'\n",
        "\n",
        "print(breakdown_fn_df_max)\n",
        "print(shap_fn_df_max)\n",
        "print(lime_fn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJRd5GND3grv"
      },
      "outputs": [],
      "source": [
        "#lime_fn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We2gSJFt3grv"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_max['Variable'])\n",
        "shapley_features = list(shap_fn_df_max['Variable'])\n",
        "lime_features = list(lime_fn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_max[breakdown_fn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_max[shap_fn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_max[lime_fn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"use_frequency\", \"commit_density\", \"file_removed\", \"file_modified\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "GaDHRDMhO6An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTFjpJjL3grw"
      },
      "source": [
        "### **Instancia FN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMDchf2v3grw"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"shap\",random_state=42)\n",
        "lime_fn_mediana = exp.predict_surrogate(df_instancia_fn_mediana, random_state=42)\n",
        "\n",
        "breakdown_fn_df_mediana = breakdown_fn_mediana.result\n",
        "shap_fn_df_mediana = shap_fn_mediana.result\n",
        "lime_fn_df_mediana=lime_fn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "P7E7TjCj3grw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "o6CVf1q53grw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjfNueQW3grw"
      },
      "outputs": [],
      "source": [
        "lime_fn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYwisGPe3grw"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fn_df_mediana['sign'] = breakdown_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.tail(25)\n",
        "shap_fn_df_mediana['sign'] = shap_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_mediana[\"Variable\"] = lime_fn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_mediana[\"Signo\"] = lime_fn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_mediana['Ranking'] = breakdown_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_mediana['Ranking'] = shap_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_mediana['Ranking'] = lime_fn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.head(5)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(columns=['contribution'])\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.drop(columns=['contribution'])\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.head(5)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.head(5)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fn_df_mediana)\n",
        "print(shap_fn_df_mediana)\n",
        "print(lime_fn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD8zS1ox3grw"
      },
      "outputs": [],
      "source": [
        "#lime_fn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knrAeoTR3grx"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fn_df_mediana['Variable'])\n",
        "lime_features = list(lime_fn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_mediana[breakdown_fn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_mediana[shap_fn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_mediana[lime_fn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"line_added\", \"file_modified\", \"file_removed\", \"file_added\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "X7c6PjCYPW2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xvVnbWo3grx"
      },
      "source": [
        "### **Instancia FN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYLs0ymH3grx"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"break_down\",random_state=42)\n",
        "shap_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"shap\",random_state=42)\n",
        "lime_fn_min = exp.predict_surrogate(df_instancia_fn_min, random_state=42)\n",
        "\n",
        "breakdown_fn_df_min = breakdown_fn_min.result\n",
        "shap_fn_df_min = shap_fn_min.result\n",
        "lime_fn_df_min = lime_fn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_min.plot()"
      ],
      "metadata": {
        "id": "A5ZX0BJX3grx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_min.plot()"
      ],
      "metadata": {
        "id": "2ygGPOc93grx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNoLFOY03grx"
      },
      "outputs": [],
      "source": [
        "lime_fn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpt619an3gry"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_min = breakdown_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(index=[0, 26])\n",
        "breakdown_fn_df_min['sign'] = breakdown_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_min = shap_fn_df_min.tail(25)\n",
        "shap_fn_df_min['sign'] = shap_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_min = shap_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_min[\"Variable\"] = lime_fn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_min[\"Signo\"] = lime_fn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_min = lime_fn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_min['Ranking'] = breakdown_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_min['Ranking'] = shap_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_min = shap_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_min['Ranking'] = lime_fn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_min = lime_fn_df_min.head(5)\n",
        "lime_fn_df_min = lime_fn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(columns=['contribution'])\n",
        "shap_fn_df_min = shap_fn_df_min.drop(columns=['contribution'])\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.head(5)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.head(5)\n",
        "shap_fn_df_min = shap_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_min = lime_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fn_df_min)\n",
        "print(shap_fn_df_min)\n",
        "print(lime_fn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g7Sjmyd3gry"
      },
      "outputs": [],
      "source": [
        "#lime_fn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UusGvKd3gry"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_min['Variable'])\n",
        "shapley_features = list(shap_fn_df_min['Variable'])\n",
        "lime_features = list(lime_fn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_min[breakdown_fn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_min[shap_fn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_min[lime_fn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"duration\", \"commit_num\", \"line_removed\", \"file_removed\", \"file_added\", \"commit_density\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "PKOYmJBEPrNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FN General:**"
      ],
      "metadata": {
        "id": "p90JYNfmR7X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "0x0_lyl9R7X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_ada_fn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_ada_fn"
      ],
      "metadata": {
        "id": "kMglRZQgR7X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_ada_fn[(\"General\", \"Ranking\")] = df_resumen_ada_fn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_ada_fn[(\"General\", \"Conteo Total\")] = df_resumen_ada_fn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_ada_fn"
      ],
      "metadata": {
        "id": "hH1TdapsR7X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_ada_fn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_ada_fn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_ada_fn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_ada_fn[(\"General\", \"Peso Conteo\")] = df_resumen_ada_fn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_ada_fn[(\"General\", \"Puntaje\")] = df_resumen_ada_fn[(\"General\", \"Peso Rango\")] + df_resumen_ada_fn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_ada_fn[(\"General\", \"Ranking\")] = df_resumen_ada_fn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_ada_fn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_ada_fn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_ada_fn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_ada_fn"
      ],
      "metadata": {
        "id": "6Tu4xH-tR7X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_ada_fn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_ada_fn = df_resumen_ada_fn[new_columns]"
      ],
      "metadata": {
        "id": "C85U4sy2R7X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_ada_fn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_ada_fn[(tech, \"Ranking Medio\")] = df_resumen_ada_fn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_ada_fn"
      ],
      "metadata": {
        "id": "2RoEH08LR7X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXD_xIQEjo3r"
      },
      "source": [
        "## **RUSBoost:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJw4Kuinjo30"
      },
      "source": [
        "**FEATURE IMPORTANCE**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permu = permutation_importance(modelo_rus, x_test, y_test, n_repeats=20, random_state=42, n_jobs=2, scoring='f1')\n",
        "\n",
        "# Umbral para valores significativos\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Filtrar los caracteristicas\n",
        "significant_indices = permu.importances_mean > importance_threshold\n",
        "permu_importances = pd.Series(permu.importances_mean.round(3), index=feature_names)[significant_indices]\n",
        "permu_std = permu.importances_std[significant_indices]\n",
        "\n",
        "# Crear la representación gráfica\n",
        "fig, ax = plt.subplots()\n",
        "permu_importances.plot.bar(yerr=permu_std, ax=ax)\n",
        "ax.set_title(\"Feature importances using permutation on full model\")\n",
        "ax.set_ylabel(\"Mean accuracy decrease\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dNySXk9c-Y5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = ['precision', 'recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "permu_score = permutation_importance(modelo_rus, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Itera a través de las métricas\n",
        "for i, metric in enumerate(scoring):\n",
        "    permu = permu_score[metric]\n",
        "\n",
        "    # Filtra las características que cumplen la condición del umbral\n",
        "    significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "    sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "    importances_mean = permu.importances_mean[significant_indices]\n",
        "    importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "    # Ordena los datos por importancia de mayor a menor\n",
        "    sorted_indices = np.argsort(importances_mean)[::1]\n",
        "    sorted_feature_names = [sorted_feature_names[j] for j in sorted_indices]\n",
        "    importances_mean = importances_mean[sorted_indices]\n",
        "    importances_std = importances_std[sorted_indices]\n",
        "\n",
        "    # Crea la representación gráfica en el subplot correspondiente\n",
        "    axs[i].barh(range(len(sorted_feature_names)), importances_mean, xerr=importances_std, align='center')\n",
        "    axs[i].set_yticks(range(len(sorted_feature_names)))\n",
        "    axs[i].set_yticklabels(sorted_feature_names)\n",
        "    axs[i].set_xlabel('Valor Importancia')\n",
        "    axs[i].set_title(f'Importancia por Permutación para {metric_names[i]}')\n",
        "\n",
        "# Ajusta los espacios entre subplots y muestra la figura\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zsRyHDwa-Y5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-bNPwaT-Y5i"
      },
      "outputs": [],
      "source": [
        "scoring = ['precision','recall','f1']\n",
        "metric_names = ['Precision', 'Recall', 'F1-score']\n",
        "\n",
        "# Umbral para importancias significativas\n",
        "importance_threshold = 0.01\n",
        "\n",
        "# Crea un diccionario para almacenar los DataFrames\n",
        "results_global_rus = {}\n",
        "\n",
        "permu_score = permutation_importance(modelo_rus, x_test, y_test, n_repeats=20, random_state=42, scoring=scoring)\n",
        "for i, metric in enumerate(scoring):\n",
        "  permu = permu_score[metric]\n",
        "\n",
        "  # Filtra las características que cumplen la condición\n",
        "  significant_indices = [j for j in range(len(permu.importances_mean)) if permu.importances_mean[j] > importance_threshold]\n",
        "  sorted_feature_names = [feature_names[j] for j in significant_indices]\n",
        "  importances_mean = permu.importances_mean[significant_indices]\n",
        "  importances_std = permu.importances_std[significant_indices]\n",
        "\n",
        "  # Crear un DataFrame con los resultados\n",
        "  df_exp_global = pd.DataFrame({'Feature': sorted_feature_names,\n",
        "                       'Importance_Mean': importances_mean,\n",
        "                       'Importance_Std': importances_std})\n",
        "\n",
        "  # Ordenar el DataFrame por importance_mean en orden descendente\n",
        "  df_exp_global = df_exp_global.sort_values(by='Importance_Mean', ascending=False)\n",
        "\n",
        "  # Asignar el DataFrame al diccionario con el nombre de la métrica\n",
        "  results_global_rus[f'df_global_{metric_names[i]}'] = df_exp_global"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_rus['df_global_Precision']"
      ],
      "metadata": {
        "id": "2ZmBeHa9-Y5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_rus['df_global_Recall']"
      ],
      "metadata": {
        "id": "2eXveVrS-Y5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_global_rus['df_global_F1-score']"
      ],
      "metadata": {
        "id": "qHDlHeKw-Y5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1ZhCC1Hjo32"
      },
      "source": [
        "**BREAK-DOWN, SHAP Y LIME:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcMchUZ8jo32"
      },
      "outputs": [],
      "source": [
        "#primero definimos el explainer\n",
        "exp = dx.Explainer(modelo_rus, x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1WP3kzn35PQ"
      },
      "source": [
        "### **Instancia VP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQl43CoF35PQ"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"break_down\",random_state=42)\n",
        "shap_vp_max = exp.predict_parts(df_instancia_vp_max, type=\"shap\",random_state=42)\n",
        "lime_vp_max = exp.predict_surrogate(df_instancia_vp_max, random_state=42)\n",
        "\n",
        "breakdown_vp_df_max = breakdown_vp_max.result\n",
        "shap_vp_df_max = shap_vp_max.result\n",
        "lime_vp_df_max=lime_vp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_max.plot()"
      ],
      "metadata": {
        "id": "PqppTW1235PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_max.plot()"
      ],
      "metadata": {
        "id": "yFjZzwom35PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsVvlGHT35PR"
      },
      "outputs": [],
      "source": [
        "lime_vp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPEkbO8835PR"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_max = breakdown_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(index=[0, 26])\n",
        "breakdown_vp_df_max['sign'] = breakdown_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_max = shap_vp_df_max.tail(25)\n",
        "shap_vp_df_max['sign'] = shap_vp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_max = shap_vp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_max[\"Variable\"] = lime_vp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_max[\"Signo\"] = lime_vp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_max = lime_vp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_max['Ranking'] = breakdown_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_max['Ranking'] = shap_vp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_max = shap_vp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_max['Ranking'] = lime_vp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_max = lime_vp_df_max.head(5)\n",
        "lime_vp_df_max = lime_vp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.drop(columns=['contribution'])\n",
        "shap_vp_df_max = shap_vp_df_max.drop(columns=['contribution'])\n",
        "lime_vp_df_max = lime_vp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.head(5)\n",
        "breakdown_vp_df_max = breakdown_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_max = shap_vp_df_max.head(5)\n",
        "shap_vp_df_max = shap_vp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_max = lime_vp_df_max.reset_index(drop=True)\n",
        "lime_vp_df_max.at[4, 'Variable'] = 'messages_min'\n",
        "\n",
        "print(breakdown_vp_df_max)\n",
        "print(shap_vp_df_max)\n",
        "print(lime_vp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b70bJd635PR"
      },
      "outputs": [],
      "source": [
        "#lime_vp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bei3KUTj35PR"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_max['Variable'])\n",
        "shapley_features = list(shap_vp_df_max['Variable'])\n",
        "lime_features = list(lime_vp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_max[breakdown_vp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_max[shap_vp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_max[lime_vp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"line_added\", \"commit_num\", \"developer_num\", \"messages_min\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "K5yTkJQDQNE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4fSRDww35PR"
      },
      "source": [
        "### **Instancia VP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHxGZpfz35PS"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vp_mediana = exp.predict_parts(df_instancia_vp_mediana, type=\"shap\",random_state=42)\n",
        "lime_vp_mediana = exp.predict_surrogate(df_instancia_vp_mediana, random_state=42)\n",
        "\n",
        "breakdown_vp_df_mediana = breakdown_vp_mediana.result\n",
        "shap_vp_df_mediana = shap_vp_mediana.result\n",
        "lime_vp_df_mediana=lime_vp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "xdgK-oUU35PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_mediana.plot()"
      ],
      "metadata": {
        "id": "hJ124PiK35PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43wKMzdj35PS"
      },
      "outputs": [],
      "source": [
        "lime_vp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQUxk5x935PS"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vp_df_mediana['sign'] = breakdown_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.tail(25)\n",
        "shap_vp_df_mediana['sign'] = shap_vp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_mediana[\"Variable\"] = lime_vp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_mediana[\"Signo\"] = lime_vp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_mediana['Ranking'] = breakdown_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_mediana['Ranking'] = shap_vp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_mediana['Ranking'] = lime_vp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.head(5)\n",
        "lime_vp_df_mediana = lime_vp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.drop(columns=['contribution'])\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.drop(columns=['contribution'])\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.head(5)\n",
        "breakdown_vp_df_mediana = breakdown_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.head(5)\n",
        "shap_vp_df_mediana = shap_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_mediana = lime_vp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_vp_df_mediana)\n",
        "print(shap_vp_df_mediana)\n",
        "print(lime_vp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtLptgUD35PS"
      },
      "outputs": [],
      "source": [
        "#lime_vp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QEjwj_M35PS"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vp_df_mediana['Variable'])\n",
        "lime_features = list(lime_vp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_mediana[breakdown_vp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_mediana[shap_vp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_mediana[lime_vp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"line_added\", \"commit_num\", \"developer_num\", \"messages_min\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "p_r-SjQJQOjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2LQkCrV35PS"
      },
      "source": [
        "### **Instancia VP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdQRsYKb35PS"
      },
      "outputs": [],
      "source": [
        "breakdown_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"break_down\",random_state=42)\n",
        "shap_vp_min = exp.predict_parts(df_instancia_vp_min, type=\"shap\",random_state=42)\n",
        "lime_vp_min = exp.predict_surrogate(df_instancia_vp_min, random_state=42)\n",
        "\n",
        "breakdown_vp_df_min = breakdown_vp_min.result\n",
        "shap_vp_df_min = shap_vp_min.result\n",
        "lime_vp_df_min = lime_vp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_min.plot()"
      ],
      "metadata": {
        "id": "aqTT4ydh35PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vp_min.plot()"
      ],
      "metadata": {
        "id": "jiH1HdPJ35PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34CWlKSJ35PT"
      },
      "outputs": [],
      "source": [
        "lime_vp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vp_df_min = breakdown_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(index=[0, 26])\n",
        "breakdown_vp_df_min['sign'] = breakdown_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vp_df_min = shap_vp_df_min.tail(25)\n",
        "shap_vp_df_min['sign'] = shap_vp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vp_df_min = shap_vp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vp_df_min[\"Variable\"] = lime_vp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vp_df_min[\"Signo\"] = lime_vp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vp_df_min = lime_vp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vp_df_min['Ranking'] = breakdown_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vp_df_min['Ranking'] = shap_vp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vp_df_min = shap_vp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vp_df_min['Ranking'] = lime_vp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vp_df_min = lime_vp_df_min.head(5)\n",
        "lime_vp_df_min = lime_vp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.drop(columns=['contribution'])\n",
        "shap_vp_df_min = shap_vp_df_min.drop(columns=['contribution'])\n",
        "lime_vp_df_min = lime_vp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.head(5)\n",
        "breakdown_vp_df_min = breakdown_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vp_df_min = shap_vp_df_min.head(5)\n",
        "shap_vp_df_min = shap_vp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vp_df_min = lime_vp_df_min.reset_index(drop=True)\n",
        "lime_vp_df_min.at[2, 'Variable'] = 'line_added'\n",
        "\n",
        "print(breakdown_vp_df_min)\n",
        "print(shap_vp_df_min)\n",
        "print(lime_vp_df_min)"
      ],
      "metadata": {
        "id": "arDJ_-lFjJkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o17TR4wT35PT"
      },
      "outputs": [],
      "source": [
        "#lime_vp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8244Ntd35PT"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vp_df_min['Variable'])\n",
        "shapley_features = list(shap_vp_df_min['Variable'])\n",
        "lime_features = list(lime_vp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vp_df_min[breakdown_vp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vp_df_min[shap_vp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vp_df_min[lime_vp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"line_added\", \"messages_min\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "XSShyrumQSYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VP General:**"
      ],
      "metadata": {
        "id": "G5W9wa7aSeoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "c-qkhLhXSeop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_rus_vp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_rus_vp"
      ],
      "metadata": {
        "id": "1D5lb971Seoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_rus_vp[(\"General\", \"Ranking\")] = df_resumen_rus_vp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_rus_vp[(\"General\", \"Conteo Total\")] = df_resumen_rus_vp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_rus_vp"
      ],
      "metadata": {
        "id": "M7VswRzpSeor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_rus_vp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_rus_vp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_rus_vp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_rus_vp[(\"General\", \"Peso Conteo\")] = df_resumen_rus_vp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_rus_vp[(\"General\", \"Puntaje\")] = df_resumen_rus_vp[(\"General\", \"Peso Rango\")] + df_resumen_rus_vp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_rus_vp[(\"General\", \"Ranking\")] = df_resumen_rus_vp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_rus_vp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rus_vp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rus_vp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_rus_vp"
      ],
      "metadata": {
        "id": "BPnXqtgjSeos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_rus_vp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_rus_vp = df_resumen_rus_vp[new_columns]"
      ],
      "metadata": {
        "id": "VQ4pC3sNSeos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_rus_vp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_rus_vp[(tech, \"Ranking Medio\")] = df_resumen_rus_vp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_rus_vp"
      ],
      "metadata": {
        "id": "enO_M504Seot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuOZiRak35PT"
      },
      "source": [
        "### **Instancia VN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueTX_noG35PT"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"break_down\",random_state=42)\n",
        "shap_vn_max = exp.predict_parts(df_instancia_vn_max, type=\"shap\",random_state=42)\n",
        "lime_vn_max = exp.predict_surrogate(df_instancia_vn_max, random_state=42)\n",
        "\n",
        "breakdown_vn_df_max = breakdown_vn_max.result\n",
        "shap_vn_df_max = shap_vn_max.result\n",
        "lime_vn_df_max = lime_vn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_max.plot()"
      ],
      "metadata": {
        "id": "EBBow7vT35PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_max.plot()"
      ],
      "metadata": {
        "id": "xbtFnty335PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMRjin2s35PU"
      },
      "outputs": [],
      "source": [
        "lime_vn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svqSbrAw35PU"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_max = breakdown_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(index=[0, 26])\n",
        "breakdown_vn_df_max['sign'] = breakdown_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_max = shap_vn_df_max.tail(25)\n",
        "shap_vn_df_max['sign'] = shap_vn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_max = shap_vn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_max[\"Variable\"] = lime_vn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_max[\"Signo\"] = lime_vn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_max = lime_vn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_max['Ranking'] = breakdown_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_max['Ranking'] = shap_vn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_max = shap_vn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_max['Ranking'] = lime_vn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_max = lime_vn_df_max.head(5)\n",
        "lime_vn_df_max = lime_vn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.drop(columns=['contribution'])\n",
        "shap_vn_df_max = shap_vn_df_max.drop(columns=['contribution'])\n",
        "lime_vn_df_max = lime_vn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.head(5)\n",
        "breakdown_vn_df_max = breakdown_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_max = shap_vn_df_max.head(5)\n",
        "shap_vn_df_max = shap_vn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_max = lime_vn_df_max.reset_index(drop=True)\n",
        "lime_vn_df_max.at[1, 'Variable'] = 'line_added'\n",
        "lime_vn_df_max.at[2, 'Variable'] = 'commit_num'\n",
        "lime_vn_df_max.at[3, 'Variable'] = 'developer_num'\n",
        "\n",
        "print(breakdown_vn_df_max)\n",
        "print(shap_vn_df_max)\n",
        "print(lime_vn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_xhW8os35PU"
      },
      "outputs": [],
      "source": [
        "#lime_vn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t96dnBcX35PU"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_max['Variable'])\n",
        "shapley_features = list(shap_vn_df_max['Variable'])\n",
        "lime_features = list(lime_vn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_max[breakdown_vn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_max[shap_vn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_max[lime_vn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"messages_min\", \"line_added\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "GZpqLUfBREX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPvIaUir35PU"
      },
      "source": [
        "### **Instancia VN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFJ1oahg35PU"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_vn_mediana = exp.predict_parts(df_instancia_vn_mediana, type=\"shap\",random_state=42)\n",
        "lime_vn_mediana = exp.predict_surrogate(df_instancia_vn_mediana, random_state=42)\n",
        "\n",
        "breakdown_vn_df_mediana = breakdown_vn_mediana.result\n",
        "shap_vn_df_mediana = shap_vn_mediana.result\n",
        "lime_vn_df_mediana = lime_vn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "XSWsxBO735PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_mediana.plot()"
      ],
      "metadata": {
        "id": "O-6i79EB35PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFPyG9yZ35PU"
      },
      "outputs": [],
      "source": [
        "lime_vn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7JjyDZH35PU"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_vn_df_mediana['sign'] = breakdown_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.tail(25)\n",
        "shap_vn_df_mediana['sign'] = shap_vn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_mediana[\"Variable\"] = lime_vn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_mediana[\"Signo\"] = lime_vn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_mediana['Ranking'] = breakdown_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_mediana['Ranking'] = shap_vn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_mediana['Ranking'] = lime_vn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.head(5)\n",
        "lime_vn_df_mediana = lime_vn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.drop(columns=['contribution'])\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.drop(columns=['contribution'])\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.head(5)\n",
        "breakdown_vn_df_mediana = breakdown_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.head(5)\n",
        "shap_vn_df_mediana = shap_vn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_mediana = lime_vn_df_mediana.reset_index(drop=True)\n",
        "lime_vn_df_mediana.at[1, 'Variable'] = 'developer_num'\n",
        "lime_vn_df_mediana.at[2, 'Variable'] = 'line_added'\n",
        "\n",
        "print(breakdown_vn_df_mediana)\n",
        "print(shap_vn_df_mediana)\n",
        "print(lime_vn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fOhWUOAf35PV"
      },
      "outputs": [],
      "source": [
        "#lime_vn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6alybsq35PV"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_vn_df_mediana['Variable'])\n",
        "lime_features = list(lime_vn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_mediana[breakdown_vn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_mediana[shap_vn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_mediana[lime_vn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"line_added\", \"messages_min\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "S-2yoYAsRWD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYiuTOr_35PV"
      },
      "source": [
        "### **Instancia VN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHxDFNo035PV"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"break_down\",random_state=42)\n",
        "shap_vn_min = exp.predict_parts(df_instancia_vn_min, type=\"shap\",random_state=42)\n",
        "lime_vn_min = exp.predict_surrogate(df_instancia_vn_min, random_state=42)\n",
        "\n",
        "breakdown_vn_df_min = breakdown_vn_min.result\n",
        "shap_vn_df_min = shap_vn_min.result\n",
        "lime_vn_df_min = lime_vn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_vn_min.plot()"
      ],
      "metadata": {
        "id": "pIGX_KT835PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_vn_min.plot()"
      ],
      "metadata": {
        "id": "MyuJi9Tu35PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5krkwh235PV"
      },
      "outputs": [],
      "source": [
        "lime_vn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NADONo_X35PV"
      },
      "outputs": [],
      "source": [
        "breakdown_vn_df_min = breakdown_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(index=[0, 26])\n",
        "breakdown_vn_df_min['sign'] = breakdown_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_vn_df_min = shap_vn_df_min.tail(25)\n",
        "shap_vn_df_min['sign'] = shap_vn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_vn_df_min = shap_vn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_vn_df_min[\"Variable\"] = lime_vn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_vn_df_min[\"Signo\"] = lime_vn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_vn_df_min = lime_vn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_vn_df_min['Ranking'] = breakdown_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_vn_df_min['Ranking'] = shap_vn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_vn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_vn_df_min = shap_vn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_vn_df_min['Ranking'] = lime_vn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_vn_df_min = lime_vn_df_min.head(5)\n",
        "lime_vn_df_min = lime_vn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.drop(columns=['contribution'])\n",
        "shap_vn_df_min = shap_vn_df_min.drop(columns=['contribution'])\n",
        "lime_vn_df_min = lime_vn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.head(5)\n",
        "breakdown_vn_df_min = breakdown_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_vn_df_min = shap_vn_df_min.head(5)\n",
        "shap_vn_df_min = shap_vn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_vn_df_min = lime_vn_df_min.reset_index(drop=True)\n",
        "lime_vn_df_min.at[2, 'Variable'] = 'line_added'\n",
        "lime_vn_df_min.at[3, 'Variable'] = 'commit_num'\n",
        "\n",
        "print(breakdown_vn_df_min)\n",
        "print(shap_vn_df_min)\n",
        "print(lime_vn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V04cw6N835PV"
      },
      "outputs": [],
      "source": [
        "#lime_vn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep7dve4X35PW"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_vn_df_min['Variable'])\n",
        "shapley_features = list(shap_vn_df_min['Variable'])\n",
        "lime_features = list(lime_vn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_vn_df_min[breakdown_vn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_vn_df_min[shap_vn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_vn_df_min[lime_vn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"messages_min\", \"line_added\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "yAErwYhFRlgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **VN General:**"
      ],
      "metadata": {
        "id": "shzi97QLSeou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "tjJiAgGVSeou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_rus_vn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_rus_vn"
      ],
      "metadata": {
        "id": "nxBVCkiNSeov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_rus_vn[(\"General\", \"Ranking\")] = df_resumen_rus_vn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_rus_vn[(\"General\", \"Conteo Total\")] = df_resumen_rus_vn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_rus_vn"
      ],
      "metadata": {
        "id": "bJBOWLCJSeow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_rus_vn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_rus_vn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_rus_vn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_rus_vn[(\"General\", \"Peso Conteo\")] = df_resumen_rus_vn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_rus_vn[(\"General\", \"Puntaje\")] = df_resumen_rus_vn[(\"General\", \"Peso Rango\")] + df_resumen_rus_vn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_rus_vn[(\"General\", \"Ranking\")] = df_resumen_rus_vn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_rus_vn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rus_vn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rus_vn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_rus_vn"
      ],
      "metadata": {
        "id": "eNP0V4GcSeow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_rus_vn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_rus_vn = df_resumen_rus_vn[new_columns]"
      ],
      "metadata": {
        "id": "nr0PW3MDSeox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_rus_vn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_rus_vn[(tech, \"Ranking Medio\")] = df_resumen_rus_vn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_rus_vn"
      ],
      "metadata": {
        "id": "LeBYisBsSeox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBoxP6rb35PW"
      },
      "source": [
        "### **Instancia FP MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1apMTI235PW"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"break_down\",random_state=42)\n",
        "shap_fp_max = exp.predict_parts(df_instancia_fp_max, type=\"shap\",random_state=42)\n",
        "lime_fp_max = exp.predict_surrogate(df_instancia_fp_max, random_state=42)\n",
        "\n",
        "breakdown_fp_df_max = breakdown_fp_max.result\n",
        "shap_fp_df_max = shap_fp_max.result\n",
        "lime_fp_df_max=lime_fp_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_max.plot()"
      ],
      "metadata": {
        "id": "WN63iOwu35PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_max.plot()"
      ],
      "metadata": {
        "id": "AmLI6Ylr35PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GES2xRN835PW"
      },
      "outputs": [],
      "source": [
        "lime_fp_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GA-LBT035PW"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_max = breakdown_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(index=[0, 26])\n",
        "breakdown_fp_df_max['sign'] = breakdown_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_max = shap_fp_df_max.tail(25)\n",
        "shap_fp_df_max['sign'] = shap_fp_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_max = shap_fp_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_max[\"Variable\"] = lime_fp_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_max[\"Signo\"] = lime_fp_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_max = lime_fp_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_max['Ranking'] = breakdown_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_max['Ranking'] = shap_fp_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_max = shap_fp_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_max['Ranking'] = lime_fp_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_max = lime_fp_df_max.head(5)\n",
        "lime_fp_df_max = lime_fp_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.drop(columns=['contribution'])\n",
        "shap_fp_df_max = shap_fp_df_max.drop(columns=['contribution'])\n",
        "lime_fp_df_max = lime_fp_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.head(5)\n",
        "breakdown_fp_df_max = breakdown_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_max = shap_fp_df_max.head(5)\n",
        "shap_fp_df_max = shap_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_max = lime_fp_df_max.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_max)\n",
        "print(shap_fp_df_max)\n",
        "print(lime_fp_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jw7OCr_O35PW"
      },
      "outputs": [],
      "source": [
        "#lime_fp_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwaYZhw835PW"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_max['Variable'])\n",
        "shapley_features = list(shap_fp_df_max['Variable'])\n",
        "lime_features = list(lime_fp_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_max[breakdown_fp_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_max[shap_fp_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_max[lime_fp_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"line_added\", \"commit_num\", \"developer_num\", \"messages_min\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "q0P01nxdRyeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb8Vw02p35PX"
      },
      "source": [
        "### **Instancia FP MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbaS2Pvo35PX"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fp_mediana = exp.predict_parts(df_instancia_fp_mediana, type=\"shap\",random_state=42)\n",
        "lime_fp_mediana = exp.predict_surrogate(df_instancia_fp_mediana, random_state=42)\n",
        "\n",
        "breakdown_fp_df_mediana = breakdown_fp_mediana.result\n",
        "shap_fp_df_mediana = shap_fp_mediana.result\n",
        "lime_fp_df_mediana=lime_fp_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "E9N1mlUy35PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_mediana.plot()"
      ],
      "metadata": {
        "id": "nPc1HbQP35PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYzyJ0pW35PX"
      },
      "outputs": [],
      "source": [
        "lime_fp_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltxBR8fC35PX"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fp_df_mediana['sign'] = breakdown_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.tail(25)\n",
        "shap_fp_df_mediana['sign'] = shap_fp_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_mediana[\"Variable\"] = lime_fp_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_mediana[\"Signo\"] = lime_fp_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_mediana['Ranking'] = breakdown_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_mediana['Ranking'] = shap_fp_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_mediana['Ranking'] = lime_fp_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.head(5)\n",
        "lime_fp_df_mediana = lime_fp_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.drop(columns=['contribution'])\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.drop(columns=['contribution'])\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.head(5)\n",
        "breakdown_fp_df_mediana = breakdown_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.head(5)\n",
        "shap_fp_df_mediana = shap_fp_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_mediana = lime_fp_df_mediana.reset_index(drop=True)\n",
        "lime_fp_df_mediana.at[3, 'Variable'] = 'developer_num'\n",
        "\n",
        "print(breakdown_fp_df_mediana)\n",
        "print(shap_fp_df_mediana)\n",
        "print(lime_fp_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6Pw7Hq635PX"
      },
      "outputs": [],
      "source": [
        "#lime_fp_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j25IEGZ335PX"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fp_df_mediana['Variable'])\n",
        "lime_features = list(lime_fp_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_mediana[breakdown_fp_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_mediana[shap_fp_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_mediana[lime_fp_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"line_added\", \"messages_min\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "rkw18vYwR-Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btUmXTJk35PY"
      },
      "source": [
        "### **Instancia FP MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExX_c8jX35PY"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"break_down\",random_state=42)\n",
        "shap_fp_min = exp.predict_parts(df_instancia_fp_min, type=\"shap\",random_state=42)\n",
        "lime_fp_min = exp.predict_surrogate(df_instancia_fp_min, random_state=42)\n",
        "\n",
        "breakdown_fp_df_min = breakdown_fp_min.result\n",
        "shap_fp_df_min = shap_fp_min.result\n",
        "lime_fp_df_min = lime_fp_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fp_min.plot()"
      ],
      "metadata": {
        "id": "IGDIbGt-35PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fp_min.plot()"
      ],
      "metadata": {
        "id": "UTdPUL8b35PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_7Kms1g35PY"
      },
      "outputs": [],
      "source": [
        "lime_fp_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrXsdINN35PY"
      },
      "outputs": [],
      "source": [
        "breakdown_fp_df_min = breakdown_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(index=[0, 26])\n",
        "breakdown_fp_df_min['sign'] = breakdown_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fp_df_min = shap_fp_df_min.tail(25)\n",
        "shap_fp_df_min['sign'] = shap_fp_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fp_df_min = shap_fp_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fp_df_min[\"Variable\"] = lime_fp_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fp_df_min[\"Signo\"] = lime_fp_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fp_df_min = lime_fp_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fp_df_min['Ranking'] = breakdown_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fp_df_min['Ranking'] = shap_fp_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fp_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fp_df_min = shap_fp_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fp_df_min['Ranking'] = lime_fp_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fp_df_min = lime_fp_df_min.head(5)\n",
        "lime_fp_df_min = lime_fp_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.drop(columns=['contribution'])\n",
        "shap_fp_df_min = shap_fp_df_min.drop(columns=['contribution'])\n",
        "lime_fp_df_min = lime_fp_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.head(5)\n",
        "breakdown_fp_df_min = breakdown_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fp_df_min = shap_fp_df_min.head(5)\n",
        "shap_fp_df_min = shap_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fp_df_min = lime_fp_df_min.reset_index(drop=True)\n",
        "\n",
        "print(breakdown_fp_df_min)\n",
        "print(shap_fp_df_min)\n",
        "print(lime_fp_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWs4c-mG35PY"
      },
      "outputs": [],
      "source": [
        "#lime_fp_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwUXGvYm35PY"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fp_df_min['Variable'])\n",
        "shapley_features = list(shap_fp_df_min['Variable'])\n",
        "lime_features = list(lime_fp_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fp_df_min[breakdown_fp_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fp_df_min[shap_fp_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fp_df_min[lime_fp_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"commit_num\", \"developer_num\", \"line_added\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "wDkTMx-OSKtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FP General:**"
      ],
      "metadata": {
        "id": "WKzHrI0xSeoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "HjYF8axOSeoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_rus_fp = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_rus_fp"
      ],
      "metadata": {
        "id": "zeevYam6Seoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_rus_fp[(\"General\", \"Ranking\")] = df_resumen_rus_fp[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_rus_fp[(\"General\", \"Conteo Total\")] = df_resumen_rus_fp[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_rus_fp"
      ],
      "metadata": {
        "id": "tFLCUBU0Seo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_rus_fp.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_rus_fp[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_rus_fp[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_rus_fp[(\"General\", \"Peso Conteo\")] = df_resumen_rus_fp[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_rus_fp[(\"General\", \"Puntaje\")] = df_resumen_rus_fp[(\"General\", \"Peso Rango\")] + df_resumen_rus_fp[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_rus_fp[(\"General\", \"Ranking\")] = df_resumen_rus_fp[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_rus_fp.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rus_fp.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rus_fp.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_rus_fp"
      ],
      "metadata": {
        "id": "5YXsdm59Seo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_rus_fp.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_rus_fp = df_resumen_rus_fp[new_columns]"
      ],
      "metadata": {
        "id": "rViZk_6YSeo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_rus_fp.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_rus_fp[(tech, \"Ranking Medio\")] = df_resumen_rus_fp[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_rus_fp"
      ],
      "metadata": {
        "id": "G2__A_O4Seo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sET31h6k35PY"
      },
      "source": [
        "### **Instancia FN MAX:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ss0etK2A35PY"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"break_down\",random_state=42)\n",
        "shap_fn_max = exp.predict_parts(df_instancia_fn_max, type=\"shap\",random_state=42)\n",
        "lime_fn_max = exp.predict_surrogate(df_instancia_fn_max, random_state=42)\n",
        "\n",
        "breakdown_fn_df_max = breakdown_fn_max.result\n",
        "shap_fn_df_max = shap_fn_max.result\n",
        "lime_fn_df_max=lime_fn_max.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_max.plot()"
      ],
      "metadata": {
        "id": "4Cbck3pF35PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_max.plot()"
      ],
      "metadata": {
        "id": "g4CMgJxh35PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCyTfUj-35PZ"
      },
      "outputs": [],
      "source": [
        "lime_fn_max.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi2CuO2T35PZ"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_max = breakdown_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(index=[0, 26])\n",
        "breakdown_fn_df_max['sign'] = breakdown_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_max = shap_fn_df_max.tail(25)\n",
        "shap_fn_df_max['sign'] = shap_fn_df_max['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_max = shap_fn_df_max.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_max[\"Variable\"] = lime_fn_df_max[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_max[\"Signo\"] = lime_fn_df_max[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_max = lime_fn_df_max.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_max['Ranking'] = breakdown_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_max['Ranking'] = shap_fn_df_max['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_max.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_max = shap_fn_df_max[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_max['Ranking'] = lime_fn_df_max['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_max = lime_fn_df_max.head(5)\n",
        "lime_fn_df_max = lime_fn_df_max[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimaxo la columna de la contribucion\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.drop(columns=['contribution'])\n",
        "shap_fn_df_max = shap_fn_df_max.drop(columns=['contribution'])\n",
        "lime_fn_df_max = lime_fn_df_max.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.head(5)\n",
        "breakdown_fn_df_max = breakdown_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_max = shap_fn_df_max.head(5)\n",
        "shap_fn_df_max = shap_fn_df_max.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_max = lime_fn_df_max.reset_index(drop=True)\n",
        "lime_fn_df_max.at[1, 'Variable'] = 'developer_num'\n",
        "lime_fn_df_max.at[2, 'Variable'] = 'line_added'\n",
        "\n",
        "print(breakdown_fn_df_max)\n",
        "print(shap_fn_df_max)\n",
        "print(lime_fn_df_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90RoX9nX35PZ"
      },
      "outputs": [],
      "source": [
        "#lime_fn_max.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0phlGZs35PZ"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_max['Variable'])\n",
        "shapley_features = list(shap_fn_df_max['Variable'])\n",
        "lime_features = list(lime_fn_df_max['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_max = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_max['Variable'] = list(all_features)\n",
        "df_final_max= df_final_max[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_max['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_max[breakdown_fn_df_max['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_max[shap_fn_df_max['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_max[lime_fn_df_max['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_max.loc[df_final_max['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_max"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_max.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"line_added\", \"messages_min\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_max = df_final_max.reindex(nuevo_orden)\n",
        "\n",
        "df_final_max"
      ],
      "metadata": {
        "id": "3Xh061sMSPQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asjU1K8I35PZ"
      },
      "source": [
        "### **Instancia FN MEDIANA:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtCxg4sb35PZ"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"break_down\",random_state=42)\n",
        "shap_fn_mediana = exp.predict_parts(df_instancia_fn_mediana, type=\"shap\",random_state=42)\n",
        "lime_fn_mediana = exp.predict_surrogate(df_instancia_fn_mediana, random_state=42)\n",
        "\n",
        "breakdown_fn_df_mediana = breakdown_fn_mediana.result\n",
        "shap_fn_df_mediana = shap_fn_mediana.result\n",
        "lime_fn_df_mediana=lime_fn_mediana.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "nz6YZjQA35PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_mediana.plot()"
      ],
      "metadata": {
        "id": "8trYxxw635PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMNzws4L35PZ"
      },
      "outputs": [],
      "source": [
        "lime_fn_mediana.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPqc2NiW35PZ"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(index=[0, 26])\n",
        "breakdown_fn_df_mediana['sign'] = breakdown_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.tail(25)\n",
        "shap_fn_df_mediana['sign'] = shap_fn_df_mediana['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_mediana[\"Variable\"] = lime_fn_df_mediana[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_mediana[\"Signo\"] = lime_fn_df_mediana[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_mediana['Ranking'] = breakdown_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_mediana['Ranking'] = shap_fn_df_mediana['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_mediana.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_mediana['Ranking'] = lime_fn_df_mediana['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.head(5)\n",
        "lime_fn_df_mediana = lime_fn_df_mediana[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimedianao la columna de la contribucion\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.drop(columns=['contribution'])\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.drop(columns=['contribution'])\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.head(5)\n",
        "breakdown_fn_df_mediana = breakdown_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.head(5)\n",
        "shap_fn_df_mediana = shap_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_mediana = lime_fn_df_mediana.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(breakdown_fn_df_mediana)\n",
        "print(shap_fn_df_mediana)\n",
        "print(lime_fn_df_mediana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_cuw2pY35Pa"
      },
      "outputs": [],
      "source": [
        "#lime_fn_mediana.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25rLAylL35Pa"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_mediana['Variable'])\n",
        "shapley_features = list(shap_fn_df_mediana['Variable'])\n",
        "lime_features = list(lime_fn_df_mediana['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_mediana = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_mediana['Variable'] = list(all_features)\n",
        "df_final_mediana= df_final_mediana[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_mediana['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_mediana[breakdown_fn_df_mediana['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_mediana[shap_fn_df_mediana['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_mediana[lime_fn_df_mediana['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_mediana.loc[df_final_mediana['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_mediana"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_mediana.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"line_added\", \"messages_min\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_mediana = df_final_mediana.reindex(nuevo_orden)\n",
        "\n",
        "df_final_mediana"
      ],
      "metadata": {
        "id": "5ulwl-BYSgM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HXsMEu735Pa"
      },
      "source": [
        "### **Instancia FN MIN:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD7DEk7l35Pa"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"break_down\",random_state=42)\n",
        "shap_fn_min = exp.predict_parts(df_instancia_fn_min, type=\"shap\",random_state=42)\n",
        "lime_fn_min = exp.predict_surrogate(df_instancia_fn_min, random_state=42)\n",
        "\n",
        "breakdown_fn_df_min = breakdown_fn_min.result\n",
        "shap_fn_df_min = shap_fn_min.result\n",
        "lime_fn_df_min = lime_fn_min.result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breakdown_fn_min.plot()"
      ],
      "metadata": {
        "id": "8e-pfxlX35Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_fn_min.plot()"
      ],
      "metadata": {
        "id": "LxQpRDFv35Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cjFvt7C35Pa"
      },
      "outputs": [],
      "source": [
        "lime_fn_min.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5_7PSM235Pa"
      },
      "outputs": [],
      "source": [
        "breakdown_fn_df_min = breakdown_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(index=[0, 26])\n",
        "breakdown_fn_df_min['sign'] = breakdown_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.loc[:, ['variable_name', 'contribution', 'sign']]\n",
        "shap_fn_df_min = shap_fn_df_min.tail(25)\n",
        "shap_fn_df_min['sign'] = shap_fn_df_min['sign'].replace({1.0: 'Positivo', 0.0: 'Nulo', -1.0: 'Negativo'})\n",
        "shap_fn_df_min = shap_fn_df_min.sort_values(by='contribution', key=lambda x: abs(x), ascending=False)\n",
        "\n",
        "lime_fn_df_min[\"Variable\"] = lime_fn_df_min[\"variable\"].str.split(\" \").str[0]\n",
        "lime_fn_df_min[\"Signo\"] = lime_fn_df_min[\"effect\"].apply(evaluar_valor)\n",
        "lime_fn_df_min = lime_fn_df_min.sort_values(by='effect', key=lambda x: abs(x), ascending=False)\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['variable'])\n",
        "\n",
        "# Agregar una columna de ranking\n",
        "breakdown_fn_df_min['Ranking'] = breakdown_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "breakdown_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "shap_fn_df_min['Ranking'] = shap_fn_df_min['contribution'].abs().rank(ascending=False).astype(int)\n",
        "shap_fn_df_min.rename(columns={'sign': 'Signo', 'variable_name':'Variable'}, inplace=True)\n",
        "shap_fn_df_min = shap_fn_df_min[['Variable', 'Ranking', 'contribution', 'Signo']]\n",
        "\n",
        "lime_fn_df_min['Ranking'] = lime_fn_df_min['effect'].abs().rank(ascending=False).astype(int)\n",
        "lime_fn_df_min = lime_fn_df_min.head(5)\n",
        "lime_fn_df_min = lime_fn_df_min[['Variable', 'Ranking', 'effect', 'Signo']]\n",
        "\n",
        "# Elimino la columna de la contribucion\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.drop(columns=['contribution'])\n",
        "shap_fn_df_min = shap_fn_df_min.drop(columns=['contribution'])\n",
        "lime_fn_df_min = lime_fn_df_min.drop(columns=['effect'])\n",
        "\n",
        "# Filtrar las 5 primeras contribuciones en valor absoluto\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.head(5)\n",
        "breakdown_fn_df_min = breakdown_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "shap_fn_df_min = shap_fn_df_min.head(5)\n",
        "shap_fn_df_min = shap_fn_df_min.reset_index(drop=True)\n",
        "\n",
        "lime_fn_df_min = lime_fn_df_min.reset_index(drop=True)\n",
        "lime_fn_df_min.at[2, 'Variable'] = 'line_added'\n",
        "lime_fn_df_min.at[3, 'Variable'] = 'commit_num'\n",
        "\n",
        "print(breakdown_fn_df_min)\n",
        "print(shap_fn_df_min)\n",
        "print(lime_fn_df_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R84k5EzK35Pa"
      },
      "outputs": [],
      "source": [
        "#lime_fn_min.show_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb_Ku0tI35Pa"
      },
      "outputs": [],
      "source": [
        "# Obtener todas las características únicas de las tres técnicas\n",
        "breakdown_features = list(breakdown_fn_df_min['Variable'])\n",
        "shapley_features = list(shap_fn_df_min['Variable'])\n",
        "lime_features = list(lime_fn_df_min['Variable'])\n",
        "all_features = list(set(breakdown_features + shapley_features + lime_features))\n",
        "all_features = all_features[::-1]\n",
        "\n",
        "df_final_min = pd.DataFrame(index=range(len(all_features)), columns=columns_multi)\n",
        "df_final_min['Variable'] = list(all_features)\n",
        "df_final_min= df_final_min[['Variable', 'Breakdown', 'Shapley', 'Lime']]\n",
        "\n",
        "print(breakdown_features)\n",
        "print(shapley_features)\n",
        "print(lime_features)\n",
        "print(all_features)\n",
        "\n",
        "for feature in df_final_min['Variable']:\n",
        "    # Buscar la característica en el DataFrame de Breakdown\n",
        "    breakdown_row = breakdown_fn_df_min[breakdown_fn_df_min['Variable'] == feature]\n",
        "    if not breakdown_row.empty:\n",
        "        # Si se encuentra, obtener los valores de \"Ranking\" y \"Signo\"\n",
        "        ranking_breakdown = breakdown_row.iloc[0]['Ranking']\n",
        "        signo_breakdown = breakdown_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = ranking_breakdown\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = signo_breakdown\n",
        "    else:\n",
        "        # Si no se encuentra, añadir \"-\"\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Breakdown', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Shapley\n",
        "    shap_row = shap_fn_df_min[shap_fn_df_min['Variable'] == feature]\n",
        "    if not shap_row.empty:\n",
        "        ranking_shap = shap_row.iloc[0]['Ranking']\n",
        "        signo_shap = shap_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = ranking_shap\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = signo_shap\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Shapley', 'Signo')] = '-'\n",
        "\n",
        "    # Repetir el proceso para el DataFrame de Lime\n",
        "    lime_row = lime_fn_df_min[lime_fn_df_min['Variable'] == feature]\n",
        "    if not lime_row.empty:\n",
        "        ranking_lime = lime_row.iloc[0]['Ranking']\n",
        "        signo_lime = lime_row.iloc[0]['Signo']\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = ranking_lime\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = signo_lime\n",
        "    else:\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Ranking')] = '-'\n",
        "        df_final_min.loc[df_final_min['Variable'] == feature, ('Lime', 'Signo')] = '-'\n",
        "\n",
        "df_final_min"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_min.set_index('Variable', inplace=True)\n",
        "nuevo_orden = [\"parallel_changed_file_num\", \"developer_num\", \"commit_num\", \"line_added\", \"messages_min\", \"delete_frequency\"]\n",
        "\n",
        "# Reorganizar el DataFrame según el nuevo orden\n",
        "df_final_min = df_final_min.reindex(nuevo_orden)\n",
        "\n",
        "df_final_min"
      ],
      "metadata": {
        "id": "hftjMJAFSu1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **FN General:**"
      ],
      "metadata": {
        "id": "t-c2kGHMSeo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_valores = {\n",
        "    'Breakdown': [],\n",
        "    'Shapley': [],\n",
        "    'Lime': []\n",
        "}\n",
        "\n",
        "# Recorre los DataFrames y almacena los pares de valores por técnica\n",
        "for tecnica in ranking_valores:\n",
        "    for caracteristica in df_final_max.index:\n",
        "        ranking = df_final_max[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_mediana.index:\n",
        "        ranking = df_final_mediana[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "    for caracteristica in df_final_min.index:\n",
        "        ranking = df_final_min[(tecnica, 'Ranking')][caracteristica]\n",
        "        if ranking != \"-\":\n",
        "            ranking_valores[tecnica].append((caracteristica, int(ranking)))\n",
        "\n",
        "# Calcula el ranking medio por técnica y característica\n",
        "ranking_medio = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, ranking in ranking_values:\n",
        "        if caracteristica not in ranking_medio[tecnica]:\n",
        "            ranking_medio[tecnica][caracteristica] = [ranking]\n",
        "        else:\n",
        "            ranking_medio[tecnica][caracteristica].append(ranking)\n",
        "\n",
        "for tecnica, ranking_values in ranking_medio.items():\n",
        "    for caracteristica in ranking_values:\n",
        "        ranking_medio[tecnica][caracteristica] = sum(ranking_values[caracteristica]) / len(ranking_values[caracteristica])\n",
        "\n",
        "\n",
        "# Ahora el conteo de apariciones por característica y técnica\n",
        "apariciones_count = {\n",
        "    'Breakdown': {},\n",
        "    'Shapley': {},\n",
        "    'Lime': {}\n",
        "}\n",
        "\n",
        "for tecnica, ranking_values in ranking_valores.items():\n",
        "    for caracteristica, _ in ranking_values:\n",
        "        if caracteristica not in apariciones_count[tecnica]:\n",
        "            apariciones_count[tecnica][caracteristica] = 1\n",
        "        else:\n",
        "            apariciones_count[tecnica][caracteristica] += 1\n",
        "\n",
        "# Tengo los valores, los conteos de apariciones y los ranking medios por técnica en los respectivos diccionarios\n",
        "print(ranking_valores)\n",
        "print(apariciones_count)\n",
        "print(ranking_medio)"
      ],
      "metadata": {
        "id": "Z5z37u5fSeo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de técnicas\n",
        "techniques = ['Breakdown', 'Shapley', 'Lime']\n",
        "\n",
        "# Diccionario para almacenar los datos\n",
        "data_dict = {}\n",
        "\n",
        "# Crear una lista de todas las características\n",
        "all_caract = list(set().union(*[set(ranking_medio[technique]) for technique in techniques]))\n",
        "\n",
        "# Recorrer las técnicas y las características\n",
        "for technique in techniques:\n",
        "    caract = list(ranking_medio[technique].keys())\n",
        "    rank = [ranking_medio[technique].get(c, \"-\") for c in all_caract]\n",
        "    apar = [apariciones_count[technique].get(c, \"-\") for c in all_caract]\n",
        "\n",
        "    # Agregar los datos al diccionario\n",
        "    data_dict[(technique, \"Ranking Medio\")] = rank\n",
        "    data_dict[(technique, \"Conteo\")] = apar\n",
        "\n",
        "# Crear el DataFrame resumen\n",
        "df_resumen_rus_fn = pd.DataFrame(data_dict, index=all_caract)\n",
        "\n",
        "df_resumen_rus_fn"
      ],
      "metadata": {
        "id": "F7qmccnjSeo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ranking medio general omitiendo los valores \"-\"\n",
        "df_resumen_rus_fn[(\"General\", \"Ranking\")] = df_resumen_rus_fn[[(tech, \"Ranking Medio\") for tech in techniques]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_rus_fn[(\"General\", \"Conteo Total\")] = df_resumen_rus_fn[[(tech, \"Conteo\") for tech in techniques]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Mostrar el DataFrame resumen actualizado\n",
        "df_resumen_rus_fn"
      ],
      "metadata": {
        "id": "Z6Ig3_XRSeo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el número de características\n",
        "num_caract = df_resumen_rus_fn.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_rus_fn[(\"General\", \"Peso Rango\")] = 1 - ((df_resumen_rus_fn[(\"General\", \"Ranking\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_rus_fn[(\"General\", \"Peso Conteo\")] = df_resumen_rus_fn[(\"General\", \"Conteo Total\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_rus_fn[(\"General\", \"Puntaje\")] = df_resumen_rus_fn[(\"General\", \"Peso Rango\")] + df_resumen_rus_fn[(\"General\", \"Peso Conteo\")]\n",
        "df_resumen_rus_fn[(\"General\", \"Ranking\")] = df_resumen_rus_fn[(\"General\", \"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "# Eliminar la subcolumnas innecesarias\n",
        "df_resumen_rus_fn.drop(\"Peso Rango\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rus_fn.drop(\"Peso Conteo\", axis=1, level=1, inplace=True)\n",
        "df_resumen_rus_fn.drop(\"Puntaje\", axis=1, level=1, inplace=True)\n",
        "\n",
        "df_resumen_rus_fn"
      ],
      "metadata": {
        "id": "Mqjdbhf4Seo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas actuales del DataFrame\n",
        "columns = df_resumen_rus_fn.columns\n",
        "\n",
        "# Extraer las columnas de \"General\" y sus subcolumnas\n",
        "general_columns = columns.get_level_values(0) == \"General\"\n",
        "\n",
        "# Crear una lista con las subcolumnas de \"General\"\n",
        "general_subcolumns = [(\"General\", \"Ranking\"), (\"General\", \"Conteo Total\")]\n",
        "\n",
        "# Crear una lista con las subcolumnas asociadas a las técnicas\n",
        "technique_subcolumns = list(columns[~general_columns])\n",
        "\n",
        "# Reorganizar las columnas para mover \"General\" al principio\n",
        "new_columns = general_subcolumns + technique_subcolumns\n",
        "\n",
        "# Crear un nuevo DataFrame con las columnas reorganizadas\n",
        "df_resumen_rus_fn = df_resumen_rus_fn[new_columns]"
      ],
      "metadata": {
        "id": "dWAEahZ2Seo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resumen_rus_fn.sort_values(by=(\"General\", \"Ranking\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for tech in techniques:\n",
        "    df_resumen_rus_fn[(tech, \"Ranking Medio\")] = df_resumen_rus_fn[(tech, \"Ranking Medio\")].apply(lambda x: f\"{x:.2f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_rus_fn"
      ],
      "metadata": {
        "id": "nw3WDtxKSeo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LOCAL GENERAL:**"
      ],
      "metadata": {
        "id": "Ao7PqeCt2VG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verdadero Positivo:"
      ],
      "metadata": {
        "id": "5a5stpbE33AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de DataFrames resumen y algoritmo\n",
        "dfs_resumen = [df_resumen_rf_vp, df_resumen_brf_vp, df_resumen_gb_vp, df_resumen_ada_vp, df_resumen_rus_vp]\n",
        "algorithms = [\"RandomForest\", \"BalancedRandomForest\", \"GradientBoosting\", \"ADABoost\", \"RUSBoost\"]\n",
        "\n",
        "# Crear un conjunto de índices único\n",
        "index_set = set()\n",
        "\n",
        "# Iterar sobre cada DataFrame resumen y agregar sus índices al conjunto\n",
        "for df_resumen in dfs_resumen:\n",
        "    index_set.update(df_resumen.index)\n",
        "index_list = list(index_set)\n",
        "\n",
        "# Crear un nuevo DataFrame para el resultado final\n",
        "df_resumen_final = pd.DataFrame(index=index_list)\n",
        "\n",
        "# Agregar las columnas de \"General\" con \"Ranking\" y \"Conteo Total\" para cada algoritmo\n",
        "for algorithm, df_resumen in zip(algorithms, dfs_resumen):\n",
        "    df_resumen_final[(algorithm, 'Ranking')] = df_resumen[('General', 'Ranking')]\n",
        "    df_resumen_final[(algorithm, 'Conteo Total')] = df_resumen[('General', 'Conteo Total')]\n",
        "\n",
        "# Rellenar el DataFrame final con datos o '-'\n",
        "df_resumen_final = df_resumen_final.fillna('-')\n",
        "\n",
        "# Calcular el ranking final promediando los rankings de las técnicas\n",
        "df_resumen_final[\"Ranking Final\"] = df_resumen_final[[(algo, \"Ranking\") for algo in algorithms]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_final[(\"Conteo Final\")] = df_resumen_final[[(algo, \"Conteo Total\") for algo in algorithms]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Obtener el número de características\n",
        "num_caract = df_resumen_final.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_final[(\"Peso Rango\")] = 1 - ((df_resumen_final[(\"Ranking Final\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_final[(\"Peso Conteo\")] = df_resumen_final[(\"Conteo Final\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_final[(\"Puntaje\")] = df_resumen_final[(\"Peso Rango\")] + df_resumen_final[(\"Peso Conteo\")]\n",
        "df_resumen_final[(\"Ranking Final\")] = df_resumen_final[(\"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "\n",
        "# Eliminar las columnas innecesarias\n",
        "df_resumen_final.drop(\"Peso Rango\", axis=1, inplace=True)\n",
        "df_resumen_final.drop(\"Peso Conteo\", axis=1, inplace=True)\n",
        "df_resumen_final.drop(\"Puntaje\", axis=1, inplace=True)\n",
        "\n",
        "df_resumen_final.sort_values(by=(\"Ranking Final\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for algo in algorithms:\n",
        "    df_resumen_final[(algo, \"Ranking\")] = df_resumen_final[(algo, \"Ranking\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "    df_resumen_final[(algo, \"Conteo Total\")] = df_resumen_final[(algo, \"Conteo Total\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_final[(\"Ranking Final\")] = df_resumen_final[(\"Ranking Final\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "df_resumen_final[(\"Conteo Final\")] = df_resumen_final[(\"Conteo Final\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_final"
      ],
      "metadata": {
        "id": "TEm6KyYfW6bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verdadero Negativo:"
      ],
      "metadata": {
        "id": "euM0-XDs5W8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de DataFrames resumen y algoritmo\n",
        "dfs_resumen = [df_resumen_rf_vn, df_resumen_brf_vn, df_resumen_gb_vn, df_resumen_ada_vn, df_resumen_rus_vn]\n",
        "algorithms = [\"RandomForest\", \"BalancedRandomForest\", \"GradientBoosting\", \"ADABoost\", \"RUSBoost\"]\n",
        "\n",
        "# Crear un conjunto de índices único\n",
        "index_set = set()\n",
        "\n",
        "# Iterar sobre cada DataFrame resumen y agregar sus índices al conjunto\n",
        "for df_resumen in dfs_resumen:\n",
        "    index_set.update(df_resumen.index)\n",
        "index_list = list(index_set)\n",
        "\n",
        "# Crear un nuevo DataFrame para el resultado final\n",
        "df_resumen_final = pd.DataFrame(index=index_list)\n",
        "\n",
        "# Agregar las columnas de \"General\" con \"Ranking\" y \"Conteo Total\" para cada algoritmo\n",
        "for algorithm, df_resumen in zip(algorithms, dfs_resumen):\n",
        "    df_resumen_final[(algorithm, 'Ranking')] = df_resumen[('General', 'Ranking')]\n",
        "    df_resumen_final[(algorithm, 'Conteo Total')] = df_resumen[('General', 'Conteo Total')]\n",
        "\n",
        "# Rellenar el DataFrame final con datos o '-'\n",
        "df_resumen_final = df_resumen_final.fillna('-')\n",
        "\n",
        "# Calcular el ranking final promediando los rankings de las técnicas\n",
        "df_resumen_final[\"Ranking Final\"] = df_resumen_final[[(algo, \"Ranking\") for algo in algorithms]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_final[(\"Conteo Final\")] = df_resumen_final[[(algo, \"Conteo Total\") for algo in algorithms]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Obtener el número de características\n",
        "num_caract = df_resumen_final.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_final[(\"Peso Rango\")] = 1 - ((df_resumen_final[(\"Ranking Final\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_final[(\"Peso Conteo\")] = df_resumen_final[(\"Conteo Final\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_final[(\"Puntaje\")] = df_resumen_final[(\"Peso Rango\")] + df_resumen_final[(\"Peso Conteo\")]\n",
        "df_resumen_final[(\"Ranking Final\")] = df_resumen_final[(\"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "\n",
        "# Eliminar las columnas innecesarias\n",
        "df_resumen_final.drop(\"Peso Rango\", axis=1, inplace=True)\n",
        "df_resumen_final.drop(\"Peso Conteo\", axis=1, inplace=True)\n",
        "df_resumen_final.drop(\"Puntaje\", axis=1, inplace=True)\n",
        "\n",
        "df_resumen_final.sort_values(by=(\"Ranking Final\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for algo in algorithms:\n",
        "    df_resumen_final[(algo, \"Ranking\")] = df_resumen_final[(algo, \"Ranking\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "    df_resumen_final[(algo, \"Conteo Total\")] = df_resumen_final[(algo, \"Conteo Total\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_final[(\"Ranking Final\")] = df_resumen_final[(\"Ranking Final\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "df_resumen_final[(\"Conteo Final\")] = df_resumen_final[(\"Conteo Final\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_final"
      ],
      "metadata": {
        "id": "G5hcrZxbhEQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Falso Positivo:"
      ],
      "metadata": {
        "id": "3cs_b1JR6HOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de DataFrames resumen y algoritmo\n",
        "dfs_resumen = [df_resumen_rf_fp, df_resumen_brf_fp, df_resumen_gb_fp, df_resumen_ada_fp, df_resumen_rus_fp]\n",
        "algorithms = [\"RandomForest\", \"BalancedRandomForest\", \"GradientBoosting\", \"ADABoost\", \"RUSBoost\"]\n",
        "\n",
        "# Crear un conjunto de índices único\n",
        "index_set = set()\n",
        "\n",
        "# Iterar sobre cada DataFrame resumen y agregar sus índices al conjunto\n",
        "for df_resumen in dfs_resumen:\n",
        "    index_set.update(df_resumen.index)\n",
        "index_list = list(index_set)\n",
        "\n",
        "# Crear un nuevo DataFrame para el resultado final\n",
        "df_resumen_final = pd.DataFrame(index=index_list)\n",
        "\n",
        "# Agregar las columnas de \"General\" con \"Ranking\" y \"Conteo Total\" para cada algoritmo\n",
        "for algorithm, df_resumen in zip(algorithms, dfs_resumen):\n",
        "    df_resumen_final[(algorithm, 'Ranking')] = df_resumen[('General', 'Ranking')]\n",
        "    df_resumen_final[(algorithm, 'Conteo Total')] = df_resumen[('General', 'Conteo Total')]\n",
        "\n",
        "# Rellenar el DataFrame final con datos o '-'\n",
        "df_resumen_final = df_resumen_final.fillna('-')\n",
        "\n",
        "# Calcular el ranking final promediando los rankings de las técnicas\n",
        "df_resumen_final[\"Ranking Final\"] = df_resumen_final[[(algo, \"Ranking\") for algo in algorithms]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_final[(\"Conteo Final\")] = df_resumen_final[[(algo, \"Conteo Total\") for algo in algorithms]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Obtener el número de características\n",
        "num_caract = df_resumen_final.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_final[(\"Peso Rango\")] = 1 - ((df_resumen_final[(\"Ranking Final\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_final[(\"Peso Conteo\")] = df_resumen_final[(\"Conteo Final\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_final[(\"Puntaje\")] = df_resumen_final[(\"Peso Rango\")] + df_resumen_final[(\"Peso Conteo\")]\n",
        "df_resumen_final[(\"Ranking Final\")] = df_resumen_final[(\"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "\n",
        "# Eliminar las columnas innecesarias\n",
        "df_resumen_final.drop(\"Peso Rango\", axis=1, inplace=True)\n",
        "df_resumen_final.drop(\"Peso Conteo\", axis=1, inplace=True)\n",
        "df_resumen_final.drop(\"Puntaje\", axis=1, inplace=True)\n",
        "\n",
        "df_resumen_final.sort_values(by=(\"Ranking Final\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for algo in algorithms:\n",
        "    df_resumen_final[(algo, \"Ranking\")] = df_resumen_final[(algo, \"Ranking\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "    df_resumen_final[(algo, \"Conteo Total\")] = df_resumen_final[(algo, \"Conteo Total\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_final[(\"Ranking Final\")] = df_resumen_final[(\"Ranking Final\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "df_resumen_final[(\"Conteo Final\")] = df_resumen_final[(\"Conteo Final\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_final"
      ],
      "metadata": {
        "id": "XCvRHDeciUhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Falso Negativo:"
      ],
      "metadata": {
        "id": "xI3xiVcn6bDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de DataFrames resumen y algoritmo\n",
        "dfs_resumen = [df_resumen_rf_fn, df_resumen_brf_fn, df_resumen_gb_fn, df_resumen_ada_fn, df_resumen_rus_fn]\n",
        "algorithms = [\"RandomForest\", \"BalancedRandomForest\", \"GradientBoosting\", \"ADABoost\", \"RUSBoost\"]\n",
        "\n",
        "# Crear un conjunto de índices único\n",
        "index_set = set()\n",
        "\n",
        "# Iterar sobre cada DataFrame resumen y agregar sus índices al conjunto\n",
        "for df_resumen in dfs_resumen:\n",
        "    index_set.update(df_resumen.index)\n",
        "index_list = list(index_set)\n",
        "\n",
        "# Crear un nuevo DataFrame para el resultado final\n",
        "df_resumen_final = pd.DataFrame(index=index_list)\n",
        "\n",
        "# Agregar las columnas de \"General\" con \"Ranking\" y \"Conteo Total\" para cada algoritmo\n",
        "for algorithm, df_resumen in zip(algorithms, dfs_resumen):\n",
        "    df_resumen_final[(algorithm, 'Ranking')] = df_resumen[('General', 'Ranking')]\n",
        "    df_resumen_final[(algorithm, 'Conteo Total')] = df_resumen[('General', 'Conteo Total')]\n",
        "\n",
        "# Rellenar el DataFrame final con datos o '-'\n",
        "df_resumen_final = df_resumen_final.fillna('-')\n",
        "\n",
        "# Calcular el ranking final promediando los rankings de las técnicas\n",
        "df_resumen_final[\"Ranking Final\"] = df_resumen_final[[(algo, \"Ranking\") for algo in algorithms]].replace('-', np.nan).mean(axis=1)\n",
        "\n",
        "# Calcular la suma total de apariciones omitiendo los valores \"-\"\n",
        "df_resumen_final[(\"Conteo Final\")] = df_resumen_final[[(algo, \"Conteo Total\") for algo in algorithms]].replace('-', 0).sum(axis=1)\n",
        "\n",
        "# Obtener el número de características\n",
        "num_caract = df_resumen_final.shape[0]\n",
        "\n",
        "# Calcular el peso para el ranking y apariciones\n",
        "df_resumen_final[(\"Peso Rango\")] = 1 - ((df_resumen_final[(\"Ranking Final\")].rank(ascending=True) - 1) / num_caract)\n",
        "df_resumen_final[(\"Peso Conteo\")] = df_resumen_final[(\"Conteo Final\")].rank(ascending=True) / num_caract\n",
        "\n",
        "# Calcular el puntaje final como suma de los pesos\n",
        "df_resumen_final[(\"Puntaje\")] = df_resumen_final[(\"Peso Rango\")] + df_resumen_final[(\"Peso Conteo\")]\n",
        "df_resumen_final[(\"Ranking Final\")] = df_resumen_final[(\"Puntaje\")].rank(ascending=False, method=\"min\")\n",
        "\n",
        "\n",
        "# Eliminar las columnas innecesarias\n",
        "df_resumen_final.drop(\"Peso Rango\", axis=1, inplace=True)\n",
        "df_resumen_final.drop(\"Peso Conteo\", axis=1, inplace=True)\n",
        "df_resumen_final.drop(\"Puntaje\", axis=1, inplace=True)\n",
        "\n",
        "df_resumen_final.sort_values(by=(\"Ranking Final\"), ascending=True, inplace=True)\n",
        "\n",
        "# Formatear los valores\n",
        "for algo in algorithms:\n",
        "    df_resumen_final[(algo, \"Ranking\")] = df_resumen_final[(algo, \"Ranking\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "    df_resumen_final[(algo, \"Conteo Total\")] = df_resumen_final[(algo, \"Conteo Total\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_final[(\"Ranking Final\")] = df_resumen_final[(\"Ranking Final\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "df_resumen_final[(\"Conteo Final\")] = df_resumen_final[(\"Conteo Final\")].apply(lambda x: f\"{x:.0f}\" if isinstance(x, (int, float)) else x)\n",
        "\n",
        "df_resumen_final"
      ],
      "metadata": {
        "id": "5T6Khu2gicB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFfzEJ3vzcGf"
      },
      "source": [
        "# **Resultados:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk8PzpLty9c9"
      },
      "source": [
        "**RENDIMIENTO MODELOS:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = [\"RandomForest\", \"BalancedRF\", \"GradientBoosting\", \"AdaBoost\", \"RUSBoost\"]\n",
        "matrices_confusion = [cm_rf, cm_brf, cm_gb, cm_ada, cm_rus]\n",
        "class_names = [\"0\", \"1\"]\n",
        "\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5), sharey=\"row\")\n",
        "\n",
        "for i, (cm, classifier_name) in enumerate(zip(matrices_confusion, classifiers)):\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "    disp.plot(ax=axes[i], cmap=\"Blues\")\n",
        "    axes[i].set_title(classifier_name)\n",
        "    disp.im_.colorbar.remove()\n",
        "    disp.ax_.set_xlabel('')\n",
        "    if i!=0:\n",
        "        disp.ax_.set_ylabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "fig.text(0.4, 0.1, \"Predicted label\", ha=\"left\")\n",
        "fig.colorbar(disp.im_, ax=axes)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YBheBTTSMlnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6meY_Wx_zlMe"
      },
      "outputs": [],
      "source": [
        "score_result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metricas = ['Accuracy', 'Recall', 'Precision', 'F1-score']\n",
        "colores = ['#3498DB', '#F7DC6F','#EC7063', '#58D68D']\n",
        "\n",
        "num_modelos = len(score_result)\n",
        "ancho_barra = 0.15\n",
        "x = range(num_modelos)\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "\n",
        "# Crear un gráfico de barras para cada métrica\n",
        "for i, metrica in enumerate(metricas):\n",
        "    # Calcular la posición para las barras de esta métrica\n",
        "    posiciones_x = [pos + i * ancho_barra for pos in x]\n",
        "\n",
        "    # Obtener los valores de la métrica actual\n",
        "    valores_metrica = score_result[metrica]\n",
        "\n",
        "    # Crear las barras para la métrica actual\n",
        "    plt.bar(\n",
        "        posiciones_x,\n",
        "        valores_metrica,\n",
        "        width=ancho_barra,\n",
        "        label=metrica,\n",
        "        color=colores[i],\n",
        "    )\n",
        "\n",
        "# Personalizar el gráfico\n",
        "plt.xlabel('Modelo')\n",
        "plt.ylabel('Valor de la Métrica')\n",
        "plt.title('Comparación de Rendimiento Python')\n",
        "plt.xticks([pos + (len(metricas) - 1) * ancho_barra / 2 for pos in x], score_result['Modelo'], rotation=45, ha=\"right\")\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Mostrar el gráfico combinado\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mrtgJNks-Tdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgJ4tTPdzcGf"
      },
      "outputs": [],
      "source": [
        "variables=list(score_result)\n",
        "variables.pop(0)\n",
        "\n",
        "for var in variables:\n",
        "  score_result.plot.bar(x='Modelo', y=var, rot=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ejhi63pzB6L"
      },
      "source": [
        "**RENDIMIENTO INVERSO:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS9SEjO2zF_h"
      },
      "outputs": [],
      "source": [
        "score_inv_result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metricas = ['Accuracy', 'Recall', 'Precision', 'F1-score']\n",
        "colores = ['#3498DB', '#F7DC6F','#EC7063', '#58D68D']\n",
        "\n",
        "num_modelos = len(score_inv_result)\n",
        "ancho_barra = 0.15\n",
        "x = range(num_modelos)\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "\n",
        "# Crear un gráfico de barras para cada métrica\n",
        "for i, metrica in enumerate(metricas):\n",
        "    # Calcular la posición para las barras de esta métrica\n",
        "    posiciones_x = [pos + i * ancho_barra for pos in x]\n",
        "\n",
        "    # Obtener los valores de la métrica actual\n",
        "    valores_metrica = score_inv_result[metrica]\n",
        "\n",
        "    # Crear las barras para la métrica actual\n",
        "    plt.bar(\n",
        "        posiciones_x,\n",
        "        valores_metrica,\n",
        "        width=ancho_barra,\n",
        "        label=metrica,\n",
        "        color=colores[i],\n",
        "    )\n",
        "\n",
        "# Personalizar el gráfico\n",
        "plt.xlabel('Modelo')\n",
        "plt.ylabel('Valor de la Métrica')\n",
        "plt.title('Comparación de Rendimiento Python (Inverso)')\n",
        "plt.xticks([pos + (len(metricas) - 1) * ancho_barra / 2 for pos in x], score_inv_result['Modelo'], rotation=45, ha=\"right\")\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Mostrar el gráfico combinado\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QFpewChVGFJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UMzmdokzIzF"
      },
      "outputs": [],
      "source": [
        "variables_inv=list(score_inv_result)\n",
        "variables_inv.pop(0)\n",
        "\n",
        "for var in variables_inv:\n",
        "  score_inv_result.plot.bar(x='Modelo', y=var, rot=0, color='green')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Código para la primera gráfica (score_result)\n",
        "metricas = ['Accuracy', 'Recall', 'Precision', 'F1-score']\n",
        "colores = ['#3498DB', '#F7DC6F', '#EC7063', '#58D68D']\n",
        "\n",
        "num_modelos = len(score_result)\n",
        "ancho_barra = 0.15\n",
        "x = range(num_modelos)\n",
        "\n",
        "# Crear una figura con dos subplots, uno a la izquierda y otro a la derecha\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Subplot izquierdo para la primera gráfica (score_result)\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "for i, metrica in enumerate(metricas):\n",
        "    posiciones_x = [pos + i * ancho_barra for pos in x]\n",
        "    valores_metrica = score_result[metrica]\n",
        "    plt.bar(\n",
        "        posiciones_x,\n",
        "        valores_metrica,\n",
        "        width=ancho_barra,\n",
        "        label=metrica,\n",
        "        color=colores[i],\n",
        "    )\n",
        "\n",
        "plt.xlabel('Modelo')\n",
        "plt.ylabel('Valor de la Métrica')\n",
        "plt.title('Comparación de Rendimiento Python')\n",
        "plt.xticks([pos + (len(metricas) - 1) * ancho_barra / 2 for pos in x], score_result['Modelo'], rotation=45, ha=\"right\")\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Subplot derecho para la segunda gráfica (score_inv_result)\n",
        "plt.subplot(1, 2, 2)\n",
        "\n",
        "for i, metrica in enumerate(metricas):\n",
        "    posiciones_x = [pos + i * ancho_barra for pos in x]\n",
        "    valores_metrica = score_inv_result[metrica]\n",
        "    plt.bar(\n",
        "        posiciones_x,\n",
        "        valores_metrica,\n",
        "        width=ancho_barra,\n",
        "        label=metrica,\n",
        "        color=colores[i],\n",
        "    )\n",
        "\n",
        "plt.xlabel('Modelo')\n",
        "plt.title('Comparación de Rendimiento Python (Inverso)')\n",
        "plt.xticks([pos + (len(metricas) - 1) * ancho_barra / 2 for pos in x], score_inv_result['Modelo'], rotation=45, ha=\"right\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.tick_params(labelleft = False)\n",
        "\n",
        "\n",
        "# Ajustar los subplots para evitar superposiciones\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar la figura combinada\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w2BbqQ4BsWNG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}